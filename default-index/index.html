<!DOCTYPE html>
<html lang="zh-CN">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
<meta name="theme-color" content="#222">
<meta name="generator" content="Hexo 5.4.0">
  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png">
  <link rel="mask-icon" href="/images/logo.svg" color="#222">

<link rel="stylesheet" href="/css/main.css">


<link rel="stylesheet" href="/lib/font-awesome/css/all.min.css">

<script id="hexo-configurations">
    var NexT = window.NexT || {};
    var CONFIG = {"hostname":"example.com","root":"/","scheme":"Pisces","version":"7.8.0","exturl":false,"sidebar":{"position":"left","display":"post","padding":18,"offset":12,"onmobile":true,"scrollpercent":true,"b2t":true},"copycode":{"enable":true,"show_result":true,"style":null},"back2top":{"enable":true,"sidebar":false,"scrollpercent":false},"bookmark":{"enable":false,"color":"#222","save":"auto"},"fancybox":false,"mediumzoom":false,"lazyload":false,"pangu":false,"comments":{"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},"algolia":{"hits":{"per_page":10},"labels":{"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}},"localsearch":{"enable":false,"trigger":"auto","top_n_per_article":1,"unescape":false,"preload":false},"motion":{"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}}};
  </script>

  <meta name="description" content="Get busy living or get busy dying">
<meta property="og:type" content="website">
<meta property="og:title" content="Blog">
<meta property="og:url" content="http://example.com/default-index/index.html">
<meta property="og:site_name" content="Blog">
<meta property="og:description" content="Get busy living or get busy dying">
<meta property="og:locale" content="zh_CN">
<meta property="article:author" content="Normal People">
<meta name="twitter:card" content="summary">

<link rel="canonical" href="http://example.com/default-index/">


<script id="page-configurations">
  // https://hexo.io/docs/variables.html
  CONFIG.page = {
    sidebar: "",
    isHome : true,
    isPost : false,
    lang   : 'zh-CN'
  };
</script>

  <title>Blog</title>
  






  <noscript>
  <style>
  .use-motion .brand,
  .use-motion .menu-item,
  .sidebar-inner,
  .use-motion .post-block,
  .use-motion .pagination,
  .use-motion .comments,
  .use-motion .post-header,
  .use-motion .post-body,
  .use-motion .collection-header { opacity: initial; }

  .use-motion .site-title,
  .use-motion .site-subtitle {
    opacity: initial;
    top: initial;
  }

  .use-motion .logo-line-before i { left: initial; }
  .use-motion .logo-line-after i { right: initial; }
  </style>
</noscript>

</head>

<body itemscope itemtype="http://schema.org/WebPage">
  <div class="container use-motion">
    <div class="headband"></div>

    <header class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="切换导航栏">
      <span class="toggle-line toggle-line-first"></span>
      <span class="toggle-line toggle-line-middle"></span>
      <span class="toggle-line toggle-line-last"></span>
    </div>
  </div>

  <div class="site-meta">

    <a href="/" class="brand" rel="start">
      <span class="logo-line-before"><i></i></span>
      <h1 class="site-title">Blog</h1>
      <span class="logo-line-after"><i></i></span>
    </a>
      <p class="site-subtitle" itemprop="description">by Normal People</p>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger">
    </div>
  </div>
</div>




<nav class="site-nav">
  <ul id="menu" class="main-menu menu">
        <li class="menu-item menu-item-home">

    <a href="/" rel="section"><i class="fa fa-home fa-fw"></i>首页</a>

  </li>
        <li class="menu-item menu-item-about">

    <a href="/about" rel="section"><i class="fa fa-user fa-fw"></i>关于</a>

  </li>
        <li class="menu-item menu-item-tags">

    <a href="/tags" rel="section"><i class="fa fa-tags fa-fw"></i>标签<span class="badge">0</span></a>

  </li>
        <li class="menu-item menu-item-categories">

    <a href="/categories" rel="section"><i class="fa fa-th fa-fw"></i>分类<span class="badge">11</span></a>

  </li>
        <li class="menu-item menu-item-archives">

    <a href="/archives" rel="section"><i class="fa fa-archive fa-fw"></i>归档<span class="badge">35</span></a>

  </li>
  </ul>
</nav>




</div>
    </header>

    
  <div class="back-to-top">
    <i class="fa fa-arrow-up"></i>
    <span>0%</span>
  </div>


    <main class="main">
      <div class="main-inner">
        <div class="content-wrap">
          

          <div class="content index posts-expand">
            
      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="http://example.com/2021/07/05/Data%20_Competition/Numpy_Practice/%E7%AC%AC%E4%BA%8C%E7%AB%A0-%E7%B4%A2%E5%BC%95/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/posthead.jpg">
      <meta itemprop="name" content="Normal People">
      <meta itemprop="description" content="Get busy living or get busy dying">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Blog">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2021/07/05/Data%20_Competition/Numpy_Practice/%E7%AC%AC%E4%BA%8C%E7%AB%A0-%E7%B4%A2%E5%BC%95/" class="post-title-link" itemprop="url">第二章 索引</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>
              

              <time title="创建时间：2021-07-05 21:33:50 / 修改时间：21:35:03" itemprop="dateCreated datePublished" datetime="2021-07-05T21:33:50+08:00">2021-07-05</time>
            </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/%E6%95%B0%E6%8D%AE%E7%AB%9E%E8%B5%9B/" itemprop="url" rel="index"><span itemprop="name">数据竞赛</span></a>
                </span>
                  ，
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/%E6%95%B0%E6%8D%AE%E7%AB%9E%E8%B5%9B/Numpy%E5%AE%9E%E8%B7%B5/" itemprop="url" rel="index"><span itemprop="name">Numpy实践</span></a>
                </span>
            </span>

          
  
  <span class="post-meta-item">
    
      <span class="post-meta-item-icon">
        <i class="far fa-comment"></i>
      </span>
      <span class="post-meta-item-text">Valine：</span>
    
    <a title="valine" href="/2021/07/05/Data%20_Competition/Numpy_Practice/%E7%AC%AC%E4%BA%8C%E7%AB%A0-%E7%B4%A2%E5%BC%95/#valine-comments" itemprop="discussionUrl">
      <span class="post-comments-count valine-comment-count" data-xid="/2021/07/05/Data%20_Competition/Numpy_Practice/%E7%AC%AC%E4%BA%8C%E7%AB%A0-%E7%B4%A2%E5%BC%95/" itemprop="commentCount"></span>
    </a>
  </span>
  
  

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h1 id="副本与视图"><a href="#副本与视图" class="headerlink" title="副本与视图"></a>副本与视图</h1><p>在Numpy中，尤其是在做数组运算或数组操作时，返回结果不是数组的<strong>副本</strong>就是<strong>视图</strong>。</p>
<p>在Numpy中，所有赋值运算不会为数组和数组中的任何元素创建副本。</p>
<ul>
<li><p><code>numpy.ndarray.copy()</code> 函数创建一个副本。 对副本数据进行修改，不会影响到原始数据，它们物理内存不在同一位置。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line">x = np.array([<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>, <span class="number">5</span>, <span class="number">6</span>, <span class="number">7</span>, <span class="number">8</span>])</span><br><span class="line">y = x</span><br><span class="line">y[<span class="number">0</span>] = -<span class="number">1</span></span><br><span class="line">print(x)</span><br><span class="line"><span class="comment"># [-1  2  3  4  5  6  7  8]</span></span><br><span class="line">print(y)</span><br><span class="line"><span class="comment"># [-1  2  3  4  5  6  7  8]</span></span><br><span class="line"></span><br><span class="line">x = np.array([<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>, <span class="number">5</span>, <span class="number">6</span>, <span class="number">7</span>, <span class="number">8</span>])</span><br><span class="line">y = x.copy()</span><br><span class="line">y[<span class="number">0</span>] = -<span class="number">1</span></span><br><span class="line">print(x)</span><br><span class="line"><span class="comment"># [1 2 3 4 5 6 7 8]</span></span><br><span class="line">print(y)</span><br><span class="line"><span class="comment"># [-1  2  3  4  5  6  7  8]</span></span><br></pre></td></tr></table></figure>
</li>
</ul>
<h1 id="索引与切片"><a href="#索引与切片" class="headerlink" title="索引与切片"></a>索引与切片</h1><p>数组索引机制指的是用方括号（[]）加序号的形式引用单个数组元素，它的用处很多，比如抽取元素，选取数组的几个元素，甚至为其赋一个新值。</p>
<h2 id="整数索引"><a href="#整数索引" class="headerlink" title="整数索引"></a>整数索引</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line">x = np.array([<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>, <span class="number">5</span>, <span class="number">6</span>, <span class="number">7</span>, <span class="number">8</span>])</span><br><span class="line">print(x[<span class="number">2</span>])  <span class="comment"># 3</span></span><br><span class="line"></span><br><span class="line">x = np.array([[<span class="number">11</span>, <span class="number">12</span>, <span class="number">13</span>, <span class="number">14</span>, <span class="number">15</span>],</span><br><span class="line">              [<span class="number">16</span>, <span class="number">17</span>, <span class="number">18</span>, <span class="number">19</span>, <span class="number">20</span>],</span><br><span class="line">              [<span class="number">21</span>, <span class="number">22</span>, <span class="number">23</span>, <span class="number">24</span>, <span class="number">25</span>],</span><br><span class="line">              [<span class="number">26</span>, <span class="number">27</span>, <span class="number">28</span>, <span class="number">29</span>, <span class="number">30</span>],</span><br><span class="line">              [<span class="number">31</span>, <span class="number">32</span>, <span class="number">33</span>, <span class="number">34</span>, <span class="number">35</span>]])</span><br><span class="line">print(x[<span class="number">2</span>])  <span class="comment"># [21 22 23 24 25]</span></span><br><span class="line">print(x[<span class="number">2</span>][<span class="number">1</span>])  <span class="comment"># 22</span></span><br><span class="line">print(x[<span class="number">2</span>, <span class="number">1</span>])  <span class="comment"># 22</span></span><br></pre></td></tr></table></figure>
<h2 id="切片索引"><a href="#切片索引" class="headerlink" title="切片索引"></a>切片索引</h2><p>切片操作是指抽取数组的一部分元素生成新数组。对 python <strong>列表</strong>进行切片操作得到的数组是原数组的<strong>副本</strong>，而对 <strong>Numpy</strong> 数据进行切片操作得到的数组则是指向相同缓冲区的<strong>视图</strong>。</p>
<p>如果想抽取（或查看）数组的一部分，必须使用切片语法，也就是，把几个用冒号（ <code>start:stop:step</code> ）隔开的数字置于方括号内。</p>
<p>为了更好地理解切片语法，还应该了解不明确指明起始和结束位置的情况。如省去第一个数字，numpy 会认为第一个数字是0；如省去第二个数字，numpy 则会认为第二个数字是数组的最大索引值；如省去最后一个数字，它将会被理解为1，也就是抽取所有元素而不再考虑间隔。</p>
<p>通过对每个以逗号分隔的维度执行单独的切片，你可以对多维数组进行切片。因此，对于二维数组，我们的第一片定义了行的切片，第二片定义了列的切片。</p>
<h2 id="dots索引"><a href="#dots索引" class="headerlink" title="dots索引"></a>dots索引</h2><h1 id="副本与视图-1"><a href="#副本与视图-1" class="headerlink" title="副本与视图"></a>副本与视图</h1><p>在 Numpy 中，尤其是在做数组运算或数组操作时，返回结果不是数组的 <strong>副本</strong> 就是 <strong>视图</strong>。</p>
<p>在 Numpy 中，所有赋值运算不会为数组和数组中的任何元素创建副本。</p>
<ul>
<li><code>numpy.ndarray.copy()</code> 函数创建一个副本。 对副本数据进行修改，不会影响到原始数据，它们物理内存不在同一位置。</li>
</ul>
<p>【例】</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line">x = np.array([<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>, <span class="number">5</span>, <span class="number">6</span>, <span class="number">7</span>, <span class="number">8</span>])</span><br><span class="line">y = x</span><br><span class="line">y[<span class="number">0</span>] = -<span class="number">1</span></span><br><span class="line">print(x)</span><br><span class="line"><span class="comment"># [-1  2  3  4  5  6  7  8]</span></span><br><span class="line">print(y)</span><br><span class="line"><span class="comment"># [-1  2  3  4  5  6  7  8]</span></span><br><span class="line"></span><br><span class="line">x = np.array([<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>, <span class="number">5</span>, <span class="number">6</span>, <span class="number">7</span>, <span class="number">8</span>])</span><br><span class="line">y = x.copy()</span><br><span class="line">y[<span class="number">0</span>] = -<span class="number">1</span></span><br><span class="line">print(x)</span><br><span class="line"><span class="comment"># [1 2 3 4 5 6 7 8]</span></span><br><span class="line">print(y)</span><br><span class="line"><span class="comment"># [-1  2  3  4  5  6  7  8]</span></span><br></pre></td></tr></table></figure>
<p>【例】数组切片操作返回的对象只是原数组的视图。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line">x = np.array([[<span class="number">11</span>, <span class="number">12</span>, <span class="number">13</span>, <span class="number">14</span>, <span class="number">15</span>],</span><br><span class="line">              [<span class="number">16</span>, <span class="number">17</span>, <span class="number">18</span>, <span class="number">19</span>, <span class="number">20</span>],</span><br><span class="line">              [<span class="number">21</span>, <span class="number">22</span>, <span class="number">23</span>, <span class="number">24</span>, <span class="number">25</span>],</span><br><span class="line">              [<span class="number">26</span>, <span class="number">27</span>, <span class="number">28</span>, <span class="number">29</span>, <span class="number">30</span>],</span><br><span class="line">              [<span class="number">31</span>, <span class="number">32</span>, <span class="number">33</span>, <span class="number">34</span>, <span class="number">35</span>]])</span><br><span class="line">y = x</span><br><span class="line">y[::<span class="number">2</span>, :<span class="number">3</span>:<span class="number">2</span>] = -<span class="number">1</span></span><br><span class="line">print(x)</span><br><span class="line"><span class="comment"># [[-1 12 -1 14 15]</span></span><br><span class="line"><span class="comment">#  [16 17 18 19 20]</span></span><br><span class="line"><span class="comment">#  [-1 22 -1 24 25]</span></span><br><span class="line"><span class="comment">#  [26 27 28 29 30]</span></span><br><span class="line"><span class="comment">#  [-1 32 -1 34 35]]</span></span><br><span class="line">print(y)</span><br><span class="line"><span class="comment"># [[-1 12 -1 14 15]</span></span><br><span class="line"><span class="comment">#  [16 17 18 19 20]</span></span><br><span class="line"><span class="comment">#  [-1 22 -1 24 25]</span></span><br><span class="line"><span class="comment">#  [26 27 28 29 30]</span></span><br><span class="line"><span class="comment">#  [-1 32 -1 34 35]]</span></span><br><span class="line"></span><br><span class="line">x = np.array([[<span class="number">11</span>, <span class="number">12</span>, <span class="number">13</span>, <span class="number">14</span>, <span class="number">15</span>],</span><br><span class="line">              [<span class="number">16</span>, <span class="number">17</span>, <span class="number">18</span>, <span class="number">19</span>, <span class="number">20</span>],</span><br><span class="line">              [<span class="number">21</span>, <span class="number">22</span>, <span class="number">23</span>, <span class="number">24</span>, <span class="number">25</span>],</span><br><span class="line">              [<span class="number">26</span>, <span class="number">27</span>, <span class="number">28</span>, <span class="number">29</span>, <span class="number">30</span>],</span><br><span class="line">              [<span class="number">31</span>, <span class="number">32</span>, <span class="number">33</span>, <span class="number">34</span>, <span class="number">35</span>]])</span><br><span class="line">y = x.copy()</span><br><span class="line">y[::<span class="number">2</span>, :<span class="number">3</span>:<span class="number">2</span>] = -<span class="number">1</span></span><br><span class="line">print(x)</span><br><span class="line"><span class="comment"># [[11 12 13 14 15]</span></span><br><span class="line"><span class="comment">#  [16 17 18 19 20]</span></span><br><span class="line"><span class="comment">#  [21 22 23 24 25]</span></span><br><span class="line"><span class="comment">#  [26 27 28 29 30]</span></span><br><span class="line"><span class="comment">#  [31 32 33 34 35]]</span></span><br><span class="line">print(y)</span><br><span class="line"><span class="comment"># [[-1 12 -1 14 15]</span></span><br><span class="line"><span class="comment">#  [16 17 18 19 20]</span></span><br><span class="line"><span class="comment">#  [-1 22 -1 24 25]</span></span><br><span class="line"><span class="comment">#  [26 27 28 29 30]</span></span><br><span class="line"><span class="comment">#  [-1 32 -1 34 35]]</span></span><br></pre></td></tr></table></figure>
<h1 id="索引与切片-1"><a href="#索引与切片-1" class="headerlink" title="索引与切片"></a>索引与切片</h1><p>数组索引机制指的是用方括号（[]）加序号的形式引用单个数组元素，它的用处很多，比如抽取元素，选取数组的几个元素，甚至为其赋一个新值。</p>
<h2 id="整数索引-1"><a href="#整数索引-1" class="headerlink" title="整数索引"></a>整数索引</h2><p>【例】要获取数组的单个元素，指定元素的索引即可。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line">x = np.array([<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>, <span class="number">5</span>, <span class="number">6</span>, <span class="number">7</span>, <span class="number">8</span>])</span><br><span class="line">print(x[<span class="number">2</span>])  <span class="comment"># 3</span></span><br><span class="line"></span><br><span class="line">x = np.array([[<span class="number">11</span>, <span class="number">12</span>, <span class="number">13</span>, <span class="number">14</span>, <span class="number">15</span>],</span><br><span class="line">              [<span class="number">16</span>, <span class="number">17</span>, <span class="number">18</span>, <span class="number">19</span>, <span class="number">20</span>],</span><br><span class="line">              [<span class="number">21</span>, <span class="number">22</span>, <span class="number">23</span>, <span class="number">24</span>, <span class="number">25</span>],</span><br><span class="line">              [<span class="number">26</span>, <span class="number">27</span>, <span class="number">28</span>, <span class="number">29</span>, <span class="number">30</span>],</span><br><span class="line">              [<span class="number">31</span>, <span class="number">32</span>, <span class="number">33</span>, <span class="number">34</span>, <span class="number">35</span>]])</span><br><span class="line">print(x[<span class="number">2</span>])  <span class="comment"># [21 22 23 24 25]</span></span><br><span class="line">print(x[<span class="number">2</span>][<span class="number">1</span>])  <span class="comment"># 22</span></span><br><span class="line">print(x[<span class="number">2</span>, <span class="number">1</span>])  <span class="comment"># 22</span></span><br></pre></td></tr></table></figure>
<h2 id="切片索引-1"><a href="#切片索引-1" class="headerlink" title="切片索引"></a>切片索引</h2><p>切片操作是指抽取数组的一部分元素生成新数组。对 python <strong>列表</strong>进行切片操作得到的数组是原数组的<strong>副本</strong>，而对 <strong>Numpy</strong> 数据进行切片操作得到的数组则是指向相同缓冲区的<strong>视图</strong>。</p>
<p>如果想抽取（或查看）数组的一部分，必须使用切片语法，也就是，把几个用冒号（ <code>start:stop:step</code> ）隔开的数字置于方括号内。</p>
<p>为了更好地理解切片语法，还应该了解不明确指明起始和结束位置的情况。如省去第一个数字，numpy 会认为第一个数字是0；如省去第二个数字，numpy 则会认为第二个数字是数组的最大索引值；如省去最后一个数字，它将会被理解为1，也就是抽取所有元素而不再考虑间隔。</p>
<p>通过对每个以逗号分隔的维度执行单独的切片，你可以对多维数组进行切片。因此，对于二维数组，我们的第一片定义了行的切片，第二片定义了列的切片。</p>
<h2 id="dots-索引"><a href="#dots-索引" class="headerlink" title="dots 索引"></a>dots 索引</h2><p>NumPy 允许使用<code>...</code>表示足够多的冒号来构建完整的索引列表。</p>
<p>比如，如果 <code>x</code> 是 5 维数组：</p>
<ul>
<li><code>x[1,2,...]</code> 等于 <code>x[1,2,:,:,:]</code></li>
<li><code>x[...,3]</code> 等于 <code>x[:,:,:,:,3]</code></li>
<li><code>x[4,...,5,:]</code> 等于 <code>x[4,:,:,5,:]</code></li>
</ul>
<h2 id="整数数组索引"><a href="#整数数组索引" class="headerlink" title="整数数组索引"></a>整数数组索引</h2><p>方括号内传入多个索引值，可以同时选择多个元素。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line">x = np.array([<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>, <span class="number">5</span>, <span class="number">6</span>, <span class="number">7</span>, <span class="number">8</span>])</span><br><span class="line">r = [<span class="number">0</span>, <span class="number">1</span>, <span class="number">2</span>]</span><br><span class="line">print(x[r])</span><br><span class="line"><span class="comment"># [1 2 3]</span></span><br><span class="line"></span><br><span class="line">x = np.array([[<span class="number">11</span>, <span class="number">12</span>, <span class="number">13</span>, <span class="number">14</span>, <span class="number">15</span>],</span><br><span class="line">              [<span class="number">16</span>, <span class="number">17</span>, <span class="number">18</span>, <span class="number">19</span>, <span class="number">20</span>],</span><br><span class="line">              [<span class="number">21</span>, <span class="number">22</span>, <span class="number">23</span>, <span class="number">24</span>, <span class="number">25</span>],</span><br><span class="line">              [<span class="number">26</span>, <span class="number">27</span>, <span class="number">28</span>, <span class="number">29</span>, <span class="number">30</span>],</span><br><span class="line">              [<span class="number">31</span>, <span class="number">32</span>, <span class="number">33</span>, <span class="number">34</span>, <span class="number">35</span>]])</span><br><span class="line">r = [<span class="number">0</span>, <span class="number">1</span>, <span class="number">2</span>]</span><br><span class="line">c = [<span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>]</span><br><span class="line">y = x[r, c]</span><br><span class="line">print(y)</span><br><span class="line"><span class="comment"># [13 19 25]</span></span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line">x = np.array([<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>, <span class="number">5</span>, <span class="number">6</span>, <span class="number">7</span>, <span class="number">8</span>])</span><br><span class="line">r = np.array([[<span class="number">0</span>, <span class="number">1</span>], [<span class="number">3</span>, <span class="number">4</span>]])</span><br><span class="line">print(x[r])</span><br><span class="line"><span class="comment"># [[1 2]</span></span><br><span class="line"><span class="comment">#  [4 5]]</span></span><br><span class="line"></span><br><span class="line">x = np.array([[<span class="number">11</span>, <span class="number">12</span>, <span class="number">13</span>, <span class="number">14</span>, <span class="number">15</span>],</span><br><span class="line">              [<span class="number">16</span>, <span class="number">17</span>, <span class="number">18</span>, <span class="number">19</span>, <span class="number">20</span>],</span><br><span class="line">              [<span class="number">21</span>, <span class="number">22</span>, <span class="number">23</span>, <span class="number">24</span>, <span class="number">25</span>],</span><br><span class="line">              [<span class="number">26</span>, <span class="number">27</span>, <span class="number">28</span>, <span class="number">29</span>, <span class="number">30</span>],</span><br><span class="line">              [<span class="number">31</span>, <span class="number">32</span>, <span class="number">33</span>, <span class="number">34</span>, <span class="number">35</span>]])</span><br><span class="line"></span><br><span class="line">r = np.array([[<span class="number">0</span>, <span class="number">1</span>], [<span class="number">3</span>, <span class="number">4</span>]])</span><br><span class="line">print(x[r])</span><br><span class="line"><span class="comment"># [[[11 12 13 14 15]</span></span><br><span class="line"><span class="comment">#   [16 17 18 19 20]]</span></span><br><span class="line"><span class="comment">#</span></span><br><span class="line"><span class="comment">#  [[26 27 28 29 30]</span></span><br><span class="line"><span class="comment">#   [31 32 33 34 35]]]</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 获取了 5X5 数组中的四个角的元素。</span></span><br><span class="line"><span class="comment"># 行索引是 [0,0] 和 [4,4]，而列索引是 [0,4] 和 [0,4]。</span></span><br><span class="line">r = np.array([[<span class="number">0</span>, <span class="number">0</span>], [<span class="number">4</span>, <span class="number">4</span>]])</span><br><span class="line">c = np.array([[<span class="number">0</span>, <span class="number">4</span>], [<span class="number">0</span>, <span class="number">4</span>]])</span><br><span class="line">y = x[r, c]</span><br><span class="line">print(y)</span><br><span class="line"><span class="comment"># [[11 15]</span></span><br><span class="line"><span class="comment">#  [31 35]]</span></span><br></pre></td></tr></table></figure>
<p>【例】可以借助切片<code>:</code>与整数数组组合。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line">x = np.array([[<span class="number">11</span>, <span class="number">12</span>, <span class="number">13</span>, <span class="number">14</span>, <span class="number">15</span>],</span><br><span class="line">              [<span class="number">16</span>, <span class="number">17</span>, <span class="number">18</span>, <span class="number">19</span>, <span class="number">20</span>],</span><br><span class="line">              [<span class="number">21</span>, <span class="number">22</span>, <span class="number">23</span>, <span class="number">24</span>, <span class="number">25</span>],</span><br><span class="line">              [<span class="number">26</span>, <span class="number">27</span>, <span class="number">28</span>, <span class="number">29</span>, <span class="number">30</span>],</span><br><span class="line">              [<span class="number">31</span>, <span class="number">32</span>, <span class="number">33</span>, <span class="number">34</span>, <span class="number">35</span>]])</span><br><span class="line"></span><br><span class="line">y = x[<span class="number">0</span>:<span class="number">3</span>, [<span class="number">1</span>, <span class="number">2</span>, <span class="number">2</span>]]</span><br><span class="line">print(y)</span><br><span class="line"><span class="comment"># [[12 13 13]</span></span><br><span class="line"><span class="comment">#  [17 18 18]</span></span><br><span class="line"><span class="comment">#  [22 23 23]]</span></span><br></pre></td></tr></table></figure>
<ul>
<li><code>numpy. take(a, indices, axis=None, out=None, mode=&#39;raise&#39;)</code> Take elements from an array along an axis.</li>
</ul>
<p>应注意：使用切片索引到numpy数组时，生成的数组视图将始终是原始数组的子数组, 但是整数数组索引，不是其子数组，是形成新的数组。 切片索引</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line">a=np.array([[<span class="number">1</span>,<span class="number">2</span>],[<span class="number">3</span>,<span class="number">4</span>],[<span class="number">5</span>,<span class="number">6</span>]])</span><br><span class="line">b=a[<span class="number">0</span>:<span class="number">1</span>,<span class="number">0</span>:<span class="number">1</span>]</span><br><span class="line">b[<span class="number">0</span>,<span class="number">0</span>]=<span class="number">2</span></span><br><span class="line">print(a[<span class="number">0</span>,<span class="number">0</span>]==b)</span><br><span class="line"><span class="comment">#[[True]]</span></span><br></pre></td></tr></table></figure>
<p>整数数组索引</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line">a=np.array([[<span class="number">1</span>,<span class="number">2</span>],[<span class="number">3</span>,<span class="number">4</span>],[<span class="number">5</span>,<span class="number">6</span>]])</span><br><span class="line">b=a[<span class="number">0</span>,<span class="number">0</span>]</span><br><span class="line">b=<span class="number">2</span></span><br><span class="line">print(a[<span class="number">0</span>,<span class="number">0</span>]==b)</span><br><span class="line"><span class="comment">#False</span></span><br></pre></td></tr></table></figure>
<h2 id="布尔索引"><a href="#布尔索引" class="headerlink" title="布尔索引"></a>布尔索引</h2><p>我们可以通过一个布尔数组来索引目标数组。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line">x = np.array([<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>, <span class="number">5</span>, <span class="number">6</span>, <span class="number">7</span>, <span class="number">8</span>])</span><br><span class="line">y = x &gt; <span class="number">5</span></span><br><span class="line">print(y)</span><br><span class="line"><span class="comment"># [False False False False False  True  True  True]</span></span><br><span class="line">print(x[x &gt; <span class="number">5</span>])</span><br><span class="line"><span class="comment"># [6 7 8]</span></span><br><span class="line"></span><br><span class="line">x = np.array([np.nan, <span class="number">1</span>, <span class="number">2</span>, np.nan, <span class="number">3</span>, <span class="number">4</span>, <span class="number">5</span>])</span><br><span class="line">y = np.logical_not(np.isnan(x))</span><br><span class="line">print(x[y])</span><br><span class="line"><span class="comment"># [1. 2. 3. 4. 5.]</span></span><br><span class="line"></span><br><span class="line">x = np.array([[<span class="number">11</span>, <span class="number">12</span>, <span class="number">13</span>, <span class="number">14</span>, <span class="number">15</span>],</span><br><span class="line">              [<span class="number">16</span>, <span class="number">17</span>, <span class="number">18</span>, <span class="number">19</span>, <span class="number">20</span>],</span><br><span class="line">              [<span class="number">21</span>, <span class="number">22</span>, <span class="number">23</span>, <span class="number">24</span>, <span class="number">25</span>],</span><br><span class="line">              [<span class="number">26</span>, <span class="number">27</span>, <span class="number">28</span>, <span class="number">29</span>, <span class="number">30</span>],</span><br><span class="line">              [<span class="number">31</span>, <span class="number">32</span>, <span class="number">33</span>, <span class="number">34</span>, <span class="number">35</span>]])</span><br><span class="line">y = x &gt; <span class="number">25</span></span><br><span class="line">print(y)</span><br><span class="line"><span class="comment"># [[False False False False False]</span></span><br><span class="line"><span class="comment">#  [False False False False False]</span></span><br><span class="line"><span class="comment">#  [False False False False False]</span></span><br><span class="line"><span class="comment">#  [ True  True  True  True  True]</span></span><br><span class="line"><span class="comment">#  [ True  True  True  True  True]]</span></span><br><span class="line">print(x[x &gt; <span class="number">25</span>])</span><br><span class="line"><span class="comment"># [26 27 28 29 30 31 32 33 34 35]</span></span><br></pre></td></tr></table></figure>
<h1 id="数组迭代"><a href="#数组迭代" class="headerlink" title="数组迭代"></a>数组迭代</h1><p>除了for循环，Numpy 还提供另外一种更为优雅的遍历方法。</p>
<ul>
<li><p><code>apply_along_axis(func1d, axis, arr)</code> Apply a function to 1-D slices along the given axis。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line">x = np.array([[<span class="number">11</span>, <span class="number">12</span>, <span class="number">13</span>, <span class="number">14</span>, <span class="number">15</span>],</span><br><span class="line">              [<span class="number">16</span>, <span class="number">17</span>, <span class="number">18</span>, <span class="number">19</span>, <span class="number">20</span>],</span><br><span class="line">              [<span class="number">21</span>, <span class="number">22</span>, <span class="number">23</span>, <span class="number">24</span>, <span class="number">25</span>],</span><br><span class="line">              [<span class="number">26</span>, <span class="number">27</span>, <span class="number">28</span>, <span class="number">29</span>, <span class="number">30</span>],</span><br><span class="line">              [<span class="number">31</span>, <span class="number">32</span>, <span class="number">33</span>, <span class="number">34</span>, <span class="number">35</span>]])</span><br><span class="line"></span><br><span class="line">y = np.apply_along_axis(np.<span class="built_in">sum</span>, <span class="number">0</span>, x)</span><br><span class="line">print(y)  <span class="comment"># [105 110 115 120 125]</span></span><br><span class="line">y = np.apply_along_axis(np.<span class="built_in">sum</span>, <span class="number">1</span>, x)</span><br><span class="line">print(y)  <span class="comment"># [ 65  90 115 140 165]</span></span><br><span class="line"></span><br><span class="line">y = np.apply_along_axis(np.mean, <span class="number">0</span>, x)</span><br><span class="line">print(y)  <span class="comment"># [21. 22. 23. 24. 25.]</span></span><br><span class="line">y = np.apply_along_axis(np.mean, <span class="number">1</span>, x)</span><br><span class="line">print(y)  <span class="comment"># [13. 18. 23. 28. 33.]</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">my_func</span>(<span class="params">x</span>):</span></span><br><span class="line">    <span class="keyword">return</span> (x[<span class="number">0</span>] + x[-<span class="number">1</span>]) * <span class="number">0.5</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">y = np.apply_along_axis(my_func, <span class="number">0</span>, x)</span><br><span class="line">print(y)  <span class="comment"># [21. 22. 23. 24. 25.]</span></span><br><span class="line">y = np.apply_along_axis(my_func, <span class="number">1</span>, x)</span><br><span class="line">print(y)  <span class="comment"># [13. 18. 23. 28. 33.]</span></span><br></pre></td></tr></table></figure>
</li>
</ul>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="http://example.com/2021/07/02/Film_And_TV_Series/Films/%E7%94%B5%E5%BD%B1/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/posthead.jpg">
      <meta itemprop="name" content="Normal People">
      <meta itemprop="description" content="Get busy living or get busy dying">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Blog">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2021/07/02/Film_And_TV_Series/Films/%E7%94%B5%E5%BD%B1/" class="post-title-link" itemprop="url">电影推荐</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>
              

              <time title="创建时间：2021-07-02 21:53:48 / 修改时间：22:03:04" itemprop="dateCreated datePublished" datetime="2021-07-02T21:53:48+08:00">2021-07-02</time>
            </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/%E7%94%B5%E5%BD%B1%E7%94%B5%E8%A7%86%E5%89%A7/" itemprop="url" rel="index"><span itemprop="name">电影电视剧</span></a>
                </span>
                  ，
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/%E7%94%B5%E5%BD%B1%E7%94%B5%E8%A7%86%E5%89%A7/%E7%94%B5%E5%BD%B1/" itemprop="url" rel="index"><span itemprop="name">电影</span></a>
                </span>
            </span>

          
  
  <span class="post-meta-item">
    
      <span class="post-meta-item-icon">
        <i class="far fa-comment"></i>
      </span>
      <span class="post-meta-item-text">Valine：</span>
    
    <a title="valine" href="/2021/07/02/Film_And_TV_Series/Films/%E7%94%B5%E5%BD%B1/#valine-comments" itemprop="discussionUrl">
      <span class="post-comments-count valine-comment-count" data-xid="/2021/07/02/Film_And_TV_Series/Films/%E7%94%B5%E5%BD%B1/" itemprop="commentCount"></span>
    </a>
  </span>
  
  

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <p><strong>此博客中推荐的电影电视剧本人均已看过多次并且觉得不错。所有电影电视剧均为个人喜好方向。如有不同见解欢迎留言讨论。</strong></p>
<h1 id="电影推荐："><a href="#电影推荐：" class="headerlink" title="电影推荐："></a>电影推荐：</h1><h2 id="Comedies-喜剧"><a href="#Comedies-喜剧" class="headerlink" title="Comedies 喜剧"></a>Comedies 喜剧</h2><h2 id="Drama-剧情"><a href="#Drama-剧情" class="headerlink" title="Drama 剧情"></a>Drama 剧情</h2><ul>
<li><strong>《肖申克的救赎》</strong></li>
<li><strong>《绿皮书》</strong></li>
<li><strong>《阿甘正传》</strong></li>
<li><strong>《小丑2019》</strong></li>
<li><strong>《魔鬼代言人》</strong></li>
<li><strong>《被解救的姜戈》</strong></li>
<li><strong>《摔跤吧！爸爸》</strong></li>
<li><strong>《荒蛮故事》</strong></li>
<li><strong>《完美陌生人》</strong></li>
<li><strong>《荒野猎人》</strong></li>
<li><strong>《无耻混蛋》</strong></li>
</ul>
<h2 id="Family-家庭"><a href="#Family-家庭" class="headerlink" title="Family 家庭"></a>Family 家庭</h2><h2 id="Animation-动画"><a href="#Animation-动画" class="headerlink" title="Animation 动画"></a>Animation 动画</h2><ul>
<li><strong>《玩具总动员》</strong></li>
</ul>
<h2 id="Romance-浪漫"><a href="#Romance-浪漫" class="headerlink" title="Romance 浪漫"></a>Romance 浪漫</h2><ul>
<li><strong>《泰坦尼克号》</strong></li>
<li><strong>《怦然心动》</strong></li>
<li><strong>《时空恋旅人》</strong></li>
<li><strong>《爱在三部曲》-《爱在黎明破晓前》《爱在日落黄昏时》《爱在午夜降临前》</strong></li>
<li><strong>《真爱至上》</strong></li>
<li><strong>《间谍同盟》</strong></li>
<li><strong>《史密斯夫妇》</strong></li>
<li><strong>《革命之路》</strong></li>
</ul>
<h2 id="Action-动作"><a href="#Action-动作" class="headerlink" title="Action 动作"></a>Action 动作</h2><h2 id="Fantasy-幻想"><a href="#Fantasy-幻想" class="headerlink" title="Fantasy 幻想"></a>Fantasy 幻想</h2><ul>
<li><strong>《盗梦空间》</strong></li>
<li><strong>《信条》</strong></li>
<li><strong>《水形物语》</strong></li>
<li><strong>《蝴蝶效应》</strong></li>
<li><strong>《这个男人来自地球》</strong></li>
<li><strong>《记忆碎片》</strong></li>
<li><strong>《绿里奇迹》</strong></li>
<li><strong>《返老还童》又名《本杰明·巴顿奇事》</strong></li>
<li><strong>《搏击俱乐部》</strong></li>
<li><strong>《时间旅行者的妻子》</strong></li>
<li><strong>《禁闭岛》</strong></li>
<li><strong>《致命魔术》</strong></li>
</ul>
<h2 id="Adventure-冒险"><a href="#Adventure-冒险" class="headerlink" title="Adventure 冒险"></a>Adventure 冒险</h2><ul>
<li><strong>《饥饿游戏1-3》</strong></li>
</ul>
<h2 id="Sci-Fi-科幻"><a href="#Sci-Fi-科幻" class="headerlink" title="Sci-Fi 科幻"></a>Sci-Fi 科幻</h2><ul>
<li><p><strong>《星际穿越》</strong></p>
</li>
<li><p><strong>《火星救援》</strong></p>
</li>
<li><p><strong>《彗星来的那一夜》</strong></p>
</li>
<li><p><strong>《黑客帝国1-3》</strong></p>
</li>
<li><p><strong>《猩球崛起1-3》</strong></p>
</li>
<li><p><strong>《太空旅客》</strong></p>
</li>
<li><p><strong>《侏罗纪公园1-3》</strong></p>
</li>
<li><p><strong>《侏罗纪世界1-2》</strong></p>
</li>
<li><p><strong>《攻壳机动队》</strong></p>
</li>
<li><p><strong>《超体》</strong></p>
</li>
<li><p><strong>《AI人工智能》</strong></p>
</li>
</ul>
<h2 id="Crime-犯罪"><a href="#Crime-犯罪" class="headerlink" title="Crime 犯罪"></a>Crime 犯罪</h2><ul>
<li><strong>《教父1-3》</strong></li>
<li><strong>《蝙蝠侠》-诺兰版三部曲</strong></li>
<li><strong>《七宗罪》</strong></li>
<li><strong>《速度与激情1-8》</strong> </li>
<li><p><strong>《金蝉脱壳》</strong></p>
</li>
<li><p><strong>《利刃出鞘》</strong></p>
</li>
<li><strong>《惊天魔盗团1-3》</strong></li>
<li><strong>《法官老爹》</strong></li>
<li><strong>《撞车》</strong></li>
<li><strong>《火柴人》</strong></li>
<li><strong>《老无所依》</strong></li>
<li><strong>《会计刺客》</strong></li>
<li><strong>《分裂》</strong></li>
<li><strong>《生死狙击》</strong></li>
<li><strong>《玩命快递》</strong></li>
<li><strong>《极限特工1-2》</strong></li>
<li><strong>《十二宫》</strong></li>
<li><strong>《谍影重重1-5》</strong></li>
<li><strong>《寄生虫》</strong></li>
</ul>
<h2 id="Musicals-音乐"><a href="#Musicals-音乐" class="headerlink" title="Musicals 音乐"></a>Musicals 音乐</h2><ul>
<li><strong>《再次出发》</strong></li>
<li><strong>《爱乐之城》</strong></li>
</ul>
<h2 id="Horror-恐怖"><a href="#Horror-恐怖" class="headerlink" title="Horror 恐怖"></a>Horror 恐怖</h2><h2 id="Thrillers-惊悚"><a href="#Thrillers-惊悚" class="headerlink" title="Thrillers 惊悚"></a>Thrillers 惊悚</h2><h2 id="Documentaries-纪录片"><a href="#Documentaries-纪录片" class="headerlink" title="Documentaries 纪录片"></a>Documentaries 纪录片</h2><h2 id="War-战争"><a href="#War-战争" class="headerlink" title="War 战争"></a>War 战争</h2><ul>
<li><strong>《1917》</strong></li>
<li><strong>《黑鹰坠落》</strong></li>
<li><strong>《拯救大兵瑞恩》</strong></li>
<li><strong>《决战中途岛》</strong></li>
</ul>
<h2 id="History-历史"><a href="#History-历史" class="headerlink" title="History 历史"></a>History 历史</h2><h2 id="Biographies-传记"><a href="#Biographies-传记" class="headerlink" title="Biographies 传记"></a>Biographies 传记</h2><ul>
<li><strong>《模仿游戏》</strong></li>
<li><strong>《猫鼠游戏》</strong></li>
<li><strong>《飞行家》</strong></li>
<li><strong>《美丽心灵》</strong></li>
<li><strong>《社交网络》</strong></li>
<li><strong>《达拉斯买家俱乐部》</strong></li>
<li><strong>《天才捕手》</strong></li>
<li><p><strong>《波西米亚狂想曲》</strong></p>
</li>
<li><p><strong>《为奴十二年》</strong></p>
</li>
<li><p><strong>《八英里》</strong></p>
</li>
</ul>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="http://example.com/2021/07/02/Data%20_Competition/Numpy_Practice/%E7%AC%AC%E4%B8%80%E7%AB%A0-%E6%95%B0%E6%8D%AE%E7%B1%BB%E5%9E%8B%E5%8F%8A%E6%95%B0%E7%BB%84%E5%88%9B%E5%BB%BA/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/posthead.jpg">
      <meta itemprop="name" content="Normal People">
      <meta itemprop="description" content="Get busy living or get busy dying">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Blog">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2021/07/02/Data%20_Competition/Numpy_Practice/%E7%AC%AC%E4%B8%80%E7%AB%A0-%E6%95%B0%E6%8D%AE%E7%B1%BB%E5%9E%8B%E5%8F%8A%E6%95%B0%E7%BB%84%E5%88%9B%E5%BB%BA/" class="post-title-link" itemprop="url">第一章 数据类型及数组创建</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>
              

              <time title="创建时间：2021-07-02 21:43:59 / 修改时间：22:02:03" itemprop="dateCreated datePublished" datetime="2021-07-02T21:43:59+08:00">2021-07-02</time>
            </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/%E6%95%B0%E6%8D%AE%E7%AB%9E%E8%B5%9B/" itemprop="url" rel="index"><span itemprop="name">数据竞赛</span></a>
                </span>
                  ，
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/%E6%95%B0%E6%8D%AE%E7%AB%9E%E8%B5%9B/Numpy%E5%AE%9E%E8%B7%B5/" itemprop="url" rel="index"><span itemprop="name">Numpy实践</span></a>
                </span>
            </span>

          
  
  <span class="post-meta-item">
    
      <span class="post-meta-item-icon">
        <i class="far fa-comment"></i>
      </span>
      <span class="post-meta-item-text">Valine：</span>
    
    <a title="valine" href="/2021/07/02/Data%20_Competition/Numpy_Practice/%E7%AC%AC%E4%B8%80%E7%AB%A0-%E6%95%B0%E6%8D%AE%E7%B1%BB%E5%9E%8B%E5%8F%8A%E6%95%B0%E7%BB%84%E5%88%9B%E5%BB%BA/#valine-comments" itemprop="discussionUrl">
      <span class="post-comments-count valine-comment-count" data-xid="/2021/07/02/Data%20_Competition/Numpy_Practice/%E7%AC%AC%E4%B8%80%E7%AB%A0-%E6%95%B0%E6%8D%AE%E7%B1%BB%E5%9E%8B%E5%8F%8A%E6%95%B0%E7%BB%84%E5%88%9B%E5%BB%BA/" itemprop="commentCount"></span>
    </a>
  </span>
  
  

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h1 id="常量"><a href="#常量" class="headerlink" title="常量"></a>常量</h1><h2 id="numpy-nan"><a href="#numpy-nan" class="headerlink" title="numpy.nan"></a>numpy.nan</h2><ul>
<li>表示空值。</li>
</ul>
<p>nan = NaN = NAN</p>
<p>两个numpy.nan是不相等的。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np </span><br><span class="line">print(np.nan == np.nan) <span class="comment">#False</span></span><br></pre></td></tr></table></figure>
<ul>
<li>numpy.isnan(x, <em>args, *</em>kwargs)</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np </span><br><span class="line">x = np.array([<span class="number">1</span>, <span class="number">2</span>, nan, <span class="number">4</span>])</span><br><span class="line">print(x) <span class="comment">#[1, 2, nan, 4]</span></span><br><span class="line"></span><br><span class="line">y = np.isnan(x)</span><br><span class="line">print(y) <span class="comment">#[False False False  True False]</span></span><br><span class="line"></span><br><span class="line">z = np.cout_nonzero(y) </span><br><span class="line">print(z) <span class="comment"># 1 True == 1, False == 0 </span></span><br></pre></td></tr></table></figure>
<h2 id="numpy-inf"><a href="#numpy-inf" class="headerlink" title="numpy.inf"></a>numpy.inf</h2><ul>
<li>表示正无穷大。</li>
</ul>
<p>Inf = inf = infty = Infinity = PINF</p>
<h2 id="numpy-pi"><a href="#numpy-pi" class="headerlink" title="numpy.pi"></a>numpy.pi</h2><ul>
<li>表示圆周率</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pi = <span class="number">3.1415926535897932384626433</span>...</span><br></pre></td></tr></table></figure>
<h2 id="numpy-e"><a href="#numpy-e" class="headerlink" title="numpy.e"></a>numpy.e</h2><ul>
<li>表示自然常数</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">e = <span class="number">2.71828182845904523536028747135266249775724709369995</span>...</span><br></pre></td></tr></table></figure>
<h1 id="数据类型"><a href="#数据类型" class="headerlink" title="数据类型"></a>数据类型</h1><h2 id="常见数据类型"><a href="#常见数据类型" class="headerlink" title="常见数据类型"></a>常见数据类型</h2><div class="table-container">
<table>
<thead>
<tr>
<th>类型</th>
<th>备注</th>
<th>说明</th>
</tr>
</thead>
<tbody>
<tr>
<td>bool_ = bool8</td>
<td>8位</td>
<td>布尔类型</td>
</tr>
<tr>
<td>int8 = byte</td>
<td>8位</td>
<td>整型</td>
</tr>
<tr>
<td>int16 = short</td>
<td>16位</td>
<td>整型</td>
</tr>
<tr>
<td>int32 = intc</td>
<td>32位</td>
<td>整型</td>
</tr>
<tr>
<td>int_ = int64 = long = int0 = intp</td>
<td>64位</td>
<td>整型</td>
</tr>
<tr>
<td>uint8 = ubyte</td>
<td>8位</td>
<td>无符号整型</td>
</tr>
<tr>
<td>uint16 = ushort</td>
<td>16位</td>
<td>无符号整型</td>
</tr>
<tr>
<td>uint32 = uintc</td>
<td>32位</td>
<td>无符号整型</td>
</tr>
<tr>
<td>uint64 = uintp = uint0 = uint</td>
<td>64位</td>
<td>无符号整型</td>
</tr>
<tr>
<td>float16 = half</td>
<td>16位</td>
<td>浮点型</td>
</tr>
<tr>
<td>float32 = single</td>
<td>32位</td>
<td>浮点型</td>
</tr>
<tr>
<td>float_ = float64 = double</td>
<td>64位</td>
<td>浮点型</td>
</tr>
<tr>
<td>str_ = unicode_ = str0 = unicode</td>
<td>\</td>
<td>Unicode 字符串</td>
<td></td>
</tr>
<tr>
<td>datetime64</td>
<td>\</td>
<td>日期时间类型</td>
<td></td>
</tr>
<tr>
<td>timedelta64</td>
<td>\</td>
<td>表示两个时间之间的间隔</td>
</tr>
</tbody>
</table>
</div>
<h2 id="创建数据类型"><a href="#创建数据类型" class="headerlink" title="创建数据类型"></a>创建数据类型</h2><p>numpy的数值类型实际上是dtype对象的实例。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">dtype</span>(<span class="params"><span class="built_in">object</span></span>):</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, obj, align=<span class="literal">False</span>, copy=<span class="literal">False</span></span>):</span></span><br><span class="line">        <span class="keyword">pass</span></span><br></pre></td></tr></table></figure>
<p>每个内建类型都有一个唯一定义它的字符代码，如下：</p>
<div class="table-container">
<table>
<thead>
<tr>
<th>字符</th>
<th>对应类型</th>
<th>备注</th>
</tr>
</thead>
<tbody>
<tr>
<td>b</td>
<td>boolean</td>
<td>‘b1’</td>
</tr>
<tr>
<td>i</td>
<td>signed integer</td>
<td>‘i1’, ‘i2’, ‘i4’, ‘i8’</td>
</tr>
<tr>
<td>u</td>
<td>unsigned integer</td>
<td>‘u1’, ‘u2’ ,’u4’ ,’u8’</td>
</tr>
<tr>
<td>f</td>
<td>floating-point</td>
<td>‘f2’, ‘f4’, ‘f8’</td>
</tr>
<tr>
<td>c</td>
<td>complex floating-point</td>
<td></td>
</tr>
<tr>
<td>m</td>
<td>timedelta64</td>
<td>表示两个时间之间的间隔</td>
</tr>
<tr>
<td>M</td>
<td>datetime64</td>
<td>日期时间类型</td>
</tr>
<tr>
<td>O</td>
<td>object</td>
<td></td>
</tr>
<tr>
<td>S</td>
<td>(byte-)string</td>
<td>S3表示长度为3的字符串</td>
</tr>
<tr>
<td>U</td>
<td>Unicode</td>
<td>Unicode 字符串</td>
</tr>
<tr>
<td>V</td>
<td>void</td>
</tr>
</tbody>
</table>
</div>
<p>例：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line">a = np.dtype(<span class="string">&#x27;b1&#x27;</span>)</span><br></pre></td></tr></table></figure>
<h2 id="数据类型信息"><a href="#数据类型信息" class="headerlink" title="数据类型信息"></a>数据类型信息</h2><p>Python 的浮点数通常是64位浮点数，几乎等同于 <code>np.float64</code>。</p>
<p>NumPy和Python整数类型的行为在整数溢出方面存在显着差异，与 NumPy 不同，Python 的<code>int</code> 是灵活的。这意味着Python整数可以扩展以容纳任何整数并且不会溢出。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">iinfo</span>(<span class="params"><span class="built_in">object</span></span>):</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, int_type</span>):</span></span><br><span class="line">        <span class="keyword">pass</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">min</span>(<span class="params">self</span>):</span></span><br><span class="line">        <span class="keyword">pass</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">max</span>(<span class="params">self</span>):</span></span><br><span class="line">        <span class="keyword">pass</span></span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">finfo</span>(<span class="params"><span class="built_in">object</span></span>):</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">_init</span>(<span class="params">self, dtype</span>):</span></span><br></pre></td></tr></table></figure>
<h1 id="时间日期和时间增量"><a href="#时间日期和时间增量" class="headerlink" title="时间日期和时间增量"></a>时间日期和时间增量</h1><h2 id="datetime64基础"><a href="#datetime64基础" class="headerlink" title="datetime64基础"></a>datetime64基础</h2><p>在 numpy 中，我们很方便的将字符串转换成时间日期类型 <code>datetime64</code>（<code>datetime</code> 已被 python 包含的日期时间库所占用）。</p>
<p><code>datatime64</code>是带单位的日期时间类型，其单位如下：</p>
<div class="table-container">
<table>
<thead>
<tr>
<th>日期单位</th>
<th>代码含义</th>
<th>时间单位</th>
<th>代码含义</th>
</tr>
</thead>
<tbody>
<tr>
<td>Y</td>
<td>年</td>
<td>h</td>
<td>小时</td>
</tr>
<tr>
<td>M</td>
<td>月</td>
<td>m</td>
<td>分钟</td>
</tr>
<tr>
<td>W</td>
<td>周</td>
<td>s</td>
<td>秒</td>
</tr>
<tr>
<td>D</td>
<td>天</td>
<td>ms</td>
<td>毫秒</td>
</tr>
<tr>
<td>-</td>
<td>-</td>
<td>us</td>
<td>微秒</td>
</tr>
<tr>
<td>-</td>
<td>-</td>
<td>ns</td>
<td>纳秒</td>
</tr>
<tr>
<td>-</td>
<td>-</td>
<td>ps</td>
<td>皮秒</td>
</tr>
<tr>
<td>-</td>
<td>-</td>
<td>fs</td>
<td>飞秒</td>
</tr>
<tr>
<td>-</td>
<td>-</td>
<td>as</td>
<td>阿托秒</td>
</tr>
</tbody>
</table>
</div>
<p>例：从字符串创建 datetime64 类型时，默认情况下，numpy 会根据字符串自动选择对应的单位。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">a = np.datetime64(<span class="string">&#x27;2020-03-08 20:00:05&#x27;</span>)</span><br><span class="line">print(a, a.dtype)  <span class="comment"># 2020-03-08T20:00:05 datetime64[s]</span></span><br></pre></td></tr></table></figure>
<p>例：从字符串创建 datetime64 类型时，可以强制指定使用的单位。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line">a = np.datetime64(<span class="string">&#x27;2020-03&#x27;</span>, <span class="string">&#x27;D&#x27;</span>)</span><br><span class="line">print(a, a.dtype)  <span class="comment"># 2020-03-01 datetime64[D]</span></span><br><span class="line"></span><br><span class="line">a = np.datetime64(<span class="string">&#x27;2020-03&#x27;</span>, <span class="string">&#x27;Y&#x27;</span>)</span><br><span class="line">print(a, a.dtype)  <span class="comment"># 2020 datetime64[Y]</span></span><br><span class="line"></span><br><span class="line">print(np.datetime64(<span class="string">&#x27;2020-03&#x27;</span>) == np.datetime64(<span class="string">&#x27;2020-03-01&#x27;</span>))  <span class="comment"># True</span></span><br><span class="line">print(np.datetime64(<span class="string">&#x27;2020-03&#x27;</span>) == np.datetime64(<span class="string">&#x27;2020-03-02&#x27;</span>))  <span class="comment">#False</span></span><br></pre></td></tr></table></figure>
<p>由上例可以看出，2019-03 和 2019-03-01 所表示的其实是同一个时间。 事实上，如果两个 datetime64 对象具有不同的单位，它们可能仍然代表相同的时刻。并且从较大的单位（如月份）转换为较小的单位（如天数）是安全的。</p>
<p>例：从字符串创建 datetime64 数组时，如果单位不统一，则一律转化成其中最小的单位。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line">a = np.array([<span class="string">&#x27;2020-03&#x27;</span>, <span class="string">&#x27;2020-03-08&#x27;</span>, <span class="string">&#x27;2020-03-08 20:00&#x27;</span>], dtype=<span class="string">&#x27;datetime64&#x27;</span>)</span><br><span class="line">print(a, a.dtype)</span><br><span class="line"><span class="comment"># [&#x27;2020-03-01T00:00&#x27; &#x27;2020-03-08T00:00&#x27; &#x27;2020-03-08T20:00&#x27;] datetime64[m]</span></span><br></pre></td></tr></table></figure>
<p>例：使用<code>arange()</code>创建 datetime64 数组，用于生成日期范围。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line">a = np.arange(<span class="string">&#x27;2020-08-01&#x27;</span>, <span class="string">&#x27;2020-08-10&#x27;</span>, dtype=np.datetime64)</span><br><span class="line">print(a)</span><br><span class="line"><span class="comment"># [&#x27;2020-08-01&#x27; &#x27;2020-08-02&#x27; &#x27;2020-08-03&#x27; &#x27;2020-08-04&#x27; &#x27;2020-08-05&#x27;</span></span><br><span class="line"><span class="comment">#  &#x27;2020-08-06&#x27; &#x27;2020-08-07&#x27; &#x27;2020-08-08&#x27; &#x27;2020-08-09&#x27;]</span></span><br><span class="line">print(a.dtype)  <span class="comment"># datetime64[D]</span></span><br></pre></td></tr></table></figure>
<h2 id="datetime64和timedelta64运算"><a href="#datetime64和timedelta64运算" class="headerlink" title="datetime64和timedelta64运算"></a>datetime64和timedelta64运算</h2><p>例：timedelta64 表示两个 datetime64 之间的差。timedelta64 也是带单位的，并且和相减运算中的两个 datetime64 中的较小的单位保持一致。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line">a = np.datetime64(<span class="string">&#x27;2020-03&#x27;</span>) + np.timedelta64(<span class="number">20</span>, <span class="string">&#x27;D&#x27;</span>)</span><br><span class="line">b = np.datetime64(<span class="string">&#x27;2020-06-15 00:00&#x27;</span>) + np.timedelta64(<span class="number">12</span>, <span class="string">&#x27;h&#x27;</span>)</span><br><span class="line">print(a, a.dtype)  <span class="comment"># 2020-03-21 datetime64[D]</span></span><br><span class="line">print(b, b.dtype)  <span class="comment"># 2020-06-15T12:00 datetime64[m]</span></span><br></pre></td></tr></table></figure>
<p>生成 timedelta64时，要注意年（’Y’）和月（’M’）这两个单位无法和其它单位进行运算（一年有几天？一个月有几个小时？这些都是不确定的）。</p>
<p>例：numpy.datetime64 与 datetime.datetime 相互转换</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> datetime</span><br><span class="line"></span><br><span class="line">dt = datetime.datetime(year=<span class="number">2020</span>, month=<span class="number">6</span>, day=<span class="number">1</span>, hour=<span class="number">20</span>, minute=<span class="number">5</span>, second=<span class="number">30</span>)</span><br><span class="line">dt64 = np.datetime64(dt, <span class="string">&#x27;s&#x27;</span>)</span><br><span class="line">print(dt64, dt64.dtype)</span><br><span class="line"><span class="comment"># 2020-06-01T20:05:30 datetime64[s]</span></span><br><span class="line"></span><br><span class="line">dt2 = dt64.astype(datetime.datetime)</span><br><span class="line">print(dt2, <span class="built_in">type</span>(dt2))</span><br><span class="line"><span class="comment"># 2020-06-01 20:05:30 &lt;class &#x27;datetime.datetime&#x27;&gt;</span></span><br></pre></td></tr></table></figure>
<h2 id="datetime64的应用"><a href="#datetime64的应用" class="headerlink" title="datetime64的应用"></a>datetime64的应用</h2><ul>
<li><p>numpy.busday_offset(dates, offsets, roll=’raise’, weekmask=’1111100’, holidays=None, busdaycal=None, out=None)</p>
<p>将指定的偏移量应用于工作日，单位天（’D’）。计算下一个工作日，如果当前日期为非工作日，默认报错。可以指定 <code>forward</code> 或 <code>backward</code> 规则来避免报错。（一个是向前取第一个有效的工作日，一个是向后取第一个有效的工作日）</p>
<p>可以指定偏移量为 0 来获取当前日期向前或向后最近的工作日，当然，如果当前日期本身就是工作日，则直接返回当前日期。</p>
</li>
<li><p>numpy.is_busday(dates, weekmask=’1111100’, holidays=None, busdaycal=None, out=None)</p>
</li>
</ul>
<p>例：自定义周掩码值，即指定一周中哪些星期是工作日。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 2020-07-10 星期五</span></span><br><span class="line">a = np.is_busday(<span class="string">&#x27;2020-07-10&#x27;</span>, weekmask=[<span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">0</span>, <span class="number">0</span>])</span><br><span class="line">b = np.is_busday(<span class="string">&#x27;2020-07-10&#x27;</span>, weekmask=[<span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">1</span>])</span><br><span class="line">print(a)  <span class="comment"># True</span></span><br><span class="line">print(b)  <span class="comment"># False</span></span><br></pre></td></tr></table></figure>
<p>例：返回两个日期之间的工作日数量。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line"><span class="comment"># 2020-07-10 星期五</span></span><br><span class="line">begindates = np.datetime64(<span class="string">&#x27;2020-07-10&#x27;</span>)</span><br><span class="line">enddates = np.datetime64(<span class="string">&#x27;2020-07-20&#x27;</span>)</span><br><span class="line">a = np.busday_count(begindates, enddates)</span><br><span class="line">b = np.busday_count(enddates, begindates)</span><br><span class="line">print(a)  <span class="comment"># 6</span></span><br><span class="line">print(b)  <span class="comment"># -6</span></span><br></pre></td></tr></table></figure>
<h1 id="数组的创建"><a href="#数组的创建" class="headerlink" title="数组的创建"></a>数组的创建</h1><p>numpy 提供的最重要的数据结构是<code>ndarray</code>，它是 python 中<code>list</code>的扩展。</p>
<h2 id="1-依据现有数据来创建ndarray"><a href="#1-依据现有数据来创建ndarray" class="headerlink" title="1. 依据现有数据来创建ndarray"></a>1. 依据现有数据来创建ndarray</h2><h3 id="（a）通过array-函数进行创建"><a href="#（a）通过array-函数进行创建" class="headerlink" title="（a）通过array()函数进行创建"></a>（a）通过array()函数进行创建</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">array</span>(<span class="params">p_object, dtype=<span class="literal">None</span>, copy=<span class="literal">True</span>, order=<span class="string">&#x27;K&#x27;</span>, subok=<span class="literal">False</span>, ndmin=<span class="number">0</span></span>):</span> </span><br></pre></td></tr></table></figure>
<p>例：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line">d = np.array([[(<span class="number">1.5</span>, <span class="number">2</span>, <span class="number">3</span>), (<span class="number">4</span>, <span class="number">5</span>, <span class="number">6</span>)],</span><br><span class="line">              [(<span class="number">3</span>, <span class="number">2</span>, <span class="number">1</span>), (<span class="number">4</span>, <span class="number">5</span>, <span class="number">6</span>)]])</span><br><span class="line">print(d, <span class="built_in">type</span>(d))</span><br></pre></td></tr></table></figure>
<h3 id="（b）通过asarray-函数进行创建"><a href="#（b）通过asarray-函数进行创建" class="headerlink" title="（b）通过asarray()函数进行创建"></a>（b）通过asarray()函数进行创建</h3><p><code>array()</code>和<code>asarray()</code>都可以将结构数据转化为 ndarray，但是<code>array()</code>和<code>asarray()</code>主要区别就是当数据源是<strong>ndarray</strong> 时，<code>array()</code>仍然会 copy 出一个副本，占用新的内存，但不改变 dtype 时 <code>asarray()</code>不会。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">asarray</span>(<span class="params">a, dtype=<span class="literal">None</span>, order=<span class="literal">None</span></span>):</span></span><br><span class="line">    <span class="keyword">return</span> array(a, dtype, copy=<span class="literal">False</span>, order=order)</span><br></pre></td></tr></table></figure>
<h3 id="（c）通过fromfunction-函数进行创建"><a href="#（c）通过fromfunction-函数进行创建" class="headerlink" title="（c）通过fromfunction()函数进行创建"></a>（c）通过fromfunction()函数进行创建</h3><p>给函数绘图的时候可能会用到<code>fromfunction()</code>，该函数可从函数中创建数组。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">fromfunction</span>(<span class="params">function, shape, **kwargs</span>):</span></span><br></pre></td></tr></table></figure>
<p>例：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">f</span>(<span class="params">x, y</span>):</span></span><br><span class="line">    <span class="keyword">return</span> <span class="number">10</span> * x + y</span><br><span class="line"></span><br><span class="line">x = np.fromfunction(f, (<span class="number">5</span>, <span class="number">4</span>), dtype=<span class="built_in">int</span>)</span><br><span class="line">print(x)</span><br><span class="line"><span class="comment"># [[ 0  1  2  3]</span></span><br><span class="line"><span class="comment">#  [10 11 12 13]</span></span><br><span class="line"><span class="comment">#  [20 21 22 23]</span></span><br><span class="line"><span class="comment">#  [30 31 32 33]</span></span><br><span class="line"><span class="comment">#  [40 41 42 43]]</span></span><br><span class="line"></span><br><span class="line">x = np.fromfunction(<span class="keyword">lambda</span> i, j: i == j, (<span class="number">3</span>, <span class="number">3</span>), dtype=<span class="built_in">int</span>)</span><br><span class="line">print(x)</span><br><span class="line"><span class="comment"># [[ True False False]</span></span><br><span class="line"><span class="comment">#  [False  True False]</span></span><br><span class="line"><span class="comment">#  [False False  True]]</span></span><br><span class="line"></span><br><span class="line">x = np.fromfunction(<span class="keyword">lambda</span> i, j: i + j, (<span class="number">3</span>, <span class="number">3</span>), dtype=<span class="built_in">int</span>)</span><br><span class="line">print(x)</span><br><span class="line"><span class="comment"># [[0 1 2]</span></span><br><span class="line"><span class="comment">#  [1 2 3]</span></span><br><span class="line"><span class="comment">#  [2 3 4]]</span></span><br></pre></td></tr></table></figure>
<h2 id="2-依据ones和zeros填充方式"><a href="#2-依据ones和zeros填充方式" class="headerlink" title="2. 依据ones和zeros填充方式"></a>2. 依据ones和zeros填充方式</h2><p>在机器学习任务中经常做的一件事就是初始化参数，需要用常数值或者随机值来创建一个固定大小的矩阵。</p>
<h3 id="（a）零数组"><a href="#（a）零数组" class="headerlink" title="（a）零数组"></a>（a）零数组</h3><ul>
<li><code>zeros()</code>函数：返回给定形状和类型的零数组。</li>
<li><code>zeros_like()</code>函数：返回与给定数组形状和类型相同的零数组。</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">zeros</span>(<span class="params">shape, dtype=<span class="literal">None</span>, order=<span class="string">&#x27;C&#x27;</span></span>):</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">zeros_like</span>(<span class="params">a, dtype=<span class="literal">None</span>, order=<span class="string">&#x27;K&#x27;</span>, subok=<span class="literal">True</span>, shape=<span class="literal">None</span></span>):</span></span><br></pre></td></tr></table></figure>
<h3 id="（b）1数组"><a href="#（b）1数组" class="headerlink" title="（b）1数组"></a>（b）1数组</h3><ul>
<li><code>ones()</code>函数：返回给定形状和类型的1数组。</li>
<li><code>ones_like()</code>函数：返回与给定数组形状和类型相同的1数组。</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">ones</span>(<span class="params">shape, dtype=<span class="literal">None</span>, order=<span class="string">&#x27;C&#x27;</span></span>):</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">ones_like</span>(<span class="params">a, dtype=<span class="literal">None</span>, order=<span class="string">&#x27;K&#x27;</span>, subok=<span class="literal">True</span>, shape=<span class="literal">None</span></span>):</span></span><br></pre></td></tr></table></figure>
<h3 id="（c）空数组"><a href="#（c）空数组" class="headerlink" title="（c）空数组"></a>（c）空数组</h3><ul>
<li><code>empty()</code>函数：返回一个空数组，数组元素为随机数。</li>
<li><code>empty_like</code>函数：返回与给定数组具有相同形状和类型的新数组。</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">empty</span>(<span class="params">shape, dtype=<span class="literal">None</span>, order=<span class="string">&#x27;C&#x27;</span></span>):</span> </span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">empty_like</span>(<span class="params">prototype, dtype=<span class="literal">None</span>, order=<span class="string">&#x27;K&#x27;</span>, subok=<span class="literal">True</span>, shape=<span class="literal">None</span></span>):</span></span><br></pre></td></tr></table></figure>
<h3 id="（d）单位数组"><a href="#（d）单位数组" class="headerlink" title="（d）单位数组"></a>（d）单位数组</h3><ul>
<li><code>eye()</code>函数：返回一个对角线上为1，其它地方为零的单位数组。</li>
<li><code>identity()</code>函数：返回一个方的单位数组。</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">eye</span>(<span class="params">N, M=<span class="literal">None</span>, k=<span class="number">0</span>, dtype=<span class="built_in">float</span>, order=<span class="string">&#x27;C&#x27;</span></span>):</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">identity</span>(<span class="params">n, dtype=<span class="literal">None</span></span>):</span></span><br></pre></td></tr></table></figure>
<h3 id="（e）对角数组"><a href="#（e）对角数组" class="headerlink" title="（e）对角数组"></a>（e）对角数组</h3><ul>
<li><code>diag()</code>函数：提取对角线或构造对角数组。</li>
</ul>
<p>例：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line">x = np.arange(<span class="number">9</span>).reshape((<span class="number">3</span>, <span class="number">3</span>))</span><br><span class="line">print(x)</span><br><span class="line"><span class="comment"># [[0 1 2]</span></span><br><span class="line"><span class="comment">#  [3 4 5]</span></span><br><span class="line"><span class="comment">#  [6 7 8]]</span></span><br><span class="line">print(np.diag(x))  <span class="comment"># [0 4 8]</span></span><br><span class="line">print(np.diag(x, k=<span class="number">1</span>))  <span class="comment"># [1 5]</span></span><br><span class="line">print(np.diag(x, k=-<span class="number">1</span>))  <span class="comment"># [3 7]</span></span><br><span class="line"></span><br><span class="line">v = [<span class="number">1</span>, <span class="number">3</span>, <span class="number">5</span>, <span class="number">7</span>]</span><br><span class="line">x = np.diag(v)</span><br><span class="line">print(x)</span><br><span class="line"><span class="comment"># [[1 0 0 0]</span></span><br><span class="line"><span class="comment">#  [0 3 0 0]</span></span><br><span class="line"><span class="comment">#  [0 0 5 0]</span></span><br><span class="line"><span class="comment">#  [0 0 0 7]]</span></span><br></pre></td></tr></table></figure>
<h3 id="（f）常数数组"><a href="#（f）常数数组" class="headerlink" title="（f）常数数组"></a>（f）常数数组</h3><ul>
<li><code>full()</code>函数：返回一个常数数组。</li>
<li><code>full_like()</code>函数：返回与给定数组具有相同形状和类型的常数数组。</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">full</span>(<span class="params">shape, fill_value, dtype=<span class="literal">None</span>, order=<span class="string">&#x27;C&#x27;</span></span>):</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">full_like</span>(<span class="params">a, fill_value, dtype=<span class="literal">None</span>, order=<span class="string">&#x27;K&#x27;</span>, subok=<span class="literal">True</span>, shape=<span class="literal">None</span></span>):</span></span><br></pre></td></tr></table></figure>
<h2 id="3-利用数值范围来创建ndarray"><a href="#3-利用数值范围来创建ndarray" class="headerlink" title="3. 利用数值范围来创建ndarray"></a>3. 利用数值范围来创建ndarray</h2><ul>
<li><code>arange()</code>函数：返回给定间隔内的均匀间隔的值。</li>
<li><code>linspace()</code>函数：返回指定间隔内的等间隔数字。</li>
<li><code>logspace()</code>函数：返回数以对数刻度均匀分布。</li>
<li><code>numpy.random.rand()</code> 返回一个由[0,1)内的随机数组成的数组。</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">arange</span>(<span class="params">[start,] stop[, step,], dtype=<span class="literal">None</span></span>):</span> </span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">linspace</span>(<span class="params">start, stop, num=<span class="number">50</span>, endpoint=<span class="literal">True</span>, retstep=<span class="literal">False</span>, </span></span></span><br><span class="line"><span class="function"><span class="params">             dtype=<span class="literal">None</span>, axis=<span class="number">0</span></span>):</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">logspace</span>(<span class="params">start, stop, num=<span class="number">50</span>, endpoint=<span class="literal">True</span>, base=<span class="number">10.0</span>, </span></span></span><br><span class="line"><span class="function"><span class="params">             dtype=<span class="literal">None</span>, axis=<span class="number">0</span></span>):</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">rand</span>(<span class="params">d0, d1, ..., dn</span>):</span></span><br></pre></td></tr></table></figure>
<h2 id="4-结构数组的创建"><a href="#4-结构数组的创建" class="headerlink" title="4. 结构数组的创建"></a>4. 结构数组的创建</h2><p>结构数组，首先需要定义结构，然后利用<code>np.array()</code>来创建数组，其参数<code>dtype</code>为定义的结构。</p>
<h3 id="（a）利用字典来定义结构"><a href="#（a）利用字典来定义结构" class="headerlink" title="（a）利用字典来定义结构"></a>（a）利用字典来定义结构</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line">personType = np.dtype(&#123;</span><br><span class="line">    <span class="string">&#x27;names&#x27;</span>: [<span class="string">&#x27;name&#x27;</span>, <span class="string">&#x27;age&#x27;</span>, <span class="string">&#x27;weight&#x27;</span>],</span><br><span class="line">    <span class="string">&#x27;formats&#x27;</span>: [<span class="string">&#x27;U30&#x27;</span>, <span class="string">&#x27;i8&#x27;</span>, <span class="string">&#x27;f8&#x27;</span>]&#125;)</span><br><span class="line"></span><br><span class="line">a = np.array([(<span class="string">&#x27;Liming&#x27;</span>, <span class="number">24</span>, <span class="number">63.9</span>), (<span class="string">&#x27;Mike&#x27;</span>, <span class="number">15</span>, <span class="number">67.</span>), (<span class="string">&#x27;Jan&#x27;</span>, <span class="number">34</span>, <span class="number">45.8</span>)],</span><br><span class="line">             dtype=personType)</span><br><span class="line">print(a, <span class="built_in">type</span>(a))</span><br><span class="line"><span class="comment"># [(&#x27;Liming&#x27;, 24, 63.9) (&#x27;Mike&#x27;, 15, 67. ) (&#x27;Jan&#x27;, 34, 45.8)]</span></span><br><span class="line"><span class="comment"># &lt;class &#x27;numpy.ndarray&#x27;&gt;</span></span><br></pre></td></tr></table></figure>
<h3 id="（b）利用包含多个元组的列表来定义结构"><a href="#（b）利用包含多个元组的列表来定义结构" class="headerlink" title="（b）利用包含多个元组的列表来定义结构"></a>（b）利用包含多个元组的列表来定义结构</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line">personType = np.dtype([(<span class="string">&#x27;name&#x27;</span>, <span class="string">&#x27;U30&#x27;</span>), (<span class="string">&#x27;age&#x27;</span>, <span class="string">&#x27;i8&#x27;</span>), (<span class="string">&#x27;weight&#x27;</span>, <span class="string">&#x27;f8&#x27;</span>)])</span><br><span class="line">a = np.array([(<span class="string">&#x27;Liming&#x27;</span>, <span class="number">24</span>, <span class="number">63.9</span>), (<span class="string">&#x27;Mike&#x27;</span>, <span class="number">15</span>, <span class="number">67.</span>), (<span class="string">&#x27;Jan&#x27;</span>, <span class="number">34</span>, <span class="number">45.8</span>)],</span><br><span class="line">             dtype=personType)</span><br><span class="line">print(a, <span class="built_in">type</span>(a))</span><br><span class="line"><span class="comment"># [(&#x27;Liming&#x27;, 24, 63.9) (&#x27;Mike&#x27;, 15, 67. ) (&#x27;Jan&#x27;, 34, 45.8)]</span></span><br><span class="line"><span class="comment"># &lt;class &#x27;numpy.ndarray&#x27;&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 结构数组的取值方式和一般数组差不多，可以通过下标取得元素：</span></span><br><span class="line">print(a[<span class="number">0</span>])</span><br><span class="line"><span class="comment"># (&#x27;Liming&#x27;, 24, 63.9)</span></span><br><span class="line"></span><br><span class="line">print(a[-<span class="number">2</span>:])</span><br><span class="line"><span class="comment"># [(&#x27;Mike&#x27;, 15, 67. ) (&#x27;Jan&#x27;, 34, 45.8)]</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 我们可以使用字段名作为下标获取对应的值</span></span><br><span class="line">print(a[<span class="string">&#x27;name&#x27;</span>])</span><br><span class="line"><span class="comment"># [&#x27;Liming&#x27; &#x27;Mike&#x27; &#x27;Jan&#x27;]</span></span><br><span class="line">print(a[<span class="string">&#x27;age&#x27;</span>])</span><br><span class="line"><span class="comment"># [24 15 34]</span></span><br><span class="line">print(a[<span class="string">&#x27;weight&#x27;</span>])</span><br><span class="line"><span class="comment"># [63.9 67.  45.8]</span></span><br></pre></td></tr></table></figure>
<h1 id="数组的属性"><a href="#数组的属性" class="headerlink" title="数组的属性"></a>数组的属性</h1><p>在使用 numpy 时，你会想知道数组的某些信息。很幸运，在这个包里边包含了很多便捷的方法，可以给你想要的信息。</p>
<ul>
<li><code>numpy.ndarray.ndim</code>用于返回数组的维数（轴的个数）也称为秩，一维数组的秩为 1，二维数组的秩为 2，以此类推。</li>
<li><code>numpy.ndarray.shape</code>表示数组的维度，返回一个元组，这个元组的长度就是维度的数目，即 <code>ndim</code> 属性(秩)。</li>
<li><code>numpy.ndarray.size</code>数组中所有元素的总量，相当于数组的<code>shape</code>中所有元素的乘积，例如矩阵的元素总量为行与列的乘积。</li>
<li><code>numpy.ndarray.dtype</code> <code>ndarray</code> 对象的元素类型。</li>
<li><code>numpy.ndarray.itemsize</code>以字节的形式返回数组中每一个元素的大小。</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">ndarray</span>(<span class="params"><span class="built_in">object</span></span>):</span></span><br><span class="line">    shape = <span class="built_in">property</span>(<span class="keyword">lambda</span> self: <span class="built_in">object</span>(), <span class="keyword">lambda</span> self, v: <span class="literal">None</span>, <span class="keyword">lambda</span> self: <span class="literal">None</span>)</span><br><span class="line">    dtype = <span class="built_in">property</span>(<span class="keyword">lambda</span> self: <span class="built_in">object</span>(), <span class="keyword">lambda</span> self, v: <span class="literal">None</span>, <span class="keyword">lambda</span> self: <span class="literal">None</span>)</span><br><span class="line">    size = <span class="built_in">property</span>(<span class="keyword">lambda</span> self: <span class="built_in">object</span>(), <span class="keyword">lambda</span> self, v: <span class="literal">None</span>, <span class="keyword">lambda</span> self: <span class="literal">None</span>)</span><br><span class="line">    ndim = <span class="built_in">property</span>(<span class="keyword">lambda</span> self: <span class="built_in">object</span>(), <span class="keyword">lambda</span> self, v: <span class="literal">None</span>, <span class="keyword">lambda</span> self: <span class="literal">None</span>)</span><br><span class="line">    itemsize = <span class="built_in">property</span>(<span class="keyword">lambda</span> self: <span class="built_in">object</span>(), <span class="keyword">lambda</span> self, v: <span class="literal">None</span>, <span class="keyword">lambda</span> self: <span class="literal">None</span>)</span><br></pre></td></tr></table></figure>
<p>在<code>ndarray</code>中所有元素必须是同一类型，否则会自动向下转换，<code>int-&gt;float-&gt;str</code>。</p>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="http://example.com/2021/06/29/Film_And_TV_Series/TV_Series/%E7%94%B5%E8%A7%86%E5%89%A7/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/posthead.jpg">
      <meta itemprop="name" content="Normal People">
      <meta itemprop="description" content="Get busy living or get busy dying">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Blog">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2021/06/29/Film_And_TV_Series/TV_Series/%E7%94%B5%E8%A7%86%E5%89%A7/" class="post-title-link" itemprop="url">电视剧推荐</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              <time title="创建时间：2021-06-29 21:18:48" itemprop="dateCreated datePublished" datetime="2021-06-29T21:18:48+08:00">2021-06-29</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">更新于</span>
                <time title="修改时间：2021-07-02 22:03:12" itemprop="dateModified" datetime="2021-07-02T22:03:12+08:00">2021-07-02</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/%E7%94%B5%E5%BD%B1%E7%94%B5%E8%A7%86%E5%89%A7/" itemprop="url" rel="index"><span itemprop="name">电影电视剧</span></a>
                </span>
                  ，
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/%E7%94%B5%E5%BD%B1%E7%94%B5%E8%A7%86%E5%89%A7/%E7%94%B5%E8%A7%86%E5%89%A7/" itemprop="url" rel="index"><span itemprop="name">电视剧</span></a>
                </span>
            </span>

          
  
  <span class="post-meta-item">
    
      <span class="post-meta-item-icon">
        <i class="far fa-comment"></i>
      </span>
      <span class="post-meta-item-text">Valine：</span>
    
    <a title="valine" href="/2021/06/29/Film_And_TV_Series/TV_Series/%E7%94%B5%E8%A7%86%E5%89%A7/#valine-comments" itemprop="discussionUrl">
      <span class="post-comments-count valine-comment-count" data-xid="/2021/06/29/Film_And_TV_Series/TV_Series/%E7%94%B5%E8%A7%86%E5%89%A7/" itemprop="commentCount"></span>
    </a>
  </span>
  
  

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <p><strong>此博客中推荐的电影电视剧本人均已看过多次并且觉得不错。所有电影电视剧均为个人喜好方向。如有不同见解欢迎留言讨论。</strong></p>
<h1 id="电视剧推荐："><a href="#电视剧推荐：" class="headerlink" title="电视剧推荐："></a>电视剧推荐：</h1><h2 id="Comedies-喜剧"><a href="#Comedies-喜剧" class="headerlink" title="Comedies 喜剧"></a>Comedies 喜剧</h2><h2 id="Drama-剧情"><a href="#Drama-剧情" class="headerlink" title="Drama 剧情"></a>Drama 剧情</h2><ul>
<li><strong>《冰血暴》第1 - 2季</strong></li>
</ul>
<h2 id="Family-家庭"><a href="#Family-家庭" class="headerlink" title="Family 家庭"></a>Family 家庭</h2><h2 id="Animation-动画"><a href="#Animation-动画" class="headerlink" title="Animation 动画"></a>Animation 动画</h2><ul>
<li><strong>《爱，死亡，机器人》1-2季</strong></li>
</ul>
<h2 id="Romance-浪漫"><a href="#Romance-浪漫" class="headerlink" title="Romance 浪漫"></a>Romance 浪漫</h2><ul>
<li><strong>《Normal People》《普通人》</strong></li>
<li><strong>《现世爱情》</strong></li>
</ul>
<h2 id="Action-动作"><a href="#Action-动作" class="headerlink" title="Action 动作"></a>Action 动作</h2><h2 id="Fantasy-幻想"><a href="#Fantasy-幻想" class="headerlink" title="Fantasy 幻想"></a>Fantasy 幻想</h2><ul>
<li><strong>《暗黑》1 - 3季</strong></li>
</ul>
<h2 id="Adventure-冒险"><a href="#Adventure-冒险" class="headerlink" title="Adventure 冒险"></a>Adventure 冒险</h2><h2 id="Sci-Fi-科幻"><a href="#Sci-Fi-科幻" class="headerlink" title="Sci-Fi 科幻"></a>Sci-Fi 科幻</h2><h2 id="Crime-犯罪"><a href="#Crime-犯罪" class="headerlink" title="Crime 犯罪"></a>Crime 犯罪</h2><ul>
<li><strong>《绝命毒师》1 - 5季</strong></li>
<li><strong>《越狱》 1 - 5季</strong></li>
<li><strong>《纸钞屋》1 - 4季</strong></li>
<li><strong>《浴血黑帮》1 - 5季</strong></li>
<li><strong>《无罪之最》 第1季</strong></li>
</ul>
<h2 id="Musicals-音乐"><a href="#Musicals-音乐" class="headerlink" title="Musicals 音乐"></a>Musicals 音乐</h2><h2 id="Horror-恐怖"><a href="#Horror-恐怖" class="headerlink" title="Horror 恐怖"></a>Horror 恐怖</h2><h2 id="Thrillers-惊悚"><a href="#Thrillers-惊悚" class="headerlink" title="Thrillers 惊悚"></a>Thrillers 惊悚</h2><h2 id="Documentaries-纪录片"><a href="#Documentaries-纪录片" class="headerlink" title="Documentaries 纪录片"></a>Documentaries 纪录片</h2><h2 id="War-战争"><a href="#War-战争" class="headerlink" title="War 战争"></a>War 战争</h2><h2 id="History-历史"><a href="#History-历史" class="headerlink" title="History 历史"></a>History 历史</h2><h2 id="Biographies-传记"><a href="#Biographies-传记" class="headerlink" title="Biographies 传记"></a>Biographies 传记</h2>
      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="http://example.com/2021/06/27/Statistical_Learning_Methods_Notes/%E7%AC%AC%E5%8D%81%E5%85%AD%E7%AB%A0-%E4%B8%BB%E6%88%90%E5%88%86%E5%88%86%E6%9E%90/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/posthead.jpg">
      <meta itemprop="name" content="Normal People">
      <meta itemprop="description" content="Get busy living or get busy dying">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Blog">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2021/06/27/Statistical_Learning_Methods_Notes/%E7%AC%AC%E5%8D%81%E5%85%AD%E7%AB%A0-%E4%B8%BB%E6%88%90%E5%88%86%E5%88%86%E6%9E%90/" class="post-title-link" itemprop="url">第十六章 主成分分析</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>
              

              <time title="创建时间：2021-06-27 15:38:41 / 修改时间：15:38:13" itemprop="dateCreated datePublished" datetime="2021-06-27T15:38:41+08:00">2021-06-27</time>
            </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/%E7%BB%9F%E8%AE%A1%E5%AD%A6%E4%B9%A0%E6%96%B9%E6%B3%95/" itemprop="url" rel="index"><span itemprop="name">统计学习方法</span></a>
                </span>
            </span>

          
  
  <span class="post-meta-item">
    
      <span class="post-meta-item-icon">
        <i class="far fa-comment"></i>
      </span>
      <span class="post-meta-item-text">Valine：</span>
    
    <a title="valine" href="/2021/06/27/Statistical_Learning_Methods_Notes/%E7%AC%AC%E5%8D%81%E5%85%AD%E7%AB%A0-%E4%B8%BB%E6%88%90%E5%88%86%E5%88%86%E6%9E%90/#valine-comments" itemprop="discussionUrl">
      <span class="post-comments-count valine-comment-count" data-xid="/2021/06/27/Statistical_Learning_Methods_Notes/%E7%AC%AC%E5%8D%81%E5%85%AD%E7%AB%A0-%E4%B8%BB%E6%88%90%E5%88%86%E5%88%86%E6%9E%90/" itemprop="commentCount"></span>
    </a>
  </span>
  
  

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <p>主成分分析（principal component analysis，PCA）是一种常用的无监督学习方法，这一方法利用正交变换把由线性相关变量表示的观测数据转换为少数几个由线性无关变量表示的数据，线性无关的变量称为主成分。</p>
<p>主成分的个数通常小于原始变量的个数，所以主成分分析属于降维方法。</p>
<p>主成分分析主要用于发现数据中的基本结构，即数据中变量之间的关系，是数据分析的有力工具，也用于其他机器学习方法的前处理。</p>
<h1 id="16-1-总体主成分分析"><a href="#16-1-总体主成分分析" class="headerlink" title="16.1 总体主成分分析"></a>16.1 总体主成分分析</h1><h2 id="16-1-1-基本想法"><a href="#16-1-1-基本想法" class="headerlink" title="16.1.1 基本想法"></a>16.1.1 基本想法</h2><p>统计分析中，数据的变量之间可能存在相关性，以致增加了分析的难度。于是，考虑由少数不相关的变量来代替相关的变量，用来表示数据，并且要求能够保留数据中的大部分信息。</p>
<p>主成分分析中，首先对给定数据进行规范化，使得数据每一变量的平均值为0，方差为1。之后对数据进行正交变换，原来由线性相关变量表示的数据，通过正交变换变成若干个线性无关的新变量表示的数据。新变量是可能的正交变换中变量的方差的和（信息保存）最大的，方差表示在新变量上信息的大小。将新变量依次称为第一主成分、第二主成分等。</p>
<p>对原坐标系中的数据进行主成分分析等价于进行坐标系旋转变换，将数据投影到新坐标系的坐标轴上；新坐标系的第一坐标轴、第二坐标轴等分别表示第一主成分、第二主成分等，数据在每一轴上的坐标值的平方表示相应变量的方差；并且，这个坐标系是在所有可能的新的坐标系中，坐标轴上的方差的和最大的。</p>
<p>等价地，主成分分析在旋转变换中选取离样本点的距离平方和最小的轴，作为第一主成分。第二主成分等的选取，在保证与已选坐标轴正交的条件下，类似地进行。</p>
<p>在数据总体（population）上进行的主成分分析称为总体主成分分析，在有限样本上进行的主成分分析称为样本主成分分析，前者是后者的基础。</p>
<h2 id="16-1-2-定义和导出"><a href="#16-1-2-定义和导出" class="headerlink" title="16.1.2 定义和导出"></a>16.1.2 定义和导出</h2><p>假设$x = (x_1,x_2,…,x_m)^T$是$m$维随机变量，其均值向量是$\mu$</p>
<script type="math/tex; mode=display">
\mu = E(x) = (\mu_1,\mu_2,...,\mu_m)^T</script><p>协方差矩阵是$\Sigma$</p>
<script type="math/tex; mode=display">
\Sigma = cov(x,x) = E[(x - \mu)(x-\mu)^T]</script><p>考虑由$m$维随机变量$x$到$m$维随机变量$y = (y_1,y_2,…,y_m)^T$的线性变换</p>
<script type="math/tex; mode=display">
y_i = \alpha_i^T x = \alpha_{1i}^T x_1+\alpha_{2i}^T x_2+...+\alpha_{mi}^T x_m\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ (16.1)</script><p>其中$\alpha_i^T = (\alpha_{1i},\alpha_{2i},…,\alpha_{mi}),i=1,2,…,m$。</p>
<p>由随机变量的性质可知，</p>
<script type="math/tex; mode=display">
E(y_i) = \alpha_i^T\mu, \ \ \ \ \ i = 1,2,...,m\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ (16.2)</script><script type="math/tex; mode=display">
var(y_i) = \alpha_i^T \Sigma \alpha_i\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ (16.3)</script><script type="math/tex; mode=display">
cov(y_i,y_j) = \alpha_i^T \Sigma \alpha_j, \ \ \ \ \ i= 1,2,...,m, \ \ \ \ \ j = 1,2,...,m\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ (16.4)</script><hr>
<p><strong>定义 16.1（总体主成分）</strong>  给定一个如式$(16.1)$所示的线性变换，如果它们满足下列条件：</p>
<p>（1）系数向量$\alpha_i^T$是单位向量，即$\alpha_i^T\alpha_i = 1,i = 1,2,…,m$；</p>
<p>（2）变量$y_i$与$y_j$互不相关，即$cov(y_i,y_j) = 0(i \neq j)$；</p>
<p>（3）变量$y_1$是$x$的所有线性变换中方差最大的；$y_2$是与$y_1$不相关的$x$的所有线性变换中方差最大的；一般地，$y_i$是与$y_1,y_2,…,y_{i-1}(i = 1,2,…,m)$都不相关的$x$的所有线性变换中方差最大的；这时分别称$y_1,y_2,…,y_m$为$x$的第一主成分、第二主成分、… 、第$m$主成分。</p>
<p>定义中的条件$(1)$表明线性变换是正交变换，$\alpha_1,\alpha_2,…,\alpha_m$是其一组标准正交基，</p>
<script type="math/tex; mode=display">
\alpha_i^T \alpha_j = \lbrace_{0, \ \ \ i \neq j}^{1 \ \ \ i = j}</script><p>条件$(2)(3)$给出了一个求主成分的方法：第一步，在$x$的所有线性变换</p>
<script type="math/tex; mode=display">
\alpha_1^Tx = \sum\limits_{i=1}^{m}\alpha_{i1}x_i</script><p>中，在$\alpha_1^T\alpha_1 = 1$条件下，求方差最大的，得到$x$的第一主成分；第二步，在与$\alpha_1^Tx$不相关的$x$的所有线性变换</p>
<script type="math/tex; mode=display">
\alpha_2^Tx = \sum\limits_{i=1}^{m}\alpha_{i2}x_i</script><p>中，在$\alpha_2^T\alpha_2 = 1$条件下，求方差最大的，得到$x$的第二主成分；第$k$步，在与$\alpha_1^Tx,\alpha_2^Tx,…,\alpha_{k-1}^Tx$不相关的$x$的所有线性变换</p>
<script type="math/tex; mode=display">
\alpha_k^Tx = \sum\limits_{i=1}^{m}\alpha_{ik}x_i</script><p>中，在$\alpha_k^T\alpha_k = 1$条件下，求方差最大的，得到$x$的第$k$主成分；如此继续下去，直到得到$x$的第$m$主成分。</p>
<h2 id="16-1-3-主要性质"><a href="#16-1-3-主要性质" class="headerlink" title="16.1.3 主要性质"></a>16.1.3 主要性质</h2><p><strong>定理 16.1</strong>  设$x$是$m$维随机变量，$\Sigma$是$x$的协方差矩阵，$\Sigma$的特征值分别是$\lambda_1 \geq\lambda_2 \geq…\geq \lambda_m \geq 0$，特征值对应的单位特征向量分别是$\alpha_1,\alpha_2,…,\alpha_m$，则$x$的第$k$主成分是</p>
<script type="math/tex; mode=display">
y_k = \alpha_k^T x = \alpha_{1k}^T x_1+\alpha_{2k}^T x_2+...+\alpha_{mk}^T x_m\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ (16.5)</script><p>$x$的第$k$主成分的方差是</p>
<script type="math/tex; mode=display">
var(y_k) = \alpha_k^T\Sigma\alpha_k = \lambda_k, \ \ \ \ \ k=1,2,...,m\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ (16.6)</script><p>即协方差矩阵$\Sigma$的第$k$个特征值。</p>
<hr>
<p><strong>推论 16.1</strong>  $m$维随机变量$y = (y_1,y_2,…,y_m)^T$的分量依次是$x$的第一主成分到第$m$主成分的充要条件是：</p>
<p>（1）$y = A^Tx$，$A$为正交矩阵</p>
<script type="math/tex; mode=display">
A = \left[ \begin{matrix}
\alpha_{11}&\alpha_{12}&...&\alpha_{1m}\\
\alpha_{21}&\alpha_{22}&...&\alpha_{2m}\\
.&.& &.\\
.&.& &.\\
.&.& &.\\
\alpha_{m1}&\alpha_{m2}&...&\alpha_{mm}
\end{matrix}\right]</script><p>（2）$y$的协方差矩阵为对角矩阵</p>
<script type="math/tex; mode=display">
cov(y) = diag(\lambda_1,\lambda_2 ,... ,\lambda_m)</script><script type="math/tex; mode=display">
\lambda_1 \geq\lambda_2 \geq...\geq \lambda_m</script><p>其中$\lambda_k$是$\Sigma$的第$k$个特征值，$\alpha_k$是对应的单位特征向量，$k = 1,2,…,m$。</p>
<hr>
<p>下面叙述总体主成分的性质：</p>
<p>（1）总体主成分$y$的协方差矩阵是对角矩阵</p>
<script type="math/tex; mode=display">
cov(y) =\varLambda= diag(\lambda_1,\lambda_2 ,... ,\lambda_m)\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ (16.17)</script><p>（2）总体主成分$y$的方差之和等于随机变量$x$的方差之和，即</p>
<script type="math/tex; mode=display">
\sum\limits_{i = 1}^{m} \lambda_i = \sum\limits_{i = 1}^{m} \sigma_{ii}\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ (16.18)</script><p>其中$\sigma_{ii}$是随机变量$x_i$的方差，即协方差矩阵$\Sigma$的对角元素。</p>
<p>（3）第$k$个主成分$y_k$与变量$x_i$的相关系数$\rho(y_k,x_i)$称为<strong>因子负荷量（factor loading）</strong>，它表示第$k$个主成分$y_k$与变量$x_i$的相关关系。计算公式是</p>
<script type="math/tex; mode=display">
\rho(y_k,x_i) = \frac{\sqrt{\lambda_k}\alpha_{ik}}{\sqrt{\sigma_{ii}}}, \ \ \ \ \ k,i = 1,2,...,m\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ (16.20)</script><p>（4）第$k$个主成分$y_k$与$m$个变量的因子负荷量满足</p>
<script type="math/tex; mode=display">
\sum\limits_{i = 1}^{m}\sigma_{ii}\rho^2(y_k,x_i) = 1\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ (16.22)</script><h2 id="16-1-4-主成分的个数"><a href="#16-1-4-主成分的个数" class="headerlink" title="16.1.4 主成分的个数"></a>16.1.4 主成分的个数</h2><p>主成分分析的主要目的是降维，所以一般选择$k, k \ll m$个主成分（线性无关变量）来代替$m$个原有变量（线性相关变量），使问题得以简化，并能保留原有变量的大部分信息。这里所说的信息是指原有变量的方差。</p>
<p><strong>定理 16.2</strong>  对任意正整数$q$，$1 \leq q \leq m$，考虑正交线性变换</p>
<script type="math/tex; mode=display">
y = B^T x\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ (16.23)</script><p>其中$y$是$q$维向量，$B^T$是$q \times m$矩阵，令$y$的协方差矩阵为</p>
<script type="math/tex; mode=display">
\Sigma _y = B^T\Sigma B\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ (16.24)</script><p>则$\Sigma_y$的迹$tr(\Sigma_y)$在$B= A_q$时取得<strong>最大值</strong>，其中矩阵$A_q$由正交矩阵$A$的<strong>前</strong>$q$<strong>列</strong>组成。</p>
<p>定理16.2表明，当$x$的线性变换$y$在$B=A_q$时，其协方差矩阵$\Sigma_y$的迹$tr(\Sigma_y)$取得最大值，这就是说，当取$A$的前$q$列取$x$的前$q$个主成分时，能够最大限度地保留原有变量方差的信息。</p>
<hr>
<p><strong>定理16.3</strong>  考虑正交变换</p>
<script type="math/tex; mode=display">
y = B^Tx</script><p>这里$B^T$是$ p \times m$矩阵，$A$和$\Sigma_y$的定义与定理16.2相同，则$tr(\Sigma_y)$在$B = A_p$时取得<strong>最小值</strong>，其中矩阵$A_p$由$A$的<strong>后</strong>$p$<strong>列</strong>组成。</p>
<p>以上两个定理可以作为选择$k$个主成分的理论依据。具体选择$k$的方法，通常利用方差贡献率。</p>
<hr>
<p><strong>定义 16.2</strong>  第$k$主成分$y_k$的方差贡献率定义为$y_k$的方差与所有方差之和的比，记作$\eta_k$</p>
<script type="math/tex; mode=display">
\eta_k = \frac{\lambda_k}{\sum\limits_{i=1}^{m}\lambda_i}\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ (16.30)</script><p>$k$个主成分$y_1,y_2,…,y_k$的累计方差贡献率定义为$k$个方差之和与所有方差之和的比</p>
<script type="math/tex; mode=display">
\sum\limits_{i=1}^{k}\eta_i =\frac{\sum\limits_{i=1}^{k}\lambda_i}{\sum\limits_{i=1}^{m}\lambda_i}\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ (16.31)</script><p>通常取$k$使得累计方差贡献率达到规定的百分比以上，例如$70\%$ ~ $80\%$以上。累计方差贡献率反映了主成分保留信息的比例，但它不能反映对某个原有变量$x_i$保留信息的比例，这时通常利用$k$个主成分$y_1,y_2,…,y_k$对原有变量$x_i$的贡献率。</p>
<hr>
<p><strong>定义 16.3</strong>  $k$个主成分$y_1,y_2,…,y_k$对原有变量$x_i$的贡献率定义为$x_i$与$(y_1,y_2,…,y_k)$的相关系数的平方，记作$\nu_i$</p>
<script type="math/tex; mode=display">
\nu_i = \rho^2(x_i,(y_1,y_2,...,y_k))</script><p>计算公式如下：</p>
<script type="math/tex; mode=display">
\nu_i =\rho^2(x_i,(y_1,y_2,...,y_k)) = \sum\limits_{j=1}^{k}\rho^2(x_i,y_j) = \sum\limits_{j=1}^{k}\frac{\lambda_j\alpha^2_{ij}}{\sigma_{ii}}\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ (16.32)</script><h2 id="16-1-5-规范化变量的总体主成分"><a href="#16-1-5-规范化变量的总体主成分" class="headerlink" title="16.1.5 规范化变量的总体主成分"></a>16.1.5 规范化变量的总体主成分</h2><p>在实际问题中，不同变量可能有不同的量纲，直接求主成分有时会产生不合理的结果。为了消除这个影响，常常对各个随机变量实施规范化，使其均值为$0$，方差为$1$。</p>
<p>设$x = (x_1,x_2,…,x_m)^T$为$m$维随机变量，$x_i$为第$i$个随机变量，$i = 1,2,…,m$，令</p>
<script type="math/tex; mode=display">
x_{i}^{*} = \frac{x_i - E(x_i)}{\sqrt{var(x_i)}},\ \ \ \ \ i=1,2,...,m\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ (16.33)</script><p>其中$E(x_i),var(x_i)$分别是随机变量$x_i$的均值和方差，这时$x_i^*$就是$x_i$的规范化随机变量。</p>
<p>显然，规范化随机变量的协方差矩阵就是相关矩阵$R$。主成分分析通常在规范化随机变量的协方差矩阵即相关矩阵上进行。</p>
<p>对照总体主成分的性质可知，规范化随机变量的总体主成分有如下性质：</p>
<p>（1）规范化变量主成分的协方差矩阵是</p>
<script type="math/tex; mode=display">
\Lambda^* = diag(\lambda_1^*,\lambda_2^*,...,\lambda_m^*)\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ (16.34)</script><p>其中$\lambda_1^<em>\geq \lambda_2^</em>\geq…\geq\lambda_m^*\geq0$为相关矩阵$R$的特征值。</p>
<p>（2）协方差矩阵的特征值之和为$m$</p>
<script type="math/tex; mode=display">
\sum\limits_{k=1}^{m}\lambda_k^* = m\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ (16.35)</script><p>（3）规范化随机变量$x_i^<em>$与主成分$y_k^</em>$的相关系数（因子负荷量）为</p>
<script type="math/tex; mode=display">
\rho(y_k^*,x_i^*) = \sqrt{\lambda_k^*}e_{ik}^* \ \ \ \ \ k,i = 1,2,...,m\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ (16.36)</script><p>其中$e_k^<em> = (e_{1k}^</em>,e_{2k}^<em>,…,e_{mk}^</em>)^T$为矩阵$R$对应于特征值$\lambda_k^*$的单位特征向量。</p>
<p>（4）所有规范化随机变量$x_i^<em>$与主成分$y_k^</em>$的相关系数的平方和等于$\lambda_k^*$</p>
<script type="math/tex; mode=display">
\sum\limits_{i=1}^{m} \rho^2(y_k^*,x_i^*) = \sum\limits_{i=1}^{m}\lambda_k^*e_{ik}^{*2} = \lambda_k^*,\ \ \ \ \ k= 1,2,...,m\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ (16.37)</script><p>（5）规范化随机变量$x_i^<em>$与所有主成分$y_k^</em>$的相关系数的平方和等于1</p>
<script type="math/tex; mode=display">
\sum\limits_{k=1}^{m} \rho^2(y_k^*,x_i^*) = \sum\limits_{k=1}^{m}\lambda_k^*e_{ik}^{*2} =1,\ \ \ \ \ i= 1,2,...,m\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ (16.38)</script><h1 id="16-2-样本主成分分析"><a href="#16-2-样本主成分分析" class="headerlink" title="16.2 样本主成分分析"></a>16.2 样本主成分分析</h1><p>在实际问题中，需要在观测数据上进行主成分分析，这就是样本主成分分析。样本主成分也和总体主成分具有相同的性质。</p>
<h2 id="16-2-1-样本主成分的定义和性质"><a href="#16-2-1-样本主成分的定义和性质" class="headerlink" title="16.2.1 样本主成分的定义和性质"></a>16.2.1 样本主成分的定义和性质</h2><p><strong>定义 16.4（样本主成分）</strong>  给定样本矩阵$X$。样本第一主成分$y_1 = a_1^Tx$是在$a_1^Ta_1 = 1$条件下，使得$a_1^Tx_j(j = 1,2,…,n)$的样本方差$a_1^TSa_1$最大的$x$的线性变换；样本第二主成分$y_2 = a_2^Tx$是在$a_2^Ta_2 = 1$和$a_2^Txj$与$a_1^Tx_j(j = 1,2,…,n)$的样本协方差$a_1^TSa_2 = 0$条件下，使得$a_2^Tx_j(j = 1,2,…,n)$的样本方差$a_2^TSa_2$最大的$x$的线性变换；一般地，样本第$i$主成分$y_i = a_i^Tx$是在$a_i^Ta_i = 1$和$a_i^Tx_j$与$a_k^Tx_j(k&lt;i,j = 1,2,…,n)$的样本协方差$a_k^TSa_i = 0$条件下，使得$a_i^Tx_j(j = 1,2,…,n)$的样本方差$a_i^TSa_i$最大的$x$的线性变换。</p>
<p>样本主成分与总体主成分具有同样的性质。只要以样本协方差矩阵$S$代替总体协方差矩阵$\Sigma$即可。总体主成分定理$16.2$及定理$16.3$对样本主成分依然成立。</p>
<p>在使用样本主成分时，一般假设样本数据是规范化的，即对样本矩阵作如下变换：</p>
<script type="math/tex; mode=display">
x_{ij}^* = \frac{x_{ij} - \bar{x}_i}{\sqrt{s_{ii}}}, \ \ \ \ \ i = 1,2,...,m;\ \ \ \ \ j = 1,2,...,n\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ (16.48)</script><p>其中</p>
<script type="math/tex; mode=display">
\bar{x}_i = \frac{1}{n}\sum\limits_{j=1}^{n}x_{ij}, \ \ \ \ \ i = 1,2,...,m</script><script type="math/tex; mode=display">
s_{ii} = \frac{1}{n - 1} \sum\limits_{j = 1}^{n} (x_{ij} - \bar{x}_i)^2, \ \ \ \ \ i = 1,2,...,m</script><p>样本协方差矩阵$S$就是样本相关矩阵$R$</p>
<script type="math/tex; mode=display">
R = \frac{1}{n-1}XX^T\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ (16.49)</script><p>样本协方差矩阵$S$是总体协方差矩阵$\Sigma$的无偏估计，样本相关矩阵$R$是总体相关矩阵的无偏估计，$S$的特征值和特征向量是$\Sigma$的特征值和特征向量的极大似然估计。</p>
<h2 id="16-2-2-相关矩阵的特征值分解算法"><a href="#16-2-2-相关矩阵的特征值分解算法" class="headerlink" title="16.2.2 相关矩阵的特征值分解算法"></a>16.2.2 相关矩阵的特征值分解算法</h2><p>给定样本矩阵$X$，利用数据的样本协方差矩阵或者样本相关矩阵的特征值分解进行主成分分析。具体步骤如下：</p>
<p>（1）对观测数据按式$(16.48)$进行规范化处理，得到规范化数据矩阵，仍以$X$表示。</p>
<p>（2）依据规范化数据矩阵，计算样本相关矩阵$R$</p>
<script type="math/tex; mode=display">
R = [r_ij]_{m \times m} = \frac{1}{n-1}XX^T</script><p>其中</p>
<script type="math/tex; mode=display">
r_{ij} = \frac{1}{n-1}\sum\limits_{t= 1}^n x_{il}x_{lj}, \ \ \ \ \ i,j = 1,2,...,m</script><p>（3）求样本相关矩阵$R$的$k$个特征值和对应的$k$个单位特征向量。</p>
<p>求解$R$的特征方程</p>
<script type="math/tex; mode=display">
|R - \lambda I| = 0</script><p>得$R$的$m$个特征值</p>
<script type="math/tex; mode=display">
\lambda_1 \geq \lambda_2 \geq...\geq\lambda_m</script><p>求方差贡献率$\sum\limits_{i = 1}^k \eta_i$达到预定值的主成分个数$k$。</p>
<p>求前$k$个特征值对应的单位特征向量</p>
<script type="math/tex; mode=display">
a_i = (a_{1i},a_{2i},...,a_{mi}), \ \ \ \ \ i = 1,2,...,k</script><p>（4）求$k$个样本主成分</p>
<p>以$k$个单位特征向量为系数进行线性变换，求出$k$个样本主成分</p>
<script type="math/tex; mode=display">
y_i = a_i^Tx, \ \ \ \ \ i = 1,2,...,k\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ (16.50)</script><p>（5）计算$k$个主成分$y_j$与原变量$x_i$的相关系数$\rho(x_i,y_j)$，以及$k$个主成分对原变量$x_i$的贡献率$\nu_i$。</p>
<p>（6）计算$n$个样本的$k$个主成分值</p>
<p>将规范化样本数据代入$k$个主成分式$(16.50)$，得到$n$个样本的主成分值。第$j$个样本$x_j = (x_{1j},x_{2j},…,x_{mj})^T$的第$i$主成分值是</p>
<script type="math/tex; mode=display">
y_{ij} = (a_{1i},a_{2i},...,a_{mi})(x_{1j},x_{2j},...,x_{mj})^T = \sum\limits_{l = 1}^m a_{li}x_{lj}</script><script type="math/tex; mode=display">
i = 1,2,...m, \ \ \ \ \ j = 1,2,...,n</script><p>主成分分析得到的结果可以用于其他机器学习方法的输入。</p>
<h2 id="16-2-3-数据矩阵的奇异值分解算法"><a href="#16-2-3-数据矩阵的奇异值分解算法" class="headerlink" title="16.2.3 数据矩阵的奇异值分解算法"></a>16.2.3 数据矩阵的奇异值分解算法</h2><p>给定样本矩阵$X$，利用数据矩阵奇异值分解进行主成分分析。</p>
<p><strong>算法 16.1（主成分分析算法）</strong></p>
<p><strong>输入</strong>：$m \times n$样本矩阵$X$，其每一行元素的均值为零；</p>
<p><strong>输出</strong>：$ k \times n $样本主成分矩阵$Y$。</p>
<p><strong>参数</strong>：主成分个数$k$</p>
<p>（1）构造新的$n \times m$矩阵</p>
<script type="math/tex; mode=display">
X^{'} = \frac{1}{\sqrt{n-1}}X^T</script><p>$X^{‘}$的每一列的均值为零。</p>
<p>（2）对矩阵$X^{‘}$进行截断奇异值分解，得到</p>
<script type="math/tex; mode=display">
X^{'} = U\Sigma V^T</script><p>有$k$个奇异值、奇异向量。矩阵$V^T$和$X$的乘积构成样本主成分矩阵。</p>
<p>（3）求$k \times n$样本主成分矩阵</p>
<script type="math/tex; mode=display">
Y = V^T X</script>
      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="http://example.com/2021/06/24/Statistical_Learning_Methods_Notes/%E7%AC%AC%E5%8D%81%E4%BA%94%E7%AB%A0-%E5%A5%87%E5%BC%82%E5%80%BC%E5%88%86%E8%A7%A3/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/posthead.jpg">
      <meta itemprop="name" content="Normal People">
      <meta itemprop="description" content="Get busy living or get busy dying">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Blog">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2021/06/24/Statistical_Learning_Methods_Notes/%E7%AC%AC%E5%8D%81%E4%BA%94%E7%AB%A0-%E5%A5%87%E5%BC%82%E5%80%BC%E5%88%86%E8%A7%A3/" class="post-title-link" itemprop="url">第十五章 奇异值分解</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>
              

              <time title="创建时间：2021-06-24 15:01:33 / 修改时间：15:24:35" itemprop="dateCreated datePublished" datetime="2021-06-24T15:01:33+08:00">2021-06-24</time>
            </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/%E7%BB%9F%E8%AE%A1%E5%AD%A6%E4%B9%A0%E6%96%B9%E6%B3%95/" itemprop="url" rel="index"><span itemprop="name">统计学习方法</span></a>
                </span>
            </span>

          
  
  <span class="post-meta-item">
    
      <span class="post-meta-item-icon">
        <i class="far fa-comment"></i>
      </span>
      <span class="post-meta-item-text">Valine：</span>
    
    <a title="valine" href="/2021/06/24/Statistical_Learning_Methods_Notes/%E7%AC%AC%E5%8D%81%E4%BA%94%E7%AB%A0-%E5%A5%87%E5%BC%82%E5%80%BC%E5%88%86%E8%A7%A3/#valine-comments" itemprop="discussionUrl">
      <span class="post-comments-count valine-comment-count" data-xid="/2021/06/24/Statistical_Learning_Methods_Notes/%E7%AC%AC%E5%8D%81%E4%BA%94%E7%AB%A0-%E5%A5%87%E5%BC%82%E5%80%BC%E5%88%86%E8%A7%A3/" itemprop="commentCount"></span>
    </a>
  </span>
  
  

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <p><strong>奇异值分解（singular value decomposition，SVD）</strong>是一种矩阵因子分解方法，是线性代数的概念，但在统计学习中被广泛使用，成为其重要工具。</p>
<p>任意一个$m \times n$矩阵，都可以表示为三个矩阵的乘积（因子分解）形式，分别是$m$阶正交矩阵、由降序排列的非负的对角线元素组成的$m \times n$矩形对角矩阵和$n$阶正交矩阵，称为该矩阵的奇异值分解。</p>
<p>矩阵的奇异值分解一定存在，但不唯一。</p>
<p>奇异值分解可以看作是矩阵数据压缩的一种方法，即用因子分解的方式近似地表示原始矩阵，这种近似是在平方损失意义下的最优近似。</p>
<h1 id="15-1-奇异值分解的定义与性质"><a href="#15-1-奇异值分解的定义与性质" class="headerlink" title="15.1 奇异值分解的定义与性质"></a>15.1 奇异值分解的定义与性质</h1><h2 id="15-1-1-定义与定理"><a href="#15-1-1-定义与定理" class="headerlink" title="15.1.1 定义与定理"></a>15.1.1 定义与定理</h2><p><strong>定义15.1（奇异值分解）</strong>  矩阵的奇异值分解是指，将一个非零的$m \times n$实矩阵$A, A \in R^{m \times n}$，表示为一下三个实矩阵乘积形式的运算，即进行矩阵的因子分解：</p>
<script type="math/tex; mode=display">
A = U \Sigma V^T \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ (15.1)</script><p>其中$U$是$m$阶<strong>正交矩阵（orthogonal matrix）</strong>，$V$是$n$阶正交矩阵，$\Sigma$是由降序排列的非负的对角线元素组成的$m \times n$<strong>矩形对角矩阵（rectangular diagonal matrix）</strong>，满足</p>
<script type="math/tex; mode=display">
UU^T = I</script><script type="math/tex; mode=display">
VV^T = I</script><script type="math/tex; mode=display">
\Sigma = diag(\sigma_1,\sigma_2,...,\sigma_p)</script><script type="math/tex; mode=display">
\sigma_1 \geq \sigma_2 \geq... \geq \sigma_p \geq 0</script><script type="math/tex; mode=display">
p = \min(m,n)</script><p>$U \Sigma V^T$称为矩阵$A$的<strong>奇异值分解（singular value decomposition，SVD）</strong>，$\sigma_i$称为矩阵$A$的<strong>奇异值（singular value）</strong>，$U$的列向量称为<strong>左奇异向量（left singular value）</strong>，$V$的列向量称为<strong>右奇异向量（right singular value）</strong>。</p>
<hr>
<p><strong>定理 15.1（奇异值分解基本定理）</strong>  若$A$为一$m \times n$实矩阵，$A \in R^{m\times n}$，则$A$的奇异值分解存在</p>
<script type="math/tex; mode=display">
A = U \Sigma V^T \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ (15.2)</script><p>其中$U$是$m$阶正交矩阵，$V$是$n$阶正交矩阵，$\Sigma$是$m \times n$矩形对角矩阵，其对角线元素非负 且按降序排列。</p>
<h2 id="15-1-2-紧奇异值分解与截断奇异值分解"><a href="#15-1-2-紧奇异值分解与截断奇异值分解" class="headerlink" title="15.1.2 紧奇异值分解与截断奇异值分解"></a>15.1.2 紧奇异值分解与截断奇异值分解</h2><p>定理15.1给出的奇异值分解</p>
<script type="math/tex; mode=display">
A = U \Sigma V^T</script><p>又称为矩阵的<strong>完全奇异值分解（full singular value decomposition）</strong>。实际常用的是奇异值分解的紧凑形式和截断形式。紧奇异值分解是与原始矩阵等秩的奇异值分解，截断奇异值分解是比原始矩阵低秩的奇异值分解。</p>
<ol>
<li><p><strong>紧奇异值分解</strong></p>
<p><strong>定义 15.2</strong>  设有$m \times n$实矩阵$A$，其秩为$rank(A) = r,r \leq min(m,n)$，则称$U_r\Sigma_r V_r^T$为$A$的紧奇异值分解（compact singular value decomposition），即</p>
<script type="math/tex; mode=display">
A =U_r\Sigma_r V_r^T \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ (15.18)</script><p>其中$U_r$是$m \times r$矩阵，$V_r$是$n \times r$矩阵，$\Sigma_r$是$r$阶对角矩阵；矩阵$U_r$由完全奇异值分解中$U$的前$r$列、矩阵$V_r$由$V$的前$r$列、矩阵$\Sigma_r$由$\Sigma$的前$r$个对角线元素得到。紧奇异值分解的对角矩阵$\Sigma_r$的秩与原始矩阵$A$的秩相等。</p>
</li>
</ol>
<hr>
<ol>
<li><strong>截断奇异值分解</strong></li>
</ol>
<p>再聚真的奇异值分解中，只取最大的$k$个奇异值（$k&lt;r$，$r$为矩阵的秩）对应的部分，就得到矩阵的截断奇异值分解。实际应用中提到矩阵的奇异值分解时，通常指截断奇异值分解。</p>
<p>定义 15.3  设$A$为$m \times n$实矩阵，其秩$rank(A) = r$，且$ 0 &lt; k &lt; r$，则称$U_k\Sigma_k V_k^T$为矩阵$A$的截断奇异值分解（truncated singular value decomposition）</p>
<script type="math/tex; mode=display">
A \approx U_k\Sigma_k V_k^T\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ (15.19)</script><p>其中$U_k$是$m \times k$矩阵，$V_k$是$n \times k$矩阵，$\Sigma_k$是$k$阶对角矩阵；矩阵$U_k$由完全奇异值分解中$U$的前$k$列、矩阵$V_k$由$V$的前$k$列、矩阵$\Sigma_k$由$\Sigma$的前$r$个对角线元素得到。对角矩阵$\Sigma_k$的秩比原始矩阵$A$的秩低。</p>
<p>在实际应用中，常常需要对矩阵的数据进行压缩，将其近似表示，奇异值分解提供了一种方法。紧奇异值分解对应着无损压缩，截断奇异值分解对应着有损压缩。</p>
<h2 id="15-1-3-几何解释"><a href="#15-1-3-几何解释" class="headerlink" title="15.1.3 几何解释"></a>15.1.3 几何解释</h2><p>从线性变换的角度理解奇异值分解，$m \times n$矩阵$A$表示从$n$维空间$R^n$到$m$维空间$R^m$的一个线性变换，</p>
<script type="math/tex; mode=display">
T : x \rightarrow Ax</script><p>$x \in R^n,Ax \in R^m$，$x$和$Ax$分别是各自空间的向量。</p>
<p>线性变换可以分解为三个简单的变换：</p>
<ul>
<li>一个坐标系的旋转或反射变换；</li>
<li>一个坐标轴的缩放变换；</li>
<li>另一个坐标系的旋转或反射变换。</li>
</ul>
<h2 id="15-1-4-主要性质"><a href="#15-1-4-主要性质" class="headerlink" title="15.1.4 主要性质"></a>15.1.4 主要性质</h2><p>（1）设矩阵$A$的奇异值分解为$A = U \Sigma V^T$，则以下关系成立：</p>
<script type="math/tex; mode=display">
A^TA = (U \Sigma V^T)^T(U \Sigma V^T) = V(\Sigma^T \Sigma)V^T\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ (15.20)</script><script type="math/tex; mode=display">
AA^T =(U \Sigma V^T)(U \Sigma V^T)^T = U(\Sigma \Sigma^T)U^T\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ (15.21)</script><p>也就是说，矩阵$A^TA$和矩阵$AA^T$的特征分解存在，且可以由矩阵$A$的奇异值分解的矩阵表示。$V$的列向量是$A^TA$的特征向量，$U$的列向量是$AA^T$的特征向量，$\Sigma$的奇异值是$A^TA$和$AA^T$的特征值的平方根。</p>
<p>（2）在矩阵$A$的奇异值分解中，奇异值、左奇异向量和右奇异向量之间存在对应关系。</p>
<p>由$A = U \Sigma V^T$易知</p>
<script type="math/tex; mode=display">
AV = U\Sigma</script><p>比较这一等式两端的第$j$列，得到</p>
<script type="math/tex; mode=display">
Av_j = \sigma_j u_j\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ (15.22)</script><p>这是矩阵$A$的右奇异向量和奇异值、左奇异向量的关系。</p>
<p>类似地，得到</p>
<script type="math/tex; mode=display">
A^T u_j = \sigma_jv_j, \ \ \ j = 1,2,...,n\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ (15.23)</script><script type="math/tex; mode=display">
A^Tu_j = 0,\ \ \ j = n+1,n+2,...,m</script><p>这是矩阵$A$的左奇异向量和奇异值、右奇异向量的关系。</p>
<p>（3）矩阵$A$的奇异值分解中，奇异值$\sigma_1,\sigma_2,…,\sigma_n$是唯一的，而矩阵$U$和$V$不是唯一的。</p>
<p>（4）矩阵$A$和$\Sigma$的秩相等，等于正奇异值$\sigma_i$的个数$r$（包含重复的奇异值）。</p>
<p>（5）</p>
<ul>
<li>矩阵$A$的$r$个右奇异向量$v_1,v_2,…,v_r$构成$A^T$的值域$R(A^T)$的一组标准正交基。</li>
<li>矩阵$A$的$n-r$个右奇异向量$v_{r+1},v_{r+2},…,v_n$构成$A$的零空间$N(A)$的一组标准正交基。</li>
<li>矩阵$A$的$r$个左奇异向量$u_1,u_2,…,u_r$构成值域$R(A)$的一组标准正交基。</li>
<li>矩阵$A$的$m-r$个左奇异向量$u_{r+1},u_{r+2},…,u_m$构成$A^T$的零空间$N(A^T)$的一组标准正交基。</li>
</ul>
<h1 id="15-2-奇异值分解的计算"><a href="#15-2-奇异值分解的计算" class="headerlink" title="15.2 奇异值分解的计算"></a>15.2 奇异值分解的计算</h1><p>矩阵$A$的奇异值分解可以通过求对称矩阵$A^TA$的特征值和特征向量得到。$A^TA$的特征向量构成正交矩阵$V$的列；$A^TA$的特征值$\lambda_j$的平方根为奇异值$\sigma_j$，即</p>
<script type="math/tex; mode=display">
\sigma_j = \sqrt{\lambda_j} \ \ \ j = 1,2,...,n</script><p>对其由大到小排列作为对角线元素，构成对角矩阵$\Sigma$；求正奇异值对应的左奇异向量，再求扩充的$A^T$的标准正交基，构成正交矩阵$U$的列。从而得到$A$的奇异值分解$A = U \Sigma V^T$。</p>
<p>（1）首先求$A^TA$的特征值和特征向量。</p>
<p>计算对称矩阵$W = A^TA$。</p>
<p>求解特征方程</p>
<script type="math/tex; mode=display">
(W-\lambda I)x = 0</script><p>得到特征值$\lambda_i$，并将特征值由大到小排列</p>
<script type="math/tex; mode=display">
\lambda_1  \geq \lambda_2 \geq ... \geq \lambda_n \geq 0</script><p>将特征值$\lambda_i(i= 1,2,…,n)$代入特征方程求得对应的特征向量。</p>
<p>（2）求$n$阶正交矩阵$V$</p>
<p>将特征向量单位化，得到单位特征向量$v_1,v_2,…,v_n$，构成$n$阶正交矩阵$V$；</p>
<script type="math/tex; mode=display">
V = [v_1,v_2...v_n]</script><p>（3）求$m \times n$对角矩阵$\Sigma$</p>
<p>计算$A$的奇异值</p>
<script type="math/tex; mode=display">
\sigma_j = \sqrt{\lambda_j} \ \ \ j = 1,2,...,n</script><p>构造$m \times n$矩形对角矩阵$\Sigma$，主对角元素是奇异值，其余元素是零，</p>
<script type="math/tex; mode=display">
\Sigma = diag(\sigma_1,\sigma_2,...,\sigma_n)</script><p>（4）求$m$阶正交矩阵$U$</p>
<p>对$A$的前$r$个正奇异值，令</p>
<script type="math/tex; mode=display">
u_j = \frac{1}{\sigma_j}Av_j, \ \ \ j = 1,2,...,r</script><p>得到</p>
<script type="math/tex; mode=display">
U_1 = [u_1,u_2,...,u_r]</script><p>求$A^T$的零空间的一组标准正交基$u_{r+1},r_{r+2},…,u_m$，令</p>
<script type="math/tex; mode=display">
U_2 = [u_{r+1},r_{r+2},...,u_m]</script><p>并令</p>
<script type="math/tex; mode=display">
U = [U_1,U_2]</script><p>（5）得到奇异值分解</p>
<script type="math/tex; mode=display">
A = U \Sigma V^T</script><p>实际应用的奇异值分解算法是通过求$A^TA$的特征值进行，但不直接计算$A^TA$。</p>
<h1 id="15-3-奇异值分解与矩阵近似"><a href="#15-3-奇异值分解与矩阵近似" class="headerlink" title="15.3 奇异值分解与矩阵近似"></a>15.3 奇异值分解与矩阵近似</h1><h2 id="15-3-1-弗罗贝尼乌斯范数"><a href="#15-3-1-弗罗贝尼乌斯范数" class="headerlink" title="15.3.1 弗罗贝尼乌斯范数"></a>15.3.1 弗罗贝尼乌斯范数</h2><p>奇异值分解也是一种矩阵近似的方法，这个近似是在弗罗贝尼乌斯范数（Frobenius norm）意义下的近似。矩阵的弗罗贝尼乌斯范数是向量的$L_2$范数的直接推广，对应着机器学习中的平方损失函数。</p>
<p><strong>定义 15.4（弗罗贝尼乌斯范数）</strong>  设矩阵$A \in R^{m \times n}$， $A = \left[ a_{ij} \right]_{m \times n}$，定义矩阵$A$的弗罗贝尼乌斯范数为</p>
<script type="math/tex; mode=display">
||A||_{F} = (\sum\limits_{i = 1}^{m} \sum\limits_{j = 1}^{n} ( a_{ij})^2 )^{ \frac{1}{2} }\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ (15.25)</script><p><strong>引理 15.1</strong>  设矩阵$A \in R^{m \times n}$，$A$的奇异值分解为$U \Sigma V^T$，其中$\Sigma = diag(\sigma_1,\sigma_2,…,\sigma_n)$，则</p>
<script type="math/tex; mode=display">
||A||_{F} = (\sigma_1^2,\sigma_2^2,...,\sigma_n^2)^{\frac{1}{2} }\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ (15.26)</script><h2 id="15-3-2-矩阵的最优近似"><a href="#15-3-2-矩阵的最优近似" class="headerlink" title="15.3.2 矩阵的最优近似"></a>15.3.2 矩阵的最优近似</h2><p>奇异值分解是在平方损失（弗罗贝尼乌斯范数）意义下对矩阵的最优近似，即数据压缩。</p>
<p><strong>定理 15.2</strong>  设矩阵$A \in R^{m \times n}$，矩阵的秩$rank(A) = r$，并设$\mathcal{M}$为$R^{m \times n}$中所有秩不超过$k$的矩阵集合，$ 0 &lt; k &lt;r$，则存在一个秩为$k$的矩阵$X \in \mathcal{M}$，使得</p>
<script type="math/tex; mode=display">
||A - X||_{F} = \min\limits_{ S \in \mathcal{M} } ||A -S||_{F} \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ (15.31)</script><p>称矩阵$X$为矩阵$A$在弗罗贝尼乌斯范数意义下的最优近似。</p>
<p><strong>定理 15.3</strong>  设矩阵$A \in R^{m \times n}$，矩阵的秩$rank(A) = r$，有奇异值分解$A = U \Sigma V^T$，并设$\mathcal{M}$为$R^{m\times n}$中所有秩不超过$k$的矩阵的集合，$0&lt;k&lt;r$，若秩为$k$的矩阵$X \in \mathcal{M}$满足</p>
<script type="math/tex; mode=display">
||A - X||_{F} = \min\limits_{S \in \mathcal{M} }||A -S||_{F}\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ (15.32)</script><p>则</p>
<script type="math/tex; mode=display">
||A - X||_{F} =( \sigma_{k+1}^2, \sigma_{k+2}^2,..., \sigma_n^2)^{ \frac{1}{2} }\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ (15.33)</script><p>特别地，若$A^{‘} = U \Sigma^{‘} V^T$，其中</p>
<script type="math/tex; mode=display">
\left[ \begin{matrix} 
\sigma_1 & & & & & \\  
 & ...& & & 0 & \\
 & & &\sigma_k & & \\
  & & & 0 & & \\
  & 0 & & & ...& \\
  & & & & & 0 \\
\end{matrix} \right] 

= \left[ \begin{matrix} 
\Sigma_k &0 \\ 
0&0
\end{matrix} \right]</script><p>则</p>
<script type="math/tex; mode=display">
||A-A^{'}||_F =(\sigma_{k+1}^2,\sigma_{k+2}^2,...,\sigma_n^2)^{\frac{1}{2}} =\min\limits_{S \in \mathcal{M}}||A -S||_F\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ (15.34)</script><p>定理 15.3 表明，在秩不超过$k$的$m\times n$矩阵的集合中，存在矩阵$A$的弗罗贝尼乌斯范数意义下的最优近似矩阵$X$。$A^{‘} = U \Sigma^{‘} V^T$是达到最优值的一个矩阵。</p>
<h1 id="15-3-3-矩阵的外积展开式"><a href="#15-3-3-矩阵的外积展开式" class="headerlink" title="15.3.3 矩阵的外积展开式"></a>15.3.3 矩阵的外积展开式</h1><p>矩阵$A$的奇异值分解$U\Sigma V^T$也可以由外积形式表示。事实上，若将$A$的奇异值分解看成矩阵$U\Sigma$和$V^T$的乘积，将$U\Sigma$按列向量分块，将$V^T$按行向量分块，即得</p>
<script type="math/tex; mode=display">
U\Sigma = [\sigma_1u_1 \ \ \sigma_1u_1 \ \ ... \ \ \ \sigma_1u_1]</script><script type="math/tex; mode=display">
V^T  =\left[ \begin{matrix} 
v_1^T\\
v_2^T\\
...\\
v_N^T
\end{matrix} \right]</script><p>则</p>
<script type="math/tex; mode=display">
A = \sigma_1u_1v_1^T + \sigma_2u_2v_2^T+...+\sigma_nu_nv_n^T\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ (15.45)</script><p>式$(15.45)$称为矩阵$A$的外积展开式，其中$u_kv_k^T$为$m\times n$矩阵，是列向量$u_k$和行向量$v_k^T$的外积，其第$i$行第$j$列元素为$u_k$的第$i$个元素与$v_k^T$的第$j$个元素的乘积。</p>
<p>$A$的外积展开式也可以写成下面的形式</p>
<script type="math/tex; mode=display">
A = \sum\limits_{k=1}^nA_k = \sum\limits_{k=1}^n \sigma_ku_kv_k^T\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ (15.46)</script><p>其中$A_k = \sigma_ku_kv_k^T$是$m \times n$矩阵。式$(15.46)$将矩阵$A$分解为矩阵的有序加权和。</p>
<p>由矩阵$A$的外积展开式知，若$A$的秩为$n$，则</p>
<script type="math/tex; mode=display">
A =\sigma_1u_1v_1^T + \sigma_2u_2v_2^T+...+\sigma_nu_nv_n^T\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ (15.47)</script><p>一般地，设矩阵</p>
<script type="math/tex; mode=display">
A_k =\sigma_1u_1v_1^T + \sigma_2u_2v_2^T+...+\sigma_ku_kv_k^T</script><p>则$A_k$的秩为$k$，并且$A_k$是秩为$k$的矩阵中在弗罗贝尼乌斯范数意义下$A$的最优近似矩阵。矩阵$A_k$就是$A$的截断奇异值分解。</p>
<p>由于通常奇异值$\sigma_i$递减很快，所以$k$取很小值时，$A_k$也可以对$A$有很好的近似。</p>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="http://example.com/2021/06/22/Statistical_Learning_Methods_Notes/%E7%AC%AC%E5%8D%81%E5%9B%9B%E7%AB%A0-%E8%81%9A%E7%B1%BB%E6%96%B9%E6%B3%95/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/posthead.jpg">
      <meta itemprop="name" content="Normal People">
      <meta itemprop="description" content="Get busy living or get busy dying">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Blog">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2021/06/22/Statistical_Learning_Methods_Notes/%E7%AC%AC%E5%8D%81%E5%9B%9B%E7%AB%A0-%E8%81%9A%E7%B1%BB%E6%96%B9%E6%B3%95/" class="post-title-link" itemprop="url">第十四章 聚类方法</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              <time title="创建时间：2021-06-22 15:28:05" itemprop="dateCreated datePublished" datetime="2021-06-22T15:28:05+08:00">2021-06-22</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">更新于</span>
                <time title="修改时间：2021-06-24 15:55:01" itemprop="dateModified" datetime="2021-06-24T15:55:01+08:00">2021-06-24</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/%E7%BB%9F%E8%AE%A1%E5%AD%A6%E4%B9%A0%E6%96%B9%E6%B3%95/" itemprop="url" rel="index"><span itemprop="name">统计学习方法</span></a>
                </span>
            </span>

          
  
  <span class="post-meta-item">
    
      <span class="post-meta-item-icon">
        <i class="far fa-comment"></i>
      </span>
      <span class="post-meta-item-text">Valine：</span>
    
    <a title="valine" href="/2021/06/22/Statistical_Learning_Methods_Notes/%E7%AC%AC%E5%8D%81%E5%9B%9B%E7%AB%A0-%E8%81%9A%E7%B1%BB%E6%96%B9%E6%B3%95/#valine-comments" itemprop="discussionUrl">
      <span class="post-comments-count valine-comment-count" data-xid="/2021/06/22/Statistical_Learning_Methods_Notes/%E7%AC%AC%E5%8D%81%E5%9B%9B%E7%AB%A0-%E8%81%9A%E7%B1%BB%E6%96%B9%E6%B3%95/" itemprop="commentCount"></span>
    </a>
  </span>
  
  

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <p>聚类时针对给定的样本，依据它们特征的相似度或距离，将其归并到若干个“类”或“簇”的数据分析问题。一个类是给定样本集合的一个子集。</p>
<p>直观上，相似的样本聚集在相同的类，不相似的样本分散在不同的类。</p>
<h1 id="14-1-聚类的基本概念"><a href="#14-1-聚类的基本概念" class="headerlink" title="14.1 聚类的基本概念"></a>14.1 聚类的基本概念</h1><p>包括样本之间的距离或相似度，类或簇，类与类之间的距离。</p>
<h2 id="14-1-1-相似度或距离"><a href="#14-1-1-相似度或距离" class="headerlink" title="14.1.1 相似度或距离"></a>14.1.1 相似度或距离</h2><p>聚类的核心概念是<strong>相似度（similarity）</strong>或<strong>距离（distance）</strong>，有多种相似度或距离的定义。因为相似度直接影响聚类的结果，所以其选择是聚类的根本问题。</p>
<script type="math/tex; mode=display">
X = [ x_{ij}]_{m \times n} = \left[ \begin{matrix} 
x_{11}& x_{12}&...&x_{1n}\\ 
x_{21}& x_{22}&...&x_{2n}\\ 
.& .&&.\\ 
.& .&&.\\ 
.& .&&.\\ 
x_{m1}& x_{m2}&...&x_{mn}\\ 
\end{matrix} \right]\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ (14.1)</script><p>矩阵的第$j$列表示第$j$个样本，$j=1,2,…n$；第$i$行表示第$i$个属性，$i = 1,2,…,m$；</p>
<p>矩阵元素$x_{ij}$表示第$j$个样本的第$i$个属性值，$i = 1,2,…,m;j = 1,2,…,n$。</p>
<hr>
<ol>
<li><strong>闵可夫斯基距离</strong></li>
</ol>
<p>在聚类中，可将样本集合看作是向量空间中点的集合，以该空间的距离表示样本之间的相似度。常用的距离有闵可夫斯基距离，特别是欧氏距离。闵可夫斯基距离越大相似度越小，距离越小相似度越大。</p>
<p><strong>定义 14.1</strong>  给定样本集合$X$，$X$是$m$维实数向量空间$R^m$中点的集合，其中$x_i,x_j \in X, x_i=(x_{1i},x_{2i},…,x_{mi})^T,x_i=(x_{1j},x_{2j},…,x_{mj})^T$，样本$x_i$与样本$x_j$的<strong>闵可夫斯基距离（Minkowski distance）</strong>定义为</p>
<script type="math/tex; mode=display">
d_{ij} = (\sum\limits_{k=1}^{m}|x_{ki} - x_{kj}|^p)^{\frac{1}{p}}\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ (14.2)</script><p>这里$p \geq 1$。当$p=2$时称为<strong>欧氏距离（Euclidean distance）</strong>，即</p>
<script type="math/tex; mode=display">
d_{ij} = (\sum\limits_{k=1}^{m}|x_{ki} - x_{kj}|^2)^{\frac{1}{2}}\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ (14.3)</script><p>当$p = 1$时称为<strong>曼哈顿距离（Manhattan distance）</strong>，即</p>
<script type="math/tex; mode=display">
d_{ij} = (\sum\limits_{k=1}^{m}|x_{ki} - x_{kj}|)\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ (14.4)</script><p>当$p = \infty$时称为<strong>切比雪夫距离（Chebyshev distance）</strong>，取各个坐标数值差的绝对值的最大值，即</p>
<script type="math/tex; mode=display">
d_{ij} = \max\limits_{k}|x_{ki} - x_{kj}|\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ (14.5)</script><hr>
<ol>
<li><strong>马哈拉诺比斯距离</strong></li>
</ol>
<p><strong>马哈拉诺比斯距离（Mahalanobis distance）</strong>，简称马氏距离，也是另一种常用的相似度，考虑各个分量（特征）之间的相关性并与各个分量尺度无关。马哈拉诺比斯距离越大相似度越小，距离越小相似度越大。</p>
<p><strong>定义 14.2</strong>   给定一个样本集合$X,X= [x{ij}]{m \times n}$，其中协方差矩阵记作$S$。样本$x_i$与样本$x_j$之间的马哈拉诺比斯距离$d_{ij}$定义为</p>
<script type="math/tex; mode=display">
d_{ij} = [(x_i-x_j)^T S^{-1}(x_i-x_j)]^{\frac{1}{2}}\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ (14.6)</script><p>其中</p>
<script type="math/tex; mode=display">
x_i=(x_{1i},x_{2i},...,x_{mi})^T,x_j=(x_{1j},x_{2j},...,x_{mj})^T\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ (14.7)</script><p>当$S$为单位矩阵时，即样本数据的各个分量互相独立且各个分量的方差为1时，由式$(14.6)$知马氏距离就是欧氏距离，所以马氏距离是欧式距离的推广。</p>
<ol>
<li><strong>相关系数</strong></li>
</ol>
<p>样本之间的相似度也可以用<strong>相关系数（correlation coefficient）</strong>来表示。相关系数的绝对值越接近于1，表示样本越相似；越接近于0，表示样本越不相似。</p>
<p><strong>定义 14.3</strong>  样本$x_i$与样本$x_j$之间的相关系数定义为</p>
<script type="math/tex; mode=display">
r_{ij} = \frac{\sum\limits_{k=1}^{m}(x_{ki} - \overline x_i)(x_{kj} - \overline x_j)}{[\sum\limits_{k=1}^{m}(x_{ki} - \overline x_i)^2 \sum\limits_{k=1}^{m}(x_{kj} - \overline x_j)^2]^{\frac{1}{2}}}\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ (14.8)</script><hr>
<p>其中</p>
<script type="math/tex; mode=display">
\overline x_i = \frac{1}{m}\sum\limits_{k=1}^{m}x_{ki}, \ \    \overline x_j = \frac{1}{m}\sum\limits_{k=1}^{m}x_{kj}</script><ol>
<li><strong>夹角余弦</strong></li>
</ol>
<p>样本之间的相似度也可以用<strong>夹角余弦（cosine）</strong>来表示。夹角余弦越接近于1，表示样本越相似；越接近于0，表示样本越不相似。</p>
<p><strong>定义 14.4</strong>  样本$x_i$与样本$x_j$之间的夹角余弦定义为</p>
<script type="math/tex; mode=display">
s_{ij} = \frac{\sum\limits_{k=1}^{m}x_{ki}x_{kj}}{[\sum\limits_{k=1}^{m}x_{ki}^2\sum\limits_{k=1}^{m}x_{kj} ^2]^{\frac{1}{2}}}\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ (14.9)</script><p>用距离度量相似度时，距离越小样本越相似；用相关系数时，相关系数越大样本越相似。注意不同相似度度量得到的结果并不一定一致。</p>
<h2 id="14-1-2-类或簇"><a href="#14-1-2-类或簇" class="headerlink" title="14.1.2 类或簇"></a>14.1.2 类或簇</h2><p>通过聚类得到的类或簇，本质是样本的子集。如果一个聚类方法假定一个样本只能属于一个类，或类的交集为空集，那么该方法称为<strong>硬聚类（hard clustering）</strong>方法。否则，如果一个样本可以属于多个类，或者类的交集不为空集，那么该方法称为<strong>软聚类（soft clustering）</strong>方法。</p>
<p>用$G$表示类或<strong>簇（cluster）</strong>，用$x_i,x_j$表示类中的样本，用$n_G$表示$G$中样本的个数，用$d_{ij}$表示样本$x_i$与样本$x_j$之间的距离。</p>
<hr>
<p><strong>定义 14.5</strong>  设$T$为给定的正数，若集合$G$中任意两个样本$x_i,x_j$，有</p>
<script type="math/tex; mode=display">
d_{ij} \leq T</script><p>则称$G$为一个类或簇。</p>
<hr>
<p><strong>定义 14.6</strong>  设$T$为给定的正数，若对集合$G$的任意样本$x_i$，一定存在$G$中的另一个样本$x_j$，使得</p>
<script type="math/tex; mode=display">
d_{ij} \leq T</script><p>则称$G$为一个类或簇。</p>
<hr>
<p><strong>定义 14.7</strong>  设$T$为给定的正数，若对集合$G$的任意一个样本$x_i$，$G$中的另一个样本$x_j$满足</p>
<script type="math/tex; mode=display">
\frac{1}{n_G-1} \sum\limits_{x_j \in G} d_{ij} \leq T</script><p>其中$n_G$为$G$中样本的个数，则称$G$为一个类或簇。</p>
<hr>
<p><strong>定义 14.8</strong>  设$T$和$V$为给定的两个正数，如果集合$G$中任意两个样本$x_i,x_j$的距离$d_{ij}$满足</p>
<script type="math/tex; mode=display">
\frac{1}{n_G(n_G-1)} \sum\limits_{x_i \in G}\sum\limits_{x_j \in G} d_{ij} \leq T</script><script type="math/tex; mode=display">
d_{ij} \leq V</script><p>则称$G$为一个类或簇。</p>
<hr>
<p>类的特征可以通过不同角度来刻画，常用的特征有下面三种：</p>
<p>（1）类的均值$\overline x_G$，又称为类的中心</p>
<script type="math/tex; mode=display">
\overline x_G =\frac{1}{n_G} \sum\limits_{a = 1}^{n_G} x_a\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ (14.10)</script><p>（2）类的<strong>直径（diameter）</strong>$D_G$</p>
<p>类的直径$D_G$是类中任意两个样本之间的最大距离，即</p>
<script type="math/tex; mode=display">
D_G = \max\limits_{x_i,x_j \in G}d_{ij}\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ (14.11)</script><p>（3）类的样本<strong>散布矩阵（scatter matrix）</strong>$A_G$与样本<strong>协方差矩阵（covariance matrix）</strong>$S_G$</p>
<p>类样本散布矩阵$A_G$为</p>
<script type="math/tex; mode=display">
A_G =\sum\limits_{i = 1}^{n_G}(x_i-\bar{x}_G)(x_i-\bar{x}_G)^T\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ (14.12)</script><p>样本协方差矩阵$S_G$为</p>
<script type="math/tex; mode=display">
S_G =\frac{1}{n_G - 1}A_G</script><script type="math/tex; mode=display">
=\frac{1}{n_G-1}\sum\limits_{i = 1}^{n_G}(x_i-\bar{x}_G)(x_i-\bar{x}_G)^T\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ (14.13)</script><h2 id="14-1-3-类与类之间的距离"><a href="#14-1-3-类与类之间的距离" class="headerlink" title="14.1.3 类与类之间的距离"></a>14.1.3 类与类之间的距离</h2><p>类$G_p$与类$G_q$之间的距离$D(p,q)$，也称为连接（linkage）。类与类之间的距离也有多种定义。</p>
<p>设类$G_p$包含$n_p$个样本，$G_q$包含$n_q$个样本，分别用$\bar{x}_p$和$\bar{x}_q$表示$G_p$和$G_q$的均值，即类的中心。</p>
<hr>
<p><strong>（1）最短距离或单链接（single linkage）</strong></p>
<p>定义类$G_p$的样本与类$G_q$的样本之间的最短距离为两类之间的距离</p>
<script type="math/tex; mode=display">
D_{pq} = \min\{d_{ij}|x_i \in G_p,x_j \in G_q\}\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ (14.14)</script><p><strong>（2）最长距离或完全连接（complete linkage）</strong></p>
<p>定义类$G_p$的样本与类$G_q$的样本之间的最长距离为两类之间的距离</p>
<script type="math/tex; mode=display">
D_{pq} = \max\{d_{ij}|x_i \in G_p,x_j \in G_q\}\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ (14.15)</script><p><strong>（3）中心距离</strong></p>
<p>定义类$G_p$与类$G_q$的中心之间的距离为两类之间的距离</p>
<script type="math/tex; mode=display">
D_{pq} = d_{\overline x_p\overline x_q}\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ (14.16)</script><p><strong>（4）平均距离</strong></p>
<p>定义类$G_p$与类$G_q$任意两个样本之间距离的平均值为两类之间的距离</p>
<script type="math/tex; mode=display">
D_{pq} = \frac{1}{n_p n_q}\sum\limits_{x_i \in G_p}\sum\limits_{x_j \in G_q}d_{ij}\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ (14.17)</script><h1 id="14-2-层次聚类"><a href="#14-2-层次聚类" class="headerlink" title="14.2 层次聚类"></a>14.2 层次聚类</h1><p>层次聚类假设类别之间存在层次结构，将样本聚到层次化的类中。</p>
<p>层次聚类又有<strong>聚合（agglomerative）</strong>或<strong>自下而上（bottom-up）聚类</strong>、<strong>分裂（divisive）</strong>或<strong>自上而下（top-down）聚类</strong>两种方法。</p>
<ul>
<li><p>聚合聚类开始将每个样本各自分到一个类；之后将相邻距离最近的两类合并，建立一个新的类，重复此操作直到满足停止条件；得到层次化的类别。</p>
</li>
<li><p>分裂聚类开始将所有样本分到一个类；之后将已有类中相距最远的样本分到两个新的类，重复此操作直到满足停止条件；得到层次化的类别。</p>
</li>
</ul>
<p>聚合聚类的具体过程如下：对于给定的样本集合，开始将每个样本分到一个类；然后按照一定规则，例如类间距离最小，将最满足规则条件的两个类进行合并；如此反复进行，每次减少一个类，直到满足停止条件，如所有样本聚为一类。</p>
<p>由此可知，聚合聚类需要预先确定下面三个要素：</p>
<ul>
<li>距离或相似度</li>
<li>合并规则</li>
<li>停止条件</li>
</ul>
<p><strong>算法 14.1（聚合聚类算法）</strong></p>
<p><strong>输入</strong>：$n$个样本组成的样本集合及样本之间的距离；</p>
<p><strong>输出</strong>：对样本集合的一个层次化聚类。</p>
<p>（1）计算$n$个样本两两之间的欧式距离$\{d_{ij}\}$，记作矩阵$D = [d_{ij}]_{n \times n}$。</p>
<p>（2）构造$n$个类，每个类只包含一个样本。</p>
<p>（3）合并类间距离最小的两个类，其中最短距离为类间距离，构建一个新类。</p>
<p>（4）计算新类与当前各类的距离。若类的个数为1，终止计算，否则回到步（3）。</p>
<h1 id="14-3-k-均值聚类"><a href="#14-3-k-均值聚类" class="headerlink" title="14.3 $k$均值聚类"></a>14.3 $k$均值聚类</h1><p>$k$均值聚类是基于样本集合划分的聚类算法。$k$均值聚类将样本集合划分为$k$个子集，构成$k$个类，将$n$个样本划分到$k$个类中，每个样本到其所属类的中心的距离最小。</p>
<h2 id="14-3-1-模型"><a href="#14-3-1-模型" class="headerlink" title="14.3.1 模型"></a>14.3.1 模型</h2><p>给定$n$个样本的集合$X = \{x_1,x_2,…,x_n\}$，每个样本由一个特征向量表示，特征向量的维数是$m$。$k$均值聚类的目标是将$n$个样本分到$k$个不同的类或簇中，这里假设$k &lt; n$。$k$个类$G_1,G_2,…,G_k$形成对样本集合$X$的划分，其中$G_i \bigcap G_j = \emptyset,\bigcup\limits_{i=1}^{k}G_i = X$。用$C$表示划分，一个划分对应着一个聚类结果。</p>
<p>划分$C$是一个多对一的函数。如果把每个样本用一个正数$i\in\{1,2,…,n\}$表示，每个类也用一个正数$l \in \{1,2,…,k\}$表示，那么划分或者聚类可以用函数$l=C(i)$表示。所以$k$均值聚类的模型是一个从样本到类的函数。</p>
<h2 id="14-3-2-策略"><a href="#14-3-2-策略" class="headerlink" title="14.3.2 策略"></a>14.3.2 策略</h2><p>$k$均值聚类归结为样本集合$X$的划分，或者从样本到类的函数的选择问题。$k$均值聚类的策略是通过损失函数的最小化选取最优的划分或函数$C^*$。</p>
<p>首先，采用<strong>欧氏距离平方（squared Euclidean distance）</strong>作为样本之间的距离$d(x_i,x_j)$</p>
<script type="math/tex; mode=display">
d(x_i,x_j) = \sum\limits_{k=1}^{m}(x_{ki} - x_{kj})^2\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ (14.18)</script><p>然后，定义样本与其所属类的中心之间的距离的总和为损失函数，即</p>
<script type="math/tex; mode=display">
W(C) =\sum\limits_{l=1}^{k}\sum\limits_{C(i) =l}||x_i-\bar{x}_l||^2\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ (14.19)</script><p>函数$W(C)$也称为能量，表示相同类中的样本相似的程度。</p>
<p>$k$均值聚类就是求解最优化问题：</p>
<script type="math/tex; mode=display">
C^* = \arg\min\limits_{C}W(C)</script><script type="math/tex; mode=display">
=\arg\min\limits_{C}\sum\limits_{l=1}^{k}\sum\limits_{C(i) =l}||x_i-\bar{x}_l||^2\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ (14.20)</script><p>相似的样本被聚到同类时，损失函数值最小，这个目标函数的优化能达到聚类的目的。</p>
<p>$k$均值聚类的最优解求解问题是NP困难问题。现实中采用迭代的方法求解。</p>
<h2 id="14-3-3-算法"><a href="#14-3-3-算法" class="headerlink" title="14.3.3 算法"></a>14.3.3 算法</h2><p>$k$均值聚类的算法是一个迭代的过程，每次迭代包括两个步骤。</p>
<ul>
<li>选择$k$个类的中心，将样本逐个指派到与其最近的中心的类中，得到一个聚类结果；</li>
<li>更新每个类的样本的均值，作为类的新的中心；</li>
</ul>
<p>重复以上步骤，直到收敛为止。</p>
<p><strong>算法 14.2（</strong>$k$<strong>均值聚类算法）</strong></p>
<p><strong>输入</strong>：$n$个样本的集合$X$；</p>
<p><strong>输出</strong>：样本集合的聚类$C^\cdot$。</p>
<p>​    （1）初始化。令$t=0$，随机选择$k$个样本点作为初始聚类中心$m^{(0)} = (m_1^{(0)},..,m_l^{(0)},…,m_k^{(0)})$。</p>
<p>​    （2）对样本进行聚类。对固定的类中心$m^{(t)} = (m_1^{(t)},..,m_l^{(t)},…,m_k^{(t)})$，其中$m_l^{(t)}$为类$G_t$的中心，计算每个样本到类中心的距离，将每个样本指派到与其最近的中心的类中，构成聚类结果$C^{(t)}$。</p>
<p>​    （3）计算新的类中心。对聚类结果$C^{(t)}$，计算当前各个类中的样本的均值，作为新的类中心$m^{(t+1)} = (m_1^{(t+1)},..,m_l^{(t+1)},…,m_k^{(t+1)})$。</p>
<p>​    （4）如果迭代收敛或符合停止条件，输出$C^* = C^{(t)}$。否则，令$t= t+1$，返回步（2）。</p>
<h2 id="14-3-4-算法特性"><a href="#14-3-4-算法特性" class="headerlink" title="14.3.4 算法特性"></a>14.3.4 算法特性</h2><ol>
<li><strong>总体特点</strong></li>
</ol>
<p>$k$均值聚类有以下特点：</p>
<ul>
<li>基本划分的聚类方法；</li>
<li>类别数$k$事先指定；</li>
<li>以欧式距离平方表示样本之间的距离，以中心或样本的均值表示类别；</li>
<li>以样本和其所属类的中心之间的距离的总和为最优化的目标函数；</li>
<li>得到的类别是平坦的、非层次化的；</li>
<li>算法是迭代算法，不能保证得到全局最优。</li>
</ul>
<ol>
<li><strong>收敛性</strong></li>
</ol>
<p>$k$均值聚类属于启发式方法，不能保证收敛到全局最优，初始中心的选择会直接影响聚类结果。</p>
<ol>
<li><strong>初始类的选择</strong></li>
</ol>
<p>选择不同的初始中心，会得到不同的聚类结果。</p>
<p>初始中心的选择，比如可以用层次聚类对样本进行聚类，得到$k$个类时停止。然后从每个类中选取一个与中心距离最近的点。</p>
<ol>
<li><strong>类别数$k$的选择</strong></li>
</ol>
<p>$k$均值聚类中的类别数$k$值需要预先指定，而在实际应用中最优的$k$值是不知道的。解决这个问题的一个方法是尝试用不同的$k$值聚类，检验各自得到聚类结果的质量，推测最优的$k$值。聚类结果的质量可以用类的平均直径来衡量。一般地，类别数变小时，平均直径会增加；类别数变大超过某个值以后，平均直径会不变；而这个值正是最优的$k$值。</p>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="http://example.com/2021/06/21/Statistical_Learning_Methods_Notes/%E7%AC%AC%E5%8D%81%E4%B8%89%E7%AB%A0-%E6%97%A0%E7%9B%91%E7%9D%A3%E5%AD%A6%E4%B9%A0%E6%A6%82%E8%AE%BA/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/posthead.jpg">
      <meta itemprop="name" content="Normal People">
      <meta itemprop="description" content="Get busy living or get busy dying">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Blog">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2021/06/21/Statistical_Learning_Methods_Notes/%E7%AC%AC%E5%8D%81%E4%B8%89%E7%AB%A0-%E6%97%A0%E7%9B%91%E7%9D%A3%E5%AD%A6%E4%B9%A0%E6%A6%82%E8%AE%BA/" class="post-title-link" itemprop="url">第十三章 无监督学习概论</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>
              

              <time title="创建时间：2021-06-21 20:01:55 / 修改时间：20:01:33" itemprop="dateCreated datePublished" datetime="2021-06-21T20:01:55+08:00">2021-06-21</time>
            </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/%E7%BB%9F%E8%AE%A1%E5%AD%A6%E4%B9%A0%E6%96%B9%E6%B3%95/" itemprop="url" rel="index"><span itemprop="name">统计学习方法</span></a>
                </span>
            </span>

          
  
  <span class="post-meta-item">
    
      <span class="post-meta-item-icon">
        <i class="far fa-comment"></i>
      </span>
      <span class="post-meta-item-text">Valine：</span>
    
    <a title="valine" href="/2021/06/21/Statistical_Learning_Methods_Notes/%E7%AC%AC%E5%8D%81%E4%B8%89%E7%AB%A0-%E6%97%A0%E7%9B%91%E7%9D%A3%E5%AD%A6%E4%B9%A0%E6%A6%82%E8%AE%BA/#valine-comments" itemprop="discussionUrl">
      <span class="post-comments-count valine-comment-count" data-xid="/2021/06/21/Statistical_Learning_Methods_Notes/%E7%AC%AC%E5%8D%81%E4%B8%89%E7%AB%A0-%E6%97%A0%E7%9B%91%E7%9D%A3%E5%AD%A6%E4%B9%A0%E6%A6%82%E8%AE%BA/" itemprop="commentCount"></span>
    </a>
  </span>
  
  

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h1 id="13-1-无监督学习基本原理"><a href="#13-1-无监督学习基本原理" class="headerlink" title="13.1 无监督学习基本原理"></a>13.1 无监督学习基本原理</h1><p>无监督学习是从无标注的数据中学习数据的统计规律或者说内在结构的机器学习，主要包括聚类、降维、概率估计。</p>
<p>假设训练数据集由$N$个样本组成，每个样本是一个$M$维向量。训练数据可以由一个矩阵表示，每一行对应一个特征，每一列对应一个样本。</p>
<p>无监督学习的基本想法是对给定数据（矩阵数据）进行某种“压缩”，从而找到数据的潜在结构。</p>
<ul>
<li>可以考虑发掘数据的纵向结构，把相似的样本聚到同类，即对数据进行聚类。</li>
<li>还可以考虑发掘数据的横向结构，把高维空间的向量转换为低维空间的向量，即对数据进行降维。</li>
<li>也可以同时考虑发掘数据的纵向与横向结构，假设数据由含有隐式结构的概率模型生成得到，从数据中学习该概率模型。</li>
</ul>
<h1 id="13-2-基本问题"><a href="#13-2-基本问题" class="headerlink" title="13.2 基本问题"></a>13.2 基本问题</h1><ol>
<li><strong>聚类</strong></li>
</ol>
<p><strong>聚类（clustering）</strong>是将样本集合中相似的样本（实例）分配到相同的类，不相似的样本分配到不同的类。聚类时，样本通常是欧式空间中的向量，类别不是事先给定，而是从数据中自动发现，但类别的个数通常是事先给定。样本之间的相似度或距离由应用决定。</p>
<ul>
<li>如果一个样本只能属于一个类，则称为<strong>硬聚类（hard clustering）</strong>；</li>
<li>如果一个样本可以属于多个类，则称为<strong>软聚类（soft clustering）</strong>。</li>
</ul>
<p>假设输入空间是欧式空间$X \subseteq R^d$，输出空间是类别集合$Z = \{1,2,…,k\}$。聚类的模型是函数$z = g_\theta(x)$或者条件概率分布$P_\theta(z|x)$，其中$x \in X$是样本的向量，$z \in Z$是样本的类别，$\theta$是参数。前者的函数是硬聚类模型，后者的条件概率分布是软聚类模型。</p>
<p>聚类的过程就是学习聚类模型的过程：    </p>
<ul>
<li>硬聚类时，每一个样本属于某一类$z_i = g_\theta(x_i),i=1,2,…,N$；</li>
<li>软聚类时，每一个样本依概率属于每一个类$P_\theta(z_i|x_i),i=1,2,…,N$。</li>
</ul>
<hr>
<ol>
<li><strong>降维</strong></li>
</ol>
<p><strong>降维（dimensionality reduction）</strong>是将训练数据中的样本（实例）从高维空间转换到低维空间。</p>
<p>假设样本原本存在于低维空间，或者近似地存在于低维空间，通过降维则可以更好地表示样本数据的结构，即更好地表示样本之间的关系。</p>
<p>高维空间通常是高维的欧式空间，而低维空间是低维的欧式空间或者<strong>流形（manifold）</strong>。</p>
<p>低维空间不是事先给定，而是从数据中自动发现，其维数通常是事先给定的。</p>
<p>从高维到低维的降维中，要保证样本中的信息损失最小。</p>
<p>降维有线性的降维和非线性的降维。</p>
<p>降维的过程就是学习降维模型的过程。降维时，每一个样本从高维向量转换为低维向量$z_i = g_\theta(x_i),i=1,2,…,N$。</p>
<hr>
<ol>
<li><strong>概率模型估计</strong></li>
</ol>
<p><strong>概率模型估计（probability model estimation）</strong>，简称概率估计，假设训练数据由一个概率模型生成，由训练数据学习概率模型的结构和参数。</p>
<p>概率模型的结构类型，或者说概率模型的集合事先给定，而模型的具体结构与参数从数据中自动学习。</p>
<p>学习的目标是找到最有可能生成数据的结构和参数。</p>
<p>概率模型包括混合模型、概率图模型等。概率图模型又包括有向图模型和无向图模型。</p>
<p>概率模型表示为条件概率分布$P_\theta(x|z)$，其中随机变量$x$表示观测数据，可以是连续变量也可以是离散变量；随机变量$z$表示隐式结构，是离散变量；随机变量$\theta$表示参数。</p>
<p>模型是混合模型时，$z$表示成分的个数；</p>
<p>模型是概率图模型时，$z$表示图的结构。</p>
<p>概率模型的一种特殊情况是隐式结构不存在，即满足$P_\theta(x|z) = P_\theta(x)$。这时条件概率分布估计变成概率分布估计，只要估计分布$P_\theta(x)$的参数即可。</p>
<h1 id="13-3-机器学习三要素"><a href="#13-3-机器学习三要素" class="headerlink" title="13.3 机器学习三要素"></a>13.3 机器学习三要素</h1><p>同监督学习一样，无监督学习也有三要素：模型、策略、算法。</p>
<ul>
<li><p>模型就是函数$z=g_\theta(x)$，条件概率分布$P_\theta(x|z)$，或条件概率分布$P_\theta(z|x)$，在聚类、降维、概率模型估计中拥有不同的形式。</p>
</li>
<li><p>策略在不同的问题中有不同的形式，但都可以表示为目标函数的优化。</p>
</li>
<li>算法通常是迭代算法，通过迭代达到目标函数的最优化，比如，梯度下降法。</li>
</ul>
<h1 id="13-4-无监督学习方法"><a href="#13-4-无监督学习方法" class="headerlink" title="13.4 无监督学习方法"></a>13.4 无监督学习方法</h1><ol>
<li>聚类</li>
</ol>
<p>聚类主要用于数据分析，也可以用于监督学习的前处理。</p>
<ol>
<li>降维</li>
</ol>
<p>降维主要用于数据分析，也可以用于监督学习的前处理。降维可以帮助发现高维数据中的统计规律。数据是连续变量表示的。</p>
<ol>
<li>话题分析</li>
</ol>
<p>略。</p>
<ol>
<li>图分析</li>
</ol>
<p><strong>图分析（graph analytics）</strong>的目的是发掘隐藏在图中的统计规律或潜在结构。</p>
<p><strong>链接分析（link analysis）</strong>是图分析的一种，包括PageRank算法，主要是发现有向图中的重要节点。</p>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="http://example.com/2021/06/18/Statistical_Learning_Methods_Notes/%E7%AC%AC%E4%B9%9D%E7%AB%A0-EM%E7%AE%97%E6%B3%95%E5%8F%8A%E6%8E%A8%E5%B9%BF/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/posthead.jpg">
      <meta itemprop="name" content="Normal People">
      <meta itemprop="description" content="Get busy living or get busy dying">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Blog">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2021/06/18/Statistical_Learning_Methods_Notes/%E7%AC%AC%E4%B9%9D%E7%AB%A0-EM%E7%AE%97%E6%B3%95%E5%8F%8A%E6%8E%A8%E5%B9%BF/" class="post-title-link" itemprop="url">第九章 EM算法及推广</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>
              

              <time title="创建时间：2021-06-18 16:36:10 / 修改时间：16:35:44" itemprop="dateCreated datePublished" datetime="2021-06-18T16:36:10+08:00">2021-06-18</time>
            </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/%E7%BB%9F%E8%AE%A1%E5%AD%A6%E4%B9%A0%E6%96%B9%E6%B3%95/" itemprop="url" rel="index"><span itemprop="name">统计学习方法</span></a>
                </span>
            </span>

          
  
  <span class="post-meta-item">
    
      <span class="post-meta-item-icon">
        <i class="far fa-comment"></i>
      </span>
      <span class="post-meta-item-text">Valine：</span>
    
    <a title="valine" href="/2021/06/18/Statistical_Learning_Methods_Notes/%E7%AC%AC%E4%B9%9D%E7%AB%A0-EM%E7%AE%97%E6%B3%95%E5%8F%8A%E6%8E%A8%E5%B9%BF/#valine-comments" itemprop="discussionUrl">
      <span class="post-comments-count valine-comment-count" data-xid="/2021/06/18/Statistical_Learning_Methods_Notes/%E7%AC%AC%E4%B9%9D%E7%AB%A0-EM%E7%AE%97%E6%B3%95%E5%8F%8A%E6%8E%A8%E5%B9%BF/" itemprop="commentCount"></span>
    </a>
  </span>
  
  

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <p>EM算法是一种迭代算法，用于含有<strong>隐变量（hidden variable）</strong>的概率模型参数的极大似然估计，或极大后验概率估计。</p>
<p>EM算法的每次迭代由两步组成：    </p>
<ul>
<li>E步，求<strong>期望（expectation）</strong>；</li>
<li>M步，求<strong>极大（maximization）</strong>。</li>
</ul>
<p>所以这一算法称为<strong>期望极大算法（expectation maximization algorithm）</strong>，简称EM算法。</p>
<h1 id="9-1-EM算法的引入"><a href="#9-1-EM算法的引入" class="headerlink" title="9.1 EM算法的引入"></a>9.1 EM算法的引入</h1><p>概率模型有时既含有<strong>观测变量（observable variable）</strong>，又含有隐变量或<strong>潜在变量（latent variable）</strong>。如果概率模型的变量都是观测变量，那么给定数据，可以直接用极大似然估计发，或贝叶斯估计法估计模型参数。但是，当模型含有隐变量时，就不能简单地使用这些估计方法。EM算法就是含有隐变量的概率模型参数的极大似然估计，或极大后验概率估计。</p>
<h2 id="9-1-1-EM算法"><a href="#9-1-1-EM算法" class="headerlink" title="9.1.1 EM算法"></a>9.1.1 EM算法</h2><p>EM算法与初值的选择有关，选择不同的初值可能得到不同的参数估计值。</p>
<p>一般地，用$Y$表示观测随机变量的数据，$Z$表示隐随机变量的数据。$Y$和$Z$连在一起称为<strong>完全数据（complete-data）</strong>，观测数据$Y$又称为<strong>不完全数据（incomplete-data）</strong>。假设给定观测数据$Y$，其概率分布是$P(Y|\theta)$，其中$\theta$是需要估计的模型参数，那么不完全数据$Y$的似然函数是$P(Y|\theta)$，对数似然函数$L(\theta) = \log P(Y|\theta)$；假设$Y$和$Z$的联合概率分布是$P(Y,Z|\theta)$，那么完全数据的对数似然函数是$\log P(Y,Z|\theta)$。</p>
<p>EM算法通过迭代求$L(\theta) = \log P(Y|\theta)$的极大似然估计。每次迭代都包含两步：E步，求期望；M步，求极大化。</p>
<p><strong>算法 9.1（EM算法）</strong></p>
<p>输入：观测变量数据$Y$，隐变量数据$Z$，联合分布$P(Y,Z|\theta)$，条件分布$P(Z|Y,\theta)$；</p>
<p><strong>输出</strong>：模型参数$\theta$。</p>
<p>​    （1）选择参数的初值$\theta^{(0)}$，开始迭代；</p>
<p>​    （2）E步：记$\theta^{(i)}$为第$i$次迭代参数$\theta$的估计值，在第$i+1$次迭代的E步，计算</p>
<script type="math/tex; mode=display">
Q(\theta,\theta^{(i)}) = E_Z[\log P(Y,Z|\theta)|Y,\theta^{(i)}]</script><script type="math/tex; mode=display">
\ \ \ \ \ \ \ \ \ \ \  \ \ \ \ \ \ \ \ \ \ \  \ \ \ \ \ \ \ \ \ \ \  \ \ \ \ \ \ \ \ \ \ \ =\sum\limits_{Z} \log P(Y,Z|\theta)P(Z|Y,\theta)\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ (9.9)</script><p>这里，$P(Z|Y,\theta)$是在给定观测数据$Y$和当前的参数估计$\theta^{(i)}$下隐变量数据$Z$的条件概率分布；</p>
<p>​    （3）M步：求使$Q(\theta,\theta^{(i)})$极大化的$\theta$，确定第$i+1$次迭代的参数的估计值$\theta^{(i+1)}$</p>
<script type="math/tex; mode=display">
\theta^{(i+1)} = \arg\max\limits_{\theta}Q(\theta,\theta^{(i)})\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ (9.10)</script><p>​    （4）重复第（2）步和第（3）步，直到收敛。</p>
<p>式$(9.9)$的函数$Q(\theta,\theta^{(i)})$是EM算法的核心，称为$Q$<strong>函数（Q function）</strong>。</p>
<p><strong>定义 9.1（</strong>$Q$<strong>函数）</strong>  完全数据的对数似然函数$\log P(Y,Z|\theta)$关于在给定观测数据$Y$和当前参数$\theta^{(i)}$下对未观测数据$Z$的条件概率分布$P(Z|Y,\theta^{(i)})$的期望称为$Q$函数，即</p>
<script type="math/tex; mode=display">
Q(\theta,\theta^{(i)}) = E_Z[\log P(Y,Z|\theta)|Y,\theta^{(i)}]\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ (9.11)</script><p>关于EM算法的几点说明：</p>
<ul>
<li><p><strong>步骤（1）</strong> 参数的初值可以任意选择，但需要注意EM算法对初值是敏感的。</p>
</li>
<li><p><strong>步骤（2）</strong> E步求$Q(\theta,\theta^{(i)})$。$Q$函数式中$Z$是未观测数据，$Y$是观测数据。注意，$Q(\theta,\theta^{(i)})$的第一个变元表示要极大化的参数，第二个变元表示参数的当前估计值。每次迭代实际在求$Q$函数及其极大。</p>
</li>
<li><p><strong>步骤（3）</strong> M步求$Q(\theta,\theta^{(i)})$的极大化，得到$\theta^{(i+1)}$，完成一次迭代$\theta^{(i)} \longrightarrow \theta^{(i+1)}$。</p>
</li>
<li><p><strong>步骤（4）</strong>给出停止迭代的条件，一般是对较小的正数$\epsilon_1,\epsilon_2$，若满足</p>
</li>
</ul>
<script type="math/tex; mode=display">
||\theta^{(i+1)} - \theta^{(i)}|| < \epsilon_1\ \ \  或 \ \ \ ||Q(\theta^{(i+1)},\theta^{(i)})-Q(\theta^{(i)},\theta^{(i)})|| < \epsilon_2</script><p>则停止迭代。</p>
<h2 id="9-1-2-EM算法的导出"><a href="#9-1-2-EM算法的导出" class="headerlink" title="9.1.2 EM算法的导出"></a>9.1.2 EM算法的导出</h2><p>对一个含有隐变量的概率模型，目标是极大化观测数据（不完全数据）$Y$关于参数$\theta$的对数似然函数，即极大化</p>
<script type="math/tex; mode=display">
L(\theta) = \log P(Y|\theta) = \log\sum\limits_{Z}P(Y,Z|\theta)</script><script type="math/tex; mode=display">
\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ = \log(\sum\limits_{Z} P(Y|Z,\theta)P(Z|\theta))\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ (9.12)</script><p>这一极大化的主要困难是式$(9.12)$中有未观测数据并有包含和（或积分）的对数。</p>
<p>事实上，EM算法是通过迭代逐步近似极大化$L(\theta)$的。假设在第$i$次迭代后$\theta$的估计值是$\theta^{(i)}$。我们希望新估计值$\theta$能使$L(\theta)$增加，即$L(\theta) &gt; L(\theta^{(i)})$，并逐步达到极大值。为此，考虑两者的差：</p>
<script type="math/tex; mode=display">
L(\theta) - L(\theta^{(i)}) = \log(\sum\limits_{Z} P(Y|Z,\theta)P(Z|\theta)) - \log P(Y|\theta^{(i)})</script><p>利用$Jensen$不等式（Jensen inequality）得到其下界：</p>
<script type="math/tex; mode=display">
L(\theta) - L(\theta^{(i)}) = \log(\sum\limits_{Z} P(Y|Z,\theta)P(Z|\theta)) - \log P(Y|\theta^{(i)})</script><script type="math/tex; mode=display">
\geq \sum\limits_{Z} P(Z|Y,\theta^{(i)})\log \frac{P(Y|Z,\theta)P(Z|\theta)}{P(Z|Y,\theta^{(i)})}- \log P(Y|\theta^{(i)})</script><script type="math/tex; mode=display">
= \sum\limits_{Z} P(Z|Y,\theta^{(i)})\log \frac{P(Y|Z,\theta)P(Z|\theta)}{P(Z|Y,\theta^{(i)})P(Y|\theta^{(i)})}</script><p>令</p>
<script type="math/tex; mode=display">
B(\theta,\theta^{(i)}) \hat= L(\theta^{(i)}) +\sum\limits_{Z} P(Z|Y,\theta^{(i)})\log \frac{P(Y|Z,\theta)P(Z|\theta)}{P(Z|Y,\theta^{(i)})P(Y|\theta^{(i)})}\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ (9.13)</script><p>则</p>
<script type="math/tex; mode=display">
L(\theta) \geq B(\theta,\theta^{(i)})\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ (9.14)</script><p>即函数$B(\theta,\theta^{(i)})$是$L(\theta)$的一个下界，而且由式$(9.13)$可知，</p>
<script type="math/tex; mode=display">
L(\theta^{(i)}) = B(\theta^{(i)},\theta^{(i)})\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ (9.15)</script><p>因此，任何可以使$B(\theta,\theta^{(i)})$增大的$\theta$，也可以使$L(\theta)$增大。为了使$L(\theta)$有尽可能大的增长，选择$\theta^{(i+1)}$使$B(\theta,\theta^{(i)})$达到极大，即</p>
<script type="math/tex; mode=display">
\theta^{(i+1)} = \arg\max\limits_{\theta}B(\theta,\theta^{(i)})\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ (9.16)</script><p>现在求$\theta^{(i+1)}$的表达式。省去对$\theta$的极大化而言是常数的项，由式$(9.16)$、式$(9.13)$即式$(9.10)$，有</p>
<script type="math/tex; mode=display">
\theta^{(i+1)} = \arg\max\limits_{\theta}(L(\theta^{(i)}) +\sum\limits_{Z} P(Z|Y,\theta^{(i)})\log \frac{c}{P(Z|Y,\theta^{(i)})P(Y|\theta^{(i)})})</script><script type="math/tex; mode=display">
=\arg\max\limits_{\theta}(\sum\limits_{Z} P(Z|Y,\theta^{(i)})\log P(Y|Z,\theta)P(Z|\theta))</script><script type="math/tex; mode=display">
=\arg\max\limits_{\theta} (\sum\limits_{Z} P(Z|Y,\theta^{(i)})\log P(Y,Z|\theta))</script><script type="math/tex; mode=display">
= \arg\max\limits_{\theta}Q(\theta,\theta^{(i)})\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ (9.17)</script><p>式$(9.17)$等价于EM算法的一次迭代，即求$Q$函数及其极大化。EM算法是通过不断求解下界的极大化逼近求解对数似然函数极大化的算法。</p>
<p>EM算法不能保证找到全局最优值。</p>
<h2 id="9-1-3-EM算法在无监督学习中的应用"><a href="#9-1-3-EM算法在无监督学习中的应用" class="headerlink" title="9.1.3 EM算法在无监督学习中的应用"></a>9.1.3 EM算法在无监督学习中的应用</h2><p>EM算法可以用于生成模型的无监督学习。生成模型由联合概率分布$P(X,Y)$表示，可以认为无监督学习训练数据是联合概率分布产生的数据。$X$为观测数据，$Y$为未观测数据。</p>
<h1 id="9-2-EM算法的收敛性"><a href="#9-2-EM算法的收敛性" class="headerlink" title="9.2 EM算法的收敛性"></a>9.2 EM算法的收敛性</h1><p><strong>定理 9.1</strong>  设$P(Y|\theta)$为观察数据的似然函数，$\theta^{(i)}(i=1,2,…)$为EM算法得到的参数估计序列，$P(Y|\theta^{(i)})(i=1,2,…)$为对应的似然函数序列，则$P(Y|\theta^{(i)})$是单调递增的，即</p>
<script type="math/tex; mode=display">
P(Y|\theta^{(i+1)}) \geq P(Y|\theta^{(i)})\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ (9.18)</script><p><strong>定理 9.2</strong>  设$L(\theta) = \log P(Y|\theta)$为观测数据的对数似然函数，$\theta^{(i)}(i=1,2,…)$为EM算法得到的参数估计序列，$L(\theta^{(i)})(i=1,2,…)$为对应的对数似然函数序列。    </p>
<p>​    （1）如果$P(Y|\theta)$有上界，则$L(\theta^{(i)}) = \log P(Y|\theta^{(i)})$收敛到某一值$L^*$；</p>
<p>​    （2）在函数$Q(\theta,\theta^{‘})$与$L(\theta)$满足一定条件下，由EM算法得到的参数估计序列$\theta^{(i)}$的收敛值$\theta^{*}$是$L(\theta)$的稳定点。</p>
<p>EM算法的收敛性包含关于对数似然函数序列$L(\theta^{(i)})$的收敛性和关于参数估计序列$\theta^{(i)}$的收敛性两层意思，前者并不蕴含后者。此外，定理只能保证参数估计序列收敛到对数似然函数序列的稳定点，不能保证收敛到极大值点。所以在应用中，初值的选择变得非常重要，常用的办法是选取几个不同的初值进行迭代，然后对得到的各个估计值加以比较，从中选择最好的。</p>
<h1 id="9-3-EM算法在高斯混合模型学习中的应用"><a href="#9-3-EM算法在高斯混合模型学习中的应用" class="headerlink" title="9.3 EM算法在高斯混合模型学习中的应用"></a>9.3 EM算法在高斯混合模型学习中的应用</h1><p>EM算法是学习<strong>高斯混合模型（Gaussian mixture model）</strong>的有效方法。</p>
<h2 id="9-3-1-高斯混合模型"><a href="#9-3-1-高斯混合模型" class="headerlink" title="9.3.1 高斯混合模型"></a>9.3.1 高斯混合模型</h2><p><strong>定义 9.2（高斯混合模型）</strong>   高斯混合模型是指具有如下形式的概率分布模型：</p>
<script type="math/tex; mode=display">
P(y|\theta) = \sum\limits_{k=1}^{K}\alpha_{k}\phi(y|\theta_k)\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ (9.24)</script><p>其中，$\alpha_k$是系数，$\alpha_k \geq 0$，$\sum\limits_{k=1}^{K}\alpha_{k} = 1$；$\phi(y|\theta_k)$是高斯分布密度，$\theta_k = (\mu_k,\sigma_k^2)$，</p>
<script type="math/tex; mode=display">
\phi(y|\theta_k) = \frac{1}{\sqrt{2\pi}\sigma_k} \exp(-\frac{(y-\mu_k)^2}{2\sigma_k^2})\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ (9.25)</script><p>称为第$k$个分模型。</p>
<p>一般混合模型可以由任意概率分布密度代替式$(9.25)$中的高斯分布密度。</p>
<h2 id="9-3-2-高斯混合模型参数估计的EM算法"><a href="#9-3-2-高斯混合模型参数估计的EM算法" class="headerlink" title="9.3.2 高斯混合模型参数估计的EM算法"></a>9.3.2 高斯混合模型参数估计的EM算法</h2><p><strong>算法 9.2（高斯混合模型参数估计的EM算法）</strong></p>
<p><strong>输入</strong>：观测数据$y_1,y_2,…,y_N$，高斯混合模型；</p>
<p><strong>输出</strong>：高斯混合模型参数。</p>
<p>​    （1）取参数的初始值开始迭代；</p>
<p>​    （2）E步：依据当前模型参数，计算分模型$k$对观测数据$y_j$的响应度</p>
<script type="math/tex; mode=display">
\hat \gamma_{jk} = \frac{\alpha_{k}\phi(y_j|\theta_k)}{\sum\limits_{k=1}^{K}\alpha_{k}\phi(y_j|\theta_k)},\ \ \ j=1,2,..,N;\ \ \ k=1,2,...,K</script><p>​    （3）M步：计算新一轮迭代的模型参数</p>
<script type="math/tex; mode=display">
\hat \mu_k = \frac{\sum\limits_{j=1}^{N}\hat \gamma_{jk}y_j}{\sum\limits_{j=1}^{N}\hat \gamma_{jk}},\ \ \ k=1,2,..,K</script><script type="math/tex; mode=display">
\hat \sigma_k^2 = \frac{\sum\limits_{j=1}^{N}\hat \gamma_{jk}(y_i - \mu_k)^2}{\sum\limits_{j=1}^{N}\hat \gamma_{jk}},\ \ \ k=1,2,..,K</script><script type="math/tex; mode=display">
\hat \alpha_k = \frac{\sum\limits_{j=1}^{N}\hat \gamma_{jk}}{N},\ \ \ k=1,2,..,K</script><p>​    （4）重复第（2）步和第（3）步，直到收敛。</p>
<h1 id="9-4-EM算法的推广"><a href="#9-4-EM算法的推广" class="headerlink" title="9.4 EM算法的推广"></a>9.4 EM算法的推广</h1><p>EM算法还可以解释为$F$<strong>函数（F function）</strong>的<strong>极大-极大算法（maximization-maximization algorithm）</strong>，基于这个解释有若干变形与推广，如<strong>广义期望极大（generalized expectation maximization，GEM）</strong>算法。</p>
<h2 id="9-4-1-F-函数的极大-极大算法"><a href="#9-4-1-F-函数的极大-极大算法" class="headerlink" title="9.4.1 $F$函数的极大-极大算法"></a>9.4.1 $F$函数的极大-极大算法</h2><p><strong>定义 9.3（</strong>$F$<strong>函数）</strong>  假设隐变量数据$Z$的概率分布为$\tilde{P}(Z)$，定义分布$\tilde{P}$与参数$\theta$的函数$F(\tilde{P},\theta)$如下：</p>
<script type="math/tex; mode=display">
F(\tilde{P},\theta) = E_{\tilde{P}}[\log P(Y,Z|\theta)] + H(\tilde{P})\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ (9.33)</script><p>称为$F$函数。式中$H(\tilde{P}) = - E_{\tilde{P}}\log \tilde{P}(Z)$是分布$\tilde{P}(Z)$的熵。</p>
<hr>
<p><strong>引理 9.1</strong>  对于固定的$\theta$，存在唯一的分布$\tilde{P}_\theta$极大化$F(\tilde{P},\theta)$，这时$\tilde{P}_\theta$由下式给出：</p>
<script type="math/tex; mode=display">
\tilde{P}_\theta(Z) = P(Z|Y,\theta)\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ (9.34)</script><p>并且$\tilde{P}_\theta$随$\theta$连续变化。</p>
<hr>
<p><strong>引理 9.2</strong>  若$\tilde{P}_\theta(Z) = P(Z|Y,\theta)$，则</p>
<script type="math/tex; mode=display">
F(\tilde{P},\theta) = \log P(Y|\theta)\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ (9.36)</script><hr>
<p><strong>定理 9.3</strong>  设$L(\theta) = \log P(Y|\theta)$为观测数据的对数似然函数，$\theta^{(i)},i=1,2,…$，为EM算法得到的参数估计序列，函数$F(\tilde{P},\theta)$由式$(9.33)$定义。如果$F(\tilde{P},\theta)$在$\tilde{P}^<em>$和$\theta^</em>$有局部极大值，那么$L(\theta)$也在$\theta^<em>$有局部极大值。类似地，如果$F(\tilde{P},\theta)$在$\tilde{P}^</em>$和$\theta^<em>$达到全局最大值，那么$L(\theta)$也在$\theta^</em>$达到全局最大值。</p>
<hr>
<p><strong>定理 9.4</strong>  EM算法的一次迭代可由$F$函数的极大-极大算法实现。</p>
<p>设$\theta^{(i)}$为第$i$次迭代参数$\theta$的估计，$\tilde{P}^{(i)}$为第$i$次迭代函数$\tilde{P}$的估计。在第$i+1$次迭代的两步为：</p>
<p>​    （1）对固定的$\theta^{(i)}$，求$\tilde{P}^{(i+1)}$使$F(\tilde{P},\theta^{(i)})$极大化；</p>
<p>​    （2）对固定的$\tilde{P}^{(i+1)}$,求$\theta^{(i+1)}$使$F(\tilde{P}^{(i+1)},\theta)$极大化。</p>
<h2 id="9-4-2-GEM算法"><a href="#9-4-2-GEM算法" class="headerlink" title="9.4.2 GEM算法"></a>9.4.2 GEM算法</h2><p><strong>算法 9.3（GEM算法1）</strong></p>
<p><strong>输入</strong>：观测数据，$F$函数；</p>
<p><strong>输出</strong>：模型参数。</p>
<p>​    （1）初始化参数$\theta^{(0)}$，开始迭代。</p>
<p>​    （2）第$i+1$次迭代，第一步：记$\theta^{(i)}$为参数$\theta$的估计值，$\tilde{P}^{(i)}$为函数$\tilde{P}$的估计，求$\tilde{P}^{(i+1)}$使$\tilde{P}$极大化$F(\tilde{P},\theta^{(i)})$；</p>
<p>​    （3）第二步：求$\theta^{(i+1)}$使$F(\tilde{P}^{(i+1)},\theta)$极大化；</p>
<p>​    （4）重复（2）和（3），直到收敛。</p>
<p>在GEM算法1中，有时求$Q(\theta,\theta^{(i)})$的极大化是很困难的。下面介绍GEM算法2和GEM算法3.</p>
<hr>
<p><strong>算法 9.4（GEM算法2）</strong></p>
<p><strong>输入</strong>：观测数据，$Q$函数；</p>
<p><strong>输出</strong>：模型参数。</p>
<p>​    （1）初始化参数$\theta^{(0)}$，开始迭代。</p>
<p>​    （2）第$i+1$次迭代，第一步：记$\theta^{(i)}$为参数$\theta$的估计值，计算</p>
<script type="math/tex; mode=display">
Q(\theta,\theta^{(i)}) = E_Z[\log P(Y,Z|\theta)|Y,\theta^{(i)}]</script><script type="math/tex; mode=display">
\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ =\sum\limits_{Z} \log P(Y,Z|\theta)P(Z|Y,\theta)</script><p>​    （3）第二步：求$\theta^{(i+1)}$使</p>
<script type="math/tex; mode=display">
Q(\theta^{(i+1)},\theta^{(i)}) > Q(\theta^{(i)},\theta^{(i)})</script><p>​    （4）重复（2）和（3），直到收敛。</p>
<hr>
<p>当参数的维数为时，可采用一种特殊的GEM算法，它将EM算法的M步分解为次条件极大化，每次只改变参数向量的一个分量，其余分量不改变。</p>
<p><strong>算法 9.5（GEM算法3）</strong></p>
<p><strong>输入</strong>：观测数据，$Q$函数；</p>
<p><strong>输出</strong>：模型参数。</p>
<p>​    （1）初始化参数$\theta^{(0)} = \{\theta^{(0)}_1,\theta^{(0)}_2,…,\theta^{(0)}_d\}$，开始迭代。</p>
<p>​    （2）第$i+1$次迭代，第一步：记$\theta^{(i)} = \{\theta^{(i)}_1,\theta^{(i)}_2,…,\theta^{(i)}_d\}$为参数$\theta = \{\theta_1,\theta_2,…,\theta_d\}$的估计值，计算</p>
<script type="math/tex; mode=display">
Q(\theta,\theta^{(i)}) = E_Z[\log P(Y,Z|\theta)|Y,\theta^{(i)}]</script><script type="math/tex; mode=display">
\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ =\sum\limits_{Z} \log P(Y,Z|\theta)P(Z|Y,\theta)</script><p>​    （3）第二步：进行$d$次条件极大化：</p>
<p>首先，在$\theta^{(i)}_2,…,\theta^{(i)}_d$保持不变的条件下求使$Q(\theta,\theta^{(i)}) $达到极大的$\theta_1^{(i+1)}$；然后，在$\theta_1 = \theta_1^{(i+1)},\theta_j = \theta_j^{(i)},j=3,4,..,d$的条件下求使$Q(\theta,\theta^{(i)})$达到极大的$\theta_2^{(i+1)}$；如此继续，经过$d$次条件极大化，得到$\theta^{(i+1)} = \{\theta^{(i+1)}_1,\theta^{(i+1)}_2,…,\theta^{(i+1)}_d\}$使得</p>
<script type="math/tex; mode=display">
Q(\theta^{(i+1)},\theta^{(i)}) > Q(\theta^{(i)},\theta^{(i)})</script><p>​    （4）重复（2）和（3），直到收敛。</p>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="http://example.com/2021/06/17/Statistical_Learning_Methods_Notes/%E7%AC%AC%E5%85%AB%E7%AB%A0-%E6%8F%90%E5%8D%87%E6%96%B9%E6%B3%95/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/posthead.jpg">
      <meta itemprop="name" content="Normal People">
      <meta itemprop="description" content="Get busy living or get busy dying">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Blog">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2021/06/17/Statistical_Learning_Methods_Notes/%E7%AC%AC%E5%85%AB%E7%AB%A0-%E6%8F%90%E5%8D%87%E6%96%B9%E6%B3%95/" class="post-title-link" itemprop="url">第八章 提升方法</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>
              

              <time title="创建时间：2021-06-17 21:49:30 / 修改时间：21:48:53" itemprop="dateCreated datePublished" datetime="2021-06-17T21:49:30+08:00">2021-06-17</time>
            </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/%E7%BB%9F%E8%AE%A1%E5%AD%A6%E4%B9%A0%E6%96%B9%E6%B3%95/" itemprop="url" rel="index"><span itemprop="name">统计学习方法</span></a>
                </span>
            </span>

          
  
  <span class="post-meta-item">
    
      <span class="post-meta-item-icon">
        <i class="far fa-comment"></i>
      </span>
      <span class="post-meta-item-text">Valine：</span>
    
    <a title="valine" href="/2021/06/17/Statistical_Learning_Methods_Notes/%E7%AC%AC%E5%85%AB%E7%AB%A0-%E6%8F%90%E5%8D%87%E6%96%B9%E6%B3%95/#valine-comments" itemprop="discussionUrl">
      <span class="post-comments-count valine-comment-count" data-xid="/2021/06/17/Statistical_Learning_Methods_Notes/%E7%AC%AC%E5%85%AB%E7%AB%A0-%E6%8F%90%E5%8D%87%E6%96%B9%E6%B3%95/" itemprop="commentCount"></span>
    </a>
  </span>
  
  

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <p><strong>提升（boosting）方法</strong>是一种常用的统计学习方法，应用广泛且有效。在分类问题中，它通过改变训练样本的权重，学习多个分类器，并将这些分类器进行线性组合，提高分类的性能。</p>
<h1 id="8-1-提升方法AdaBoost算法"><a href="#8-1-提升方法AdaBoost算法" class="headerlink" title="8.1 提升方法AdaBoost算法"></a>8.1 提升方法AdaBoost算法</h1><h2 id="8-1-1-提升方法的基本思路"><a href="#8-1-1-提升方法的基本思路" class="headerlink" title="8.1.1 提升方法的基本思路"></a>8.1.1 提升方法的基本思路</h2><p>提升方法基于这样一种思想：对于一个复杂任务来说，将多个专家的判断进行适当的综合所得出的判断，要比其中任何一个专家单独的判断好。</p>
<p>在<strong>概率近似正确（probably approximately correct，PAC）</strong>学习框架中，</p>
<ul>
<li><p>一个概念（一个类），如果存在一个多项式的学习算法能够学习它，并且正确率很高，那么就称这个概念是强可学习的；</p>
</li>
<li><p>一个概念，如果存在一个多项式的学习算法能够学习它，学习的正确率仅比随机猜测略好，那么就称这个概念是弱可学习的。</p>
</li>
</ul>
<p>在PAC学习的框架下，一个概念是强可学习的充分必要条件是这个概念是弱可学习的。</p>
<p>提升方法就是从弱学习算法，反复学习，得到一系列弱分类器（又称为基本分类器），然后组合这些弱分类器，构成一个强分类器。大多数的提升方法都是改变训练数据的概率分布（训练数据的权值分布），针对不同的训练数据分布调用弱学习算法学习一系列弱分类器。</p>
<hr>
<p>对于提升方法来说，有两个问题需要回答：</p>
<ul>
<li>在每一轮如何改变训练数据的权值或概率分布；</li>
<li>如何将弱分类器组合成一个强分类器。</li>
</ul>
<p>关于第一个问题，AdaBoost的做法是，提高那些被前一轮弱分类器错误分类样本的权值，而降低那些被正确分类样本的权值。那些没有得到正确分类的数据，由于其权值的加大而受到后一轮的弱分类器的更大关注。于是，分类问题被一系列的弱分类器“分而治之”。</p>
<p>至于第二个问题，即弱分类器的组合，AdaBoost采取加权多数表决的方法。具体地，加大分类误差率小的弱分类器的权值，使其在表决中起较大的作用；减小分类误差率大的弱分类器的权值，使其在表决中起较小的作用。</p>
<h2 id="8-1-2-AdaBoost算法"><a href="#8-1-2-AdaBoost算法" class="headerlink" title="8.1.2 AdaBoost算法"></a>8.1.2 AdaBoost算法</h2><p><strong>算法 8.1（AdaBoost）</strong></p>
<p><strong>输入</strong>：训练数据集$T = \{(x_1,y_1),(x_2,y_2),…,(x_N,y_N)\}$，其中，$x_i \in \chi = R^n, y \in Y = \{+1, -1\}, i=1,2,…,N$；弱学习算法；</p>
<p><strong>输出</strong>：最终分类器$G(x)$。</p>
<p>​    （1）初始化训练数据的权值分布</p>
<script type="math/tex; mode=display">
D_1 = (w_{11},...,w_{1i},...,w_{1N})\ \ \ w_{1i} = \frac{1}{N},\ \ \ i= 1,2,...,N</script><p>​    （2）对$m=1,2,…,M$</p>
<p>​        （a）使用具有权值分布$D_m$的训练数据集学习，得到基本分类器。</p>
<script type="math/tex; mode=display">
G_m(x) : \mathcal{X} \longrightarrow \{-1, +1\}</script><p>​        （b）计算$G_m(x)$在训练数据集上的分类误差率</p>
<script type="math/tex; mode=display">
e_m = \sum\limits_{i = 1}^{N}P(G_m(x_i) \neq y_i) = \sum\limits_{i = 1}^{N}w_{mi}I(G_m(x_i) \neq y_i)\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ (8.1)</script><p>​        （c）计算$G_m(x)$的系数</p>
<script type="math/tex; mode=display">
\alpha_m = \frac{1}{2}\log\frac{1 - e_m}{e_m}\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ (8.2)</script><p>这里的对数是自然对数。</p>
<p>​        （d）更新训练数据集的权值分布</p>
<script type="math/tex; mode=display">
D_{m+1} = (w_{m+1,1},...,w_{m+1,i},...,w_{m+1,N})\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ (8.3)</script><script type="math/tex; mode=display">
w_{m+1,i} = \frac{w_{mi}}{Z_m}\exp(-\alpha_my_iG_m(x_i)), \ \ \ i= 1,2,...,N \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ (8.4)</script><p>这里，$Z_m$是规范化因子</p>
<script type="math/tex; mode=display">
Z_m = \sum\limits_{i = 1}^{N} w_{mi}\exp(-\alpha_my_iG_m(x_i))\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ (8.5)</script><p>它使$D_{m+1}$成为一个概率分布。</p>
<p>​    （3）构建基本分类器的线性组合（所有$\alpha_m$之和并不为1）</p>
<script type="math/tex; mode=display">
f(x) =\sum\limits_{i = 1}^{N} \alpha_m G_m(x)\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ (8.6)</script><p>得到最终分类器</p>
<script type="math/tex; mode=display">
G(x) = sign(f(x)) = sign(\sum\limits_{i = 1}^{N} \alpha_m G_m(x))\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ (8.7)</script><p>AdaBoost的特点：</p>
<ul>
<li>不改变所给的训练数据，而不断改变训练数据权值的分布，使得训练数据在基本分类器的学习中起不同的作用；</li>
<li>利用基本分类器的线性组合构建最终分类器。</li>
</ul>
<h1 id="8-2-AdaBoost算法的训练误差分析"><a href="#8-2-AdaBoost算法的训练误差分析" class="headerlink" title="8.2 AdaBoost算法的训练误差分析"></a>8.2 AdaBoost算法的训练误差分析</h1><p>AdaBoost最基本的性质是它能在学习过程中不断减少训练误差，即在训练数据集上的分类误差率。</p>
<p><strong>定理 8.1（AdaBoost的训练误差界）</strong>  AdaBoost算法最终分类器的训练误差界为</p>
<script type="math/tex; mode=display">
\frac{1}{N}\sum\limits_{i = 1}^{N}I(G(x_i) \neq y_i) \leq \frac{1}{N}\sum\limits_{i}\exp(-y_i f(x_i)) = \prod\limits_{m} Z_m\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ (8.9)</script><p>这里，$G(x),f(x)$和$Z_m$分别由式$(8.7)$、式$(8.6)$和式$(8.5)$给出。</p>
<p>这一定理说明，可以在每一轮选取适当的$G_m$使得$Z_m$最小，从而使训练误差下降最快。</p>
<hr>
<p><strong>定理 8.2（二类分类问题AdaBoost的训练误差界）</strong></p>
<script type="math/tex; mode=display">
\prod\limits_{m=1}^{M} Z_m = \prod\limits_{m=1}^{M} [2\sqrt{e_m(1-e_m)} ]</script><script type="math/tex; mode=display">
= \prod\limits_{m=1}^{M} \sqrt{(1-4\gamma^2_m)}</script><script type="math/tex; mode=display">
\ \ \ \ \ \ \ \ \ \\ \ \ \ \ \ \ \ \  \ \ \ \ \ \ \ \ \ \ \ \  \ \ \ \ \ \ \ \ \ \ \ \ \leq \exp(-1\sum\limits_{m=1}^{M} \gamma_m^2)\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ (8.10)</script><p>这里，$\gamma_m = \frac{1}{2} - e_m$。</p>
<hr>
<p><strong>推论 8.1</strong>  如果存在$\gamma &gt; 0$，对所有$m$有$\gamma_m \geq \gamma$，则</p>
<script type="math/tex; mode=display">
\frac{1}{N}\sum\limits_{i=1}^{N}I(G(x_i) \neq y_i) \leq \exp(-2M\gamma^2)\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ (8.12)</script><p>这表明在此条件下AdaBoost的训练误差是以指数速率下降的。</p>
<p>AdaBoost具有适应性，即它能适应弱分类器各自的训练误差率。</p>
<h1 id="8-3-AdaBoost算法的解释"><a href="#8-3-AdaBoost算法的解释" class="headerlink" title="8.3 AdaBoost算法的解释"></a>8.3 AdaBoost算法的解释</h1><p>AdaBoost算法还有另一个解释，即可以认为AdaBoost算法是模型为加法模型、损失函数为指数函数、学习算法为前向分步算法时的二类分类学习方法。</p>
<h2 id="8-3-1-前向分步算法"><a href="#8-3-1-前向分步算法" class="headerlink" title="8.3.1 前向分步算法"></a>8.3.1 前向分步算法</h2><p>考虑<strong>加法模型（additive model）</strong></p>
<script type="math/tex; mode=display">
f(x) = \sum\limits_{m=1}^{M}\beta_m b(x;\gamma_m)\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ (8.13)</script><p>其中，$b(x;\gamma_m)$为基函数，$\gamma_m$为基函数的参数，$\beta_m$为基函数的系数。</p>
<p>在给定训练数据及损失函数$L(y,f(x))$的条件下，学习加法模型$f(x)$成为经验风险极小化即损失函数极小化问题：</p>
<script type="math/tex; mode=display">
\min\limits_{\beta_m,\gamma_m} \sum\limits_{i=1}^{N} L(y_i,\sum\limits_{m=1}^{M}\beta_m b(x_i;\gamma_m))\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ (8.14)</script><p><strong>前向分步算法（forward stagewise algorithm）</strong>求解这一优化问题的想法是：因为学习的是加法模型，如果能够从前向后，每一步只学习一个基函数及其系数，逐步逼近优化目标函数$(8.14)$，那么就可以简化优化的复杂度。具体地，每步只需优化如下损失函数：</p>
<script type="math/tex; mode=display">
\min\limits_{\beta,\gamma} \sum\limits_{i=1}^{N} L(y_i,\beta b(x_i;\gamma))\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ (8.15)</script><hr>
<p><strong>算法 8.2（前向分步算法）</strong></p>
<p><strong>输入</strong>：训练数据集$T = \{(x_1,y_1),(x_2,y_2),…,(x_N,y_N)\}$；损失函数$L(y,f(x))$；基函数集$\{b(x;\gamma)\}$；</p>
<p><strong>输出</strong>：加法模型$f(x)$。</p>
<p>​    （1）初始化$f_0(x) = 0$；</p>
<p>​    （2）对$m = 1,2,..,M$</p>
<p>​        （a）极小化损失函数</p>
<script type="math/tex; mode=display">
(\beta_m,\gamma_m) = \arg\min\limits_{\beta,\gamma}\sum\limits_{i=1}^{N} L(y_i,f_{m-1}(x_i)  + \beta b(x_i;\gamma))\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ (8.16)</script><p>​    得到参数$\beta_m,\gamma_m$。</p>
<p>​        （b）更新</p>
<script type="math/tex; mode=display">
f_m(x) = f_{m-1}(x) + \beta_m b(x;\gamma_m)\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ (8.17)</script><p>​    （3）得到加法模型</p>
<script type="math/tex; mode=display">
f(x) = f_M(x) = \sum\limits_{m=1}^{M}\beta_m b(x;\gamma_m)\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ (8.18)</script><p>这样，前向分步算法将同时求解从$m = 1$到$M$所有参数$\beta_m,\gamma_m$的优化问题简化为逐次求解各个$\beta_m,\gamma_m$的优化问题。</p>
<h2 id="8-3-2-前向分步算法与AdaBoost"><a href="#8-3-2-前向分步算法与AdaBoost" class="headerlink" title="8.3.2 前向分步算法与AdaBoost"></a>8.3.2 前向分步算法与AdaBoost</h2><p><strong>定理 8.3</strong> AdaBoost算法是前向分步加法算法的特例。这时，模型是由基本分类器组成的加法模型，损失函数是指数函数。</p>
<h1 id="8-4-提升树"><a href="#8-4-提升树" class="headerlink" title="8.4 提升树"></a>8.4 提升树</h1><p>提升树是以分类树或回归树为基本分类器的提升方法。</p>
<h2 id="8-4-1-提升树模型"><a href="#8-4-1-提升树模型" class="headerlink" title="8.4.1 提升树模型"></a>8.4.1 提升树模型</h2><p>以决策树为基函数的提升方法称为<strong>提升树（booting tree）</strong>。对分类问题决策树是二叉分类树，对回归问题决策树是二叉回归树。</p>
<p>提升树模型可以表示为决策树的加法模型：</p>
<script type="math/tex; mode=display">
f_M(x) = \sum\limits_{m=1}^{M}T(x;\Theta_m)\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ (8.24)</script><p>其中，$T(x;\Theta_m)$表示决策树，$\Theta_m$为决策树的参数，$M$为树的个数。</p>
<h2 id="8-4-2-提升树算法"><a href="#8-4-2-提升树算法" class="headerlink" title="8.4.2 提升树算法"></a>8.4.2 提升树算法</h2><p>提升树算法采用前向分步算法。首先确定初始提升树$f_0(x) = 0$，第$m$步的模型是</p>
<script type="math/tex; mode=display">
f_m(x) = f_{m-1}(x) + T(x;\Theta_m)\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ (8.25)</script><p>其中，$f_{m-1}(x)$为当前模型，通过经验风险极小化确定下一棵决策树的参数$\Theta_m$：</p>
<script type="math/tex; mode=display">
\hat \Theta_m  = \arg\min\limits_{i=1}^{N}L(y_i,f_{m-1}(x_i) + T(x_i;\Theta_m))\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ (8.26)</script><p>针对不同问题的提升树学习算法，其主要区别在于使用的损失函数不同。包括用平方误差损失函数的回归问题，用指数损失函数的分类问题，以及用一般损失函数的一般决策问题。</p>
<p>对于二分类问题，提升树算法只需将AdaBoost算法8.1中的基本分类器限制为二类分类树即可，可以说这时的提升树算法是AdaBoost算法的特殊情况。</p>
<hr>
<p>已知一个训练数据集$T = \{(x_1,y_1),(x_2,y_2),…,(x_N,y_N)\}$，其中，$x_i \in \chi = R^n$，$\mathcal{X}$为输入空间，$ y \in Y \subseteq R$，$\mathcal{Y}$为输出空间。如果将输入空间$\mathcal{X}$划分为$J$个互不相交的区域$R_1,R_2,…,R_J$，并且在每个区域上确定输出的常量$c_j$，那么树可表示为</p>
<script type="math/tex; mode=display">
T(x;\Theta) = \sum\limits_{j=1}^{J}c_jI(x \in R_j)\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ (8.27)</script><p>其中，参数$\Theta = \{(R_1,c_1),(R_2,c_2),…,(R_J,c_J)\}$表示树的区域划分和各区域上的常数。$J$是回归树的复杂度即叶结点个数。</p>
<p>回归问题提升树使用以下前向分步算法：</p>
<script type="math/tex; mode=display">
f_0(x) = 0</script><script type="math/tex; mode=display">
f_m(x) = f_{m-1}(x) + T(x;\Theta_m), \ \ \ m = 1,2,...,M</script><script type="math/tex; mode=display">
f_M(x) = \sum\limits_{m=1}^{M}T(x;\Theta_m)</script><p>在前向分步算法的第$m$步，给定当前模型$f_{m-1}(x)$，需求解</p>
<script type="math/tex; mode=display">
\hat \Theta_m  = \arg\min\limits_{i=1}^{N}L(y_i,f_{m-1}(x_i) + T(x_i;\Theta_m))</script><p>得到$\hat \Theta_m$，即第$m$棵树的参数。</p>
<p>当采用平方误差损失函数时，</p>
<script type="math/tex; mode=display">
L(y,f(x)) = (y-f(x))^2</script><p>其损失变为</p>
<script type="math/tex; mode=display">
L(y,f_{m-1}(x) + T(x;\Theta_m)) = [y- f_{m-1}(x)-T(x;\Theta_m)]^2</script><script type="math/tex; mode=display">
= [r-T(x;\Theta_m)]^2</script><p>这里，</p>
<script type="math/tex; mode=display">
r = y- f_{m-1}(x)\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ (8.28)</script><p>是更强模型拟合数据的<strong>残差（residual）</strong>。所以，对回归问题的提升树算法来说，只需简单地拟合当前模型的残差。</p>
<p><strong>算法 8.3（回归问题的提升树算法）</strong></p>
<p><strong>输入</strong>：训练数据集$T = \{(x_1,y_1),(x_2,y_2),…,(x_N,y_N)\}$，$x_i \in \chi = R^n$，$ y \in Y \subseteq R$；</p>
<p><strong>输出</strong>：提升树$f_M(x)$。</p>
<p>​    （1）初始化$f_0(x) = 0$。</p>
<p>​    （2）对$m = 1,2,…,M$。</p>
<p>​        （a）按式$(8.28)$计算残差：</p>
<script type="math/tex; mode=display">
r_{mi} = y_i- f_{m-1}(x_i), \ \ \ i=1,2,...,N</script><p>​        （b）拟合残差$r_{mi}$学习一个回归树，得到$T(x;\Theta_m)$。</p>
<p>​        （c）更新$f_m(x) = f_{m-1}(x) + T(x;\Theta_m)$。</p>
<p>​    （3）得到回归问题提升树</p>
<script type="math/tex; mode=display">
f_M(x) = \sum\limits_{m=1}^{M}T(x;\Theta_m)</script><h2 id="8-4-3-梯度提升"><a href="#8-4-3-梯度提升" class="headerlink" title="8.4.3 梯度提升"></a>8.4.3 梯度提升</h2><p>对于一般损失函数而言，往往每一步优化并不那么容易。针对这一问题，Freidman提出了<strong>梯度提升（gradient boosting）</strong>算法。这是利用最速下降法的近似方法，其关键是利用损失函数的负梯度在当前模型的值</p>
<script type="math/tex; mode=display">
-[\frac{\partial L(y,f(x_i))}{\partial f(x_i)}]_{f(x)=f_{m-1}(x)}</script><p>作为回归问题提升树算法中的残差近似值，拟合一个回归树。</p>
<p><strong>算法 8.4（梯度提升算法）</strong></p>
<p><strong>输入</strong>：训练数据集$T = \{(x_1,y_1),(x_2,y_2),…,(x_N,y_N)\}$，$x_i \in \chi = R^n$，$ y \in Y \subseteq R$；</p>
<p><strong>输出</strong>：提升树$\hat f(x)$。</p>
<p>​    （1）初始化</p>
<script type="math/tex; mode=display">
f_0(x) = \arg\min\limits_{c}\sum\limits_{i=1}^{N}L(y_i,c)</script><p>​    （2）对$m = 1,2,…,M$</p>
<p>​        （a）对$i=1,2,…,N$，计算</p>
<script type="math/tex; mode=display">
r_{mi} = -[\frac{\partial L(y_i,f(x_i))}{\partial f(x_i)}]_{f(x)=f_{m-1}(x)}</script><p>​        （b）对$r_{mi}$拟合一个回归树，得到第$m$棵树的叶结点区域$R_{mj},j=1,2,…,J$。</p>
<p>​        （c）对$j=1,2,…,J$，计算</p>
<script type="math/tex; mode=display">
c_{mj} =\arg\min\limits_{c}\sum\limits_{x_i \in R_{mj}}L(y_i,f_{m-1}(x_i) + c)</script><p>​        （d）更新$f_m(x) = f_{m-1}(x) + \sum\limits_{j=1}^{J}c_{mj}I(x \in R_{mj})$</p>
<p>​    （3）得到回归树</p>
<script type="math/tex; mode=display">
\hat f(x) = f_M(x) = \sum\limits_{m=1}^{M}\sum\limits_{j=1}^{J}I(x \in R_{mj})</script><ul>
<li>算法第1步初始化，估计使损失函数极小化的常数值，它是只有一个根结点的树。</li>
<li><p>第2(a)步计算损失函数的负梯度在当前模型的值，将它作为残差的估计。</p>
<ul>
<li>对于平方损失函数，它就是通常所说的残差；</li>
<li>对于一般损失函数他就是残差的近似值。</li>
</ul>
</li>
<li><p>第2(b)步估计回归树叶结点区域，以拟合残差的近似值。</p>
</li>
<li>第2(c)步利用线性搜索估计叶结点区域的值，是损失函数极小化。</li>
<li>第2(d)步更新回归树。</li>
<li>第3步得到输出的最终模型$\hat f(x)$</li>
</ul>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  


  
  <nav class="pagination">
    <span class="page-number current">1</span><a class="page-number" href="/default-index/page/2/">2</a><span class="space">&hellip;</span><a class="page-number" href="/default-index/page/4/">4</a><a class="extend next" rel="next" href="/default-index/page/2/"><i class="fa fa-angle-right" aria-label="下一页"></i></a>
  </nav>



          </div>
          

<script>
  window.addEventListener('tabs:register', () => {
    let { activeClass } = CONFIG.comments;
    if (CONFIG.comments.storage) {
      activeClass = localStorage.getItem('comments_active') || activeClass;
    }
    if (activeClass) {
      let activeTab = document.querySelector(`a[href="#comment-${activeClass}"]`);
      if (activeTab) {
        activeTab.click();
      }
    }
  });
  if (CONFIG.comments.storage) {
    window.addEventListener('tabs:click', event => {
      if (!event.target.matches('.tabs-comment .tab-content .tab-pane')) return;
      let commentClass = event.target.classList[1];
      localStorage.setItem('comments_active', commentClass);
    });
  }
</script>

        </div>
          
  
  <div class="toggle sidebar-toggle">
    <span class="toggle-line toggle-line-first"></span>
    <span class="toggle-line toggle-line-middle"></span>
    <span class="toggle-line toggle-line-last"></span>
  </div>

  <aside class="sidebar">
    <div class="sidebar-inner">

      <ul class="sidebar-nav motion-element">
        <li class="sidebar-nav-toc">
          文章目录
        </li>
        <li class="sidebar-nav-overview">
          站点概览
        </li>
      </ul>

      <!--noindex-->
      <div class="post-toc-wrap sidebar-panel">
      </div>
      <!--/noindex-->

      <div class="site-overview-wrap sidebar-panel">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
    <img class="site-author-image" itemprop="image" alt="Normal People"
      src="/images/posthead.jpg">
  <p class="site-author-name" itemprop="name">Normal People</p>
  <div class="site-description" itemprop="description">Get busy living or get busy dying</div>
</div>
<div class="site-state-wrap motion-element">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
          <a href="/archives">
        
          <span class="site-state-item-count">35</span>
          <span class="site-state-item-name">日志</span>
        </a>
      </div>
      <div class="site-state-item site-state-categories">
            <a href="/categories">
          
        <span class="site-state-item-count">11</span>
        <span class="site-state-item-name">分类</span></a>
      </div>
  </nav>
</div>
  <div class="links-of-author motion-element">
      <span class="links-of-author-item">
        <a href="https://github.com/TheNormalPeople" title="GitHub → https:&#x2F;&#x2F;github.com&#x2F;TheNormalPeople" rel="noopener" target="_blank"><i class="fab fa-github fa-fw"></i>GitHub</a>
      </span>
      <span class="links-of-author-item">
        <a href="mailto:1272481411@qq.com" title="E-Mail → mailto:1272481411@qq.com" rel="noopener" target="_blank"><i class="fa fa-envelope fa-fw"></i>E-Mail</a>
      </span>
      <span class="links-of-author-item">
        <a href="https://weibo.com/u/5938927274" title="Weibo → https:&#x2F;&#x2F;weibo.com&#x2F;u&#x2F;5938927274" rel="noopener" target="_blank"><i class="fab fa-weibo fa-fw"></i>Weibo</a>
      </span>
      <span class="links-of-author-item">
        <a href="https://instagram.com/cy19970506" title="Instagram → https:&#x2F;&#x2F;instagram.com&#x2F;cy19970506" rel="noopener" target="_blank"><i class="fab fa-instagram fa-fw"></i>Instagram</a>
      </span>
  </div>



      </div>

    </div>
  </aside>
  <div id="sidebar-dimmer"></div>


      </div>
    </main>

    <footer class="footer">
      <div class="footer-inner">
        

        

<div class="copyright">
  
  &copy; 
  <span itemprop="copyrightYear">2021</span>
  <span class="with-love">
    <i class="heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">Normal People</span>
</div>

        








      </div>
    </footer>
  </div>

  
  <script src="/lib/anime.min.js"></script>
  <script src="/lib/velocity/velocity.min.js"></script>
  <script src="/lib/velocity/velocity.ui.min.js"></script>

<script src="/js/utils.js"></script>

<script src="/js/motion.js"></script>


<script src="/js/schemes/pisces.js"></script>


<script src="/js/next-boot.js"></script>




  















  

  
      

<script>
  if (typeof MathJax === 'undefined') {
    window.MathJax = {
      loader: {
        source: {
          '[tex]/amsCd': '[tex]/amscd',
          '[tex]/AMScd': '[tex]/amscd'
        }
      },
      tex: {
        inlineMath: {'[+]': [['$', '$']]},
        tags: 'ams'
      },
      options: {
        renderActions: {
          findScript: [10, doc => {
            document.querySelectorAll('script[type^="math/tex"]').forEach(node => {
              const display = !!node.type.match(/; *mode=display/);
              const math = new doc.options.MathItem(node.textContent, doc.inputJax[0], display);
              const text = document.createTextNode('');
              node.parentNode.replaceChild(text, node);
              math.start = {node: text, delim: '', n: 0};
              math.end = {node: text, delim: '', n: 0};
              doc.math.push(math);
            });
          }, '', false],
          insertedScript: [200, () => {
            document.querySelectorAll('mjx-container').forEach(node => {
              let target = node.parentNode;
              if (target.nodeName.toLowerCase() === 'li') {
                target.parentNode.classList.add('has-jax');
              }
            });
          }, '', false]
        }
      }
    };
    (function () {
      var script = document.createElement('script');
      script.src = '//cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js';
      script.defer = true;
      document.head.appendChild(script);
    })();
  } else {
    MathJax.startup.document.state(0);
    MathJax.texReset();
    MathJax.typeset();
  }
</script>

    

  


<script>
NexT.utils.loadComments(document.querySelector('#valine-comments'), () => {
  NexT.utils.getScript('//unpkg.com/valine/dist/Valine.min.js', () => {
    var GUEST = ['nick', 'mail', 'link'];
    var guest = 'nick,mail,link';
    guest = guest.split(',').filter(item => {
      return GUEST.includes(item);
    });
    new Valine({
      el         : '#valine-comments',
      verify     : false,
      notify     : false,
      appId      : 'y8XFURQNCoQsprRTou9DiEJu-gzGzoHsz',
      appKey     : 'QfVpjKDtJQdJrnJNnWUbVvjH',
      placeholder: "留下邮箱,有空时间回复您！",
      avatar     : 'mm',
      meta       : guest,
      pageSize   : '10' || 10,
      visitor    : false,
      lang       : '' || 'zh-cn',
      path       : location.pathname,
      recordIP   : false,
      serverURLs : ''
    });
  }, window.Valine);
});
</script>

</body>
</html>
