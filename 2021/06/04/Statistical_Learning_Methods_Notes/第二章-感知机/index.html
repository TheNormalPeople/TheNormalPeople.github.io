<!DOCTYPE html>
<html lang="zh-CN">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
<meta name="theme-color" content="#222">
<meta name="generator" content="Hexo 5.4.0">
  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png">
  <link rel="mask-icon" href="/images/logo.svg" color="#222">

<link rel="stylesheet" href="/css/main.css">


<link rel="stylesheet" href="/lib/font-awesome/css/all.min.css">

<script id="hexo-configurations">
    var NexT = window.NexT || {};
    var CONFIG = {"hostname":"example.com","root":"/","scheme":"Pisces","version":"7.8.0","exturl":false,"sidebar":{"position":"left","display":"post","padding":18,"offset":12,"onmobile":true,"scrollpercent":true,"b2t":true},"copycode":{"enable":true,"show_result":true,"style":null},"back2top":{"enable":true,"sidebar":false,"scrollpercent":false},"bookmark":{"enable":false,"color":"#222","save":"auto"},"fancybox":false,"mediumzoom":false,"lazyload":false,"pangu":false,"comments":{"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},"algolia":{"hits":{"per_page":10},"labels":{"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}},"localsearch":{"enable":false,"trigger":"auto","top_n_per_article":1,"unescape":false,"preload":false},"motion":{"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}}};
  </script>

  <meta name="description" content="感知机（perceptron）是二类分类的线性分类模型，其输入为实例的特征向量，输出为实例的类别，取 $+1$ 和 $-1$ 二值。 感知机对应输入空间（特征空间）中将实例划分为正负两类的分离超平面（separating hyperplane），属于判别模型。感知机学习旨在求出将训练数据进行线性划分的分离超平面。 导入基于误分类的损失函数，利用梯度下降法对损失函数进行极小化，求得感知机模型。 2.">
<meta property="og:type" content="article">
<meta property="og:title" content="第二章 感知机">
<meta property="og:url" content="http://example.com/2021/06/04/Statistical_Learning_Methods_Notes/%E7%AC%AC%E4%BA%8C%E7%AB%A0-%E6%84%9F%E7%9F%A5%E6%9C%BA/index.html">
<meta property="og:site_name" content="Blog">
<meta property="og:description" content="感知机（perceptron）是二类分类的线性分类模型，其输入为实例的特征向量，输出为实例的类别，取 $+1$ 和 $-1$ 二值。 感知机对应输入空间（特征空间）中将实例划分为正负两类的分离超平面（separating hyperplane），属于判别模型。感知机学习旨在求出将训练数据进行线性划分的分离超平面。 导入基于误分类的损失函数，利用梯度下降法对损失函数进行极小化，求得感知机模型。 2.">
<meta property="og:locale" content="zh_CN">
<meta property="article:published_time" content="2021-06-04T12:34:57.494Z">
<meta property="article:modified_time" content="2021-06-04T13:19:35.393Z">
<meta property="article:author" content="Normal People">
<meta name="twitter:card" content="summary">

<link rel="canonical" href="http://example.com/2021/06/04/Statistical_Learning_Methods_Notes/%E7%AC%AC%E4%BA%8C%E7%AB%A0-%E6%84%9F%E7%9F%A5%E6%9C%BA/">


<script id="page-configurations">
  // https://hexo.io/docs/variables.html
  CONFIG.page = {
    sidebar: "",
    isHome : false,
    isPost : true,
    lang   : 'zh-CN'
  };
</script>

  <title>第二章 感知机 | Blog</title>
  






  <noscript>
  <style>
  .use-motion .brand,
  .use-motion .menu-item,
  .sidebar-inner,
  .use-motion .post-block,
  .use-motion .pagination,
  .use-motion .comments,
  .use-motion .post-header,
  .use-motion .post-body,
  .use-motion .collection-header { opacity: initial; }

  .use-motion .site-title,
  .use-motion .site-subtitle {
    opacity: initial;
    top: initial;
  }

  .use-motion .logo-line-before i { left: initial; }
  .use-motion .logo-line-after i { right: initial; }
  </style>
</noscript>

</head>

<body itemscope itemtype="http://schema.org/WebPage">
  <div class="container use-motion">
    <div class="headband"></div>

    <header class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="切换导航栏">
      <span class="toggle-line toggle-line-first"></span>
      <span class="toggle-line toggle-line-middle"></span>
      <span class="toggle-line toggle-line-last"></span>
    </div>
  </div>

  <div class="site-meta">

    <a href="/" class="brand" rel="start">
      <span class="logo-line-before"><i></i></span>
      <h1 class="site-title">Blog</h1>
      <span class="logo-line-after"><i></i></span>
    </a>
      <p class="site-subtitle" itemprop="description">by Normal People</p>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger">
    </div>
  </div>
</div>




<nav class="site-nav">
  <ul id="menu" class="main-menu menu">
        <li class="menu-item menu-item-home">

    <a href="/" rel="section"><i class="fa fa-home fa-fw"></i>首页</a>

  </li>
        <li class="menu-item menu-item-about">

    <a href="/about" rel="section"><i class="fa fa-user fa-fw"></i>关于</a>

  </li>
        <li class="menu-item menu-item-tags">

    <a href="/tags" rel="section"><i class="fa fa-tags fa-fw"></i>标签<span class="badge">0</span></a>

  </li>
        <li class="menu-item menu-item-categories">

    <a href="/categories" rel="section"><i class="fa fa-th fa-fw"></i>分类<span class="badge">6</span></a>

  </li>
        <li class="menu-item menu-item-archives">

    <a href="/archives" rel="section"><i class="fa fa-archive fa-fw"></i>归档<span class="badge">26</span></a>

  </li>
  </ul>
</nav>




</div>
    </header>

    
  <div class="back-to-top">
    <i class="fa fa-arrow-up"></i>
    <span>0%</span>
  </div>


    <main class="main">
      <div class="main-inner">
        <div class="content-wrap">
          

          <div class="content post posts-expand">
            

    
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="http://example.com/2021/06/04/Statistical_Learning_Methods_Notes/%E7%AC%AC%E4%BA%8C%E7%AB%A0-%E6%84%9F%E7%9F%A5%E6%9C%BA/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/posthead.jpg">
      <meta itemprop="name" content="Normal People">
      <meta itemprop="description" content="Get busy living or get busy dying">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Blog">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          第二章 感知机
        </h1>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>
              

              <time title="创建时间：2021-06-04 20:34:57 / 修改时间：21:19:35" itemprop="dateCreated datePublished" datetime="2021-06-04T20:34:57+08:00">2021-06-04</time>
            </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/%E7%BB%9F%E8%AE%A1%E5%AD%A6%E4%B9%A0%E6%96%B9%E6%B3%95/" itemprop="url" rel="index"><span itemprop="name">统计学习方法</span></a>
                </span>
            </span>

          
  
  <span class="post-meta-item">
    
      <span class="post-meta-item-icon">
        <i class="far fa-comment"></i>
      </span>
      <span class="post-meta-item-text">Valine：</span>
    
    <a title="valine" href="/2021/06/04/Statistical_Learning_Methods_Notes/%E7%AC%AC%E4%BA%8C%E7%AB%A0-%E6%84%9F%E7%9F%A5%E6%9C%BA/#valine-comments" itemprop="discussionUrl">
      <span class="post-comments-count valine-comment-count" data-xid="/2021/06/04/Statistical_Learning_Methods_Notes/%E7%AC%AC%E4%BA%8C%E7%AB%A0-%E6%84%9F%E7%9F%A5%E6%9C%BA/" itemprop="commentCount"></span>
    </a>
  </span>
  
  

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
        <p><strong>感知机（perceptron）</strong>是二类分类的线性分类模型，其输入为实例的特征向量，输出为实例的类别，取 $+1$ 和 $-1$ 二值。</p>
<p>感知机对应输入空间（特征空间）中将实例划分为正负两类的<strong>分离超平面（separating hyperplane）</strong>，属于判别模型。感知机学习旨在求出将训练数据进行线性划分的分离超平面。</p>
<p>导入基于误分类的损失函数，利用梯度下降法对损失函数进行极小化，求得感知机模型。</p>
<h1 id="2-1-感知机模型"><a href="#2-1-感知机模型" class="headerlink" title="2.1 感知机模型"></a>2.1 感知机模型</h1><p><strong>定义2.1（感知机）</strong>  假设输入空间（特征空间）是$\chi \subseteq R^n$,输出空间是$Y={+1, -1}$。输入$x \in \chi$表示实例的特征向量，对应于输入空间（特征空间）的点；</p>
<p>输出$y \in Y$表示实例的类别。由输入空间到输出空间的如下函数：<br>$$<br>f(x) = sign(\omega·x + b) \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ (2.1)<br>$$<br>称为感知机。其中，$\omega$和$b$为感知机模型参数，$\omega \in R^n$叫作全职（weight）或权值向量（weight vector），$b \in R$叫作偏置（bias），$\omega·x$表示$\omega$和$x$的内积。$sign$是符号函数，即<br>$$<br>sign(x) = \lbrace_{ -1,\ \ x &lt; 0 }^{+1,\ \ x \geq 0}  \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ (2.2)<br>$$<br>感知机模型的假设空间定义在特征空间中的所有<strong>线性分类模型（linear classification model）</strong>或<strong>线性分类器（linear classifier）</strong>，即函数集合：<br>$$<br>{f|f(x) = \omega·x + b}<br>$$<br>感知机由如下几何解释：线性方程<br>$$<br>\omega·x + b = 0<br>$$<br>对应于特征空间$R^n$中的一个超平面$S$,其中$\omega$是超平面的法向量，$b$是超平面的截距。</p>
<ul>
<li><p>感知机学习，由训练数据集（实力的特征向量及类别）求得感知机模型（2.1），即求得模型参数$\omega,b$。</p>
</li>
<li><p>感知机预测，通过学习得到的感知机模型，对于新的输入实例给出其对应的输出类别。</p>
</li>
</ul>
<h1 id="2-2-感知机学习策略"><a href="#2-2-感知机学习策略" class="headerlink" title="2.2 感知机学习策略"></a>2.2 感知机学习策略</h1><h2 id="2-2-1-数据集的线性可分性"><a href="#2-2-1-数据集的线性可分性" class="headerlink" title="2.2.1 数据集的线性可分性"></a>2.2.1 数据集的线性可分性</h2><p><strong>定义2.2（数据集的线性可分性）</strong>  给定一个数据集<br>$$<br>T = {(x_1,y_1),(x_2,y_2),…,(x_N,y_N)}<br>$$<br>其中，$x_i \in \chi = R^n, y \in Y = {+1, -1}, i=1,2,…,N$，如果存在某个超平面$S$<br>$$<br>\omega·x + b = 0<br>$$<br>能够将数据集的正实例点和负实例点完全正确地划分到超平面的两侧，即对所有$y_i=+1$的实例$i$，有$\omega·x + b &gt; 0$，对所有$y_i = -1$的实例$i$，有$\omega·x + b &lt; 0$，则称数据集$T$为线性可分数据集（linearly separable data set）；否则，称数据集$T$线性不可分。</p>
<h2 id="2-2-2-感知机学习策略"><a href="#2-2-2-感知机学习策略" class="headerlink" title="2.2.2 感知机学习策略"></a>2.2.2 感知机学习策略</h2><p>为了找出这样的超平面，即确定感知机模型参数$\omega,b$，需要确定一个学习策略，即定义（经验）损失函数并将损失函数极小化。</p>
<p>损失函数的选择是误分类点到超平面$S$的总距离，这是感知机所采用的。</p>
<ul>
<li>假设超平面$s$的误分类点集合为$M$，那么所有误分类点到超平面$S$的总距离为</li>
</ul>
<p>$$<br>-\frac{1}{||\omega||}\sum\limits_{x_i \in M} y_i(\omega·x_i + b)<br>$$</p>
<p>​        不考虑$\frac{1}{||\omega||}$，就得到感知机学习的损失函数。</p>
<ul>
<li>感知机$sign(\omega·x + b)$学习的损失函数定义为</li>
</ul>
<p>$$<br>L(\omega,b) =-\sum\limits_{x_i \in M} y_i(\omega·x_i + b) \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ (2.4)<br>$$</p>
<p>​        这个损失函数就是感知机学习的经验风险函数。</p>
<p>显然，损失函数$L(\omega,b)$是非负的。如果没有误分类点，损失函数值是$0$。而且，误分类点越少，误分类点离超平面越近，损失函数值就越小。</p>
<p>一个特定的样本点的损失函数：在误分类时是参数$\omega,b$的线性函数，在正确分类时是$0$。因此，给定训练数据集$T$，损失函数$L(\omega,b)$是$\omega,b$的连续可导函数。</p>
<p>感知机学习的策略是在假设空间中选取使损失函数（2.4）最小的模型参数$\omega,b$，即感知机模型。</p>
<h1 id="2-3-感知机学习算法"><a href="#2-3-感知机学习算法" class="headerlink" title="2.3 感知机学习算法"></a>2.3 感知机学习算法</h1><p>感知机学习算法是对以下最优化问题的算法。<br>$$<br>\min\limits_{\omega,b} L(\omega,b) = - \sum\limits_{x_i \in M} y_i(\omega·x_i + b) \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ (2.5)<br>$$<br>感知机学习算法是误分类驱动的，具体采用随机梯度下降法（stochastic gradient descent）。首先，任意选取一个超平面$\omega_0,b_0$，然后用梯度下降法不断地极小化目标函数(2.5)。极小化过程中不是一次使$M$中所有误分类点的梯度下降，而是一次随机选取一个误分类点使其梯度下降。</p>
<ul>
<li>假设误分类点集合$M$是固定的，那么损失函数$L(\omega,b)$的梯度由</li>
</ul>
<p>$$<br>\bigtriangledown_{\omega}L(\omega,b) = - \sum\limits_{x_i \in M}y_i x_i<br>$$</p>
<p>$$<br>\bigtriangledown_{b}L(\omega,b) = - \sum\limits_{x_i \in M}y_i<br>$$</p>
<p>​        给出。</p>
<ul>
<li><p>随机取一个误分类点$(x_i,y_i)$，对$\omega,b$进行更新：<br>$$<br>\omega \longleftarrow \omega \ + \ \eta y_i x_i \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ (2.6)<br>$$</p>
<p>$$<br>b \longleftarrow b\ + \ \eta y_i \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ (2.7)<br>$$</p>
</li>
</ul>
<p>式中$\eta(0&lt;\eta \le 1)$是步长，在统计学习中又称为学习率（learning rate）。这样，通过迭代可以期待损失函数$L(\omega,b)$不断减小，直到为$0$。</p>
<p><strong>算法 2.1（感知机学习算法的原始形式）</strong></p>
<p><strong>输入</strong>：训练数据集$T = {(x_1,y_1),(x_2,y_2),…,(x_N,y_N)}$，其中，$x_i \in \chi = R^n, y \in Y = {+1, -1}, i=1,2,…,N$；学习率$\eta(0&lt;\eta \le 1)$；</p>
<p><strong>输出</strong>：$\omega,b$；感知机模型$f(x)=sign(\omega·x + b)$。</p>
<p>​    （1）选取初值$\omega_0,b_0$；</p>
<p>​    （2）在训练集中选取数据$(x_i,y_i)$；</p>
<p>​    （3）如果$y_i(\omega·x_i + b) \leq 0$，<br>$$<br>\omega \longleftarrow \omega \ + \ \eta y_i x_i  \   b \longleftarrow b\ + \ \eta y_i<br>$$<br>​    （4）转至（2），直至训练集中没有误分类点。</p>
<p>这种学习算法直观上有如下解释：当一个实例点被误分类，即位于分离超平面的错误一侧时，则调整$\omega,b$的值，使分离超平面向该误分类点的一侧移动，以减少该误分类点与超平面间的距离，直至超平面越过该误分类点使其被正确分类。</p>
<p>感知机学习算法由于采用不同的初值或选取不同的误分类点，解可以不同。</p>
<h2 id="2-3-2-算法的收敛性"><a href="#2-3-2-算法的收敛性" class="headerlink" title="2.3.2 算法的收敛性"></a>2.3.2 算法的收敛性</h2><p>为了便于叙述与推导，将偏置$b$并入权重向量$\omega$，记作$\hat\omega = (\omega^T,b)^T$，同样也将输入向量加以扩充，加进常数$1$，记作$\hat x=(x^T,1)^T$。这样，$\hat x \in R^{n+1},\hat\omega \in R^{n+1}$。显然，$\hat\omega·\hat x = \omega·x + b$。</p>
<p><strong>定理 2.1（Novikoff）</strong>  设训练数据集$T = {(x_1,y_1),(x_2,y_2),…,(x_N,y_N)}$，其中，$x_i \in \chi = R^n, y \in Y = {+1, -1}, i=1,2,…,N$，则</p>
<p>​    （1）存在满足条件$||\hat\omega_{opt}||=1$的超平面$\hat\omega_{opt}·\hat x =\omega_{opt}·x+b_{opt} = 0$将训练数据集完全正确分开；且存在$\gamma&gt;0$，对所有$i=1,2,…,N$<br>$$<br>y_i(\hat\omega_{opt}·\hat x_i) = y_i(\omega_{opt}·x_i+b_{opt}) \geq \gamma \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ (2.8)<br>$$<br>​    （2）令$R=\max\limits_{1\leq i \leq N}||\hat x_i||$，则感知机算法2.1在训练数据集上的误分类次数$k$满足不等式<br>$$<br>k \leq(\frac{R}{\gamma})^2) \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ (2.9)<br>$$<br>定理表明，误分类的次数$k$是有上界的，经过有限次搜索可以找到将训练数据完全正确分开的分离超平面。也就是说，当训练数据集线性可分时，感知机学习算法原始形式迭代是收敛的。</p>
<p>感知机学习算法存在许多解，这些解既依赖与初值的选择，也依赖于迭代过程中误分类点的选择顺序。为了得到唯一的超平面，需要对分离超平面增加约束条件。</p>
<p>当训练集线性不可分时，感知机学习算法不收敛，迭代结果会放生震荡。</p>
<h2 id="2-3-3-感知机学习算法的对偶形式"><a href="#2-3-3-感知机学习算法的对偶形式" class="headerlink" title="2.3.3 感知机学习算法的对偶形式"></a>2.3.3 感知机学习算法的对偶形式</h2><p>对偶形式的基本想法是，将$\omega$和$b$表示为实例$x_i$和标记$y_i$的线性组合的形式，通过求解其系数而求得$\omega$和$b$。</p>
<p>在算法2.1中可假设初始值$\omega_0,b_0$均为0。对误分类点$(x_i,y_i)$通过<br>$$<br>\omega \longleftarrow \omega \ + \ \eta y_i x_i  \   b \longleftarrow b\ + \ \eta y_i<br>$$<br>逐步修改$\omega,b$，设修改$n$次，则$\omega,b$关于$(x_i,y_i)$的增量分别是$\alpha_i y_i x_i$和$\alpha_i y_i$，这里$\alpha_i = n_i\eta$，$n_i$是点$(x_i,y_i)$被误分类的次数。最后学习到的$\omega,b$可以分别表示为<br>$$<br>\omega = \sum\limits_{i=1}^N \alpha_i y_i x_i \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ (2.14) \ b = \sum\limits_{i=1}^N \alpha_i y_i \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ (2.15)<br>$$<br>这里，$\alpha_i \geq 0,i=1,2,…,N$，当$\eta = 1$时，表示第$i$个实例点由与误分而进行更新的次数。实例点更新次数越多，意味着它距离分离超平面越近，也就越难正确分类。换句话说，这样的实例对学习结果影响最大。</p>
<p><strong>算法 2.2（感知机学习算法的对偶形式）</strong></p>
<p><strong>输入</strong>：训练数据集$T = {(x_1,y_1),(x_2,y_2),…,(x_N,y_N)}$，其中，$x_i \in \chi = R^n, y \in Y = {+1, -1}, i=1,2,…,N$；学习率$\eta(0&lt;\eta \le 1)$；</p>
<p><strong>输出</strong>：$\alpha,b$；感知机模型$f(x)=sign(\sum\limits_{j=1}^N \alpha_j y_j x_j · x + b)$，其中$\alpha = (\alpha_1, \alpha_2,…,\alpha_N)^T$。</p>
<p>​    （1）$\alpha \longleftarrow 0, b \longleftarrow 0$；</p>
<p>​    （2）在训练集中选取数据$(x_i,y_i)$；</p>
<p>​    （3）如果$y_i(\sum\limits_{j=1}^N \alpha_j y_j x_j · x + b) \leq 0$，<br>$$<br>\alpha_i \longleftarrow \alpha_i \ + \ \eta \ b \longleftarrow b \ + \ \eta y_i<br>$$<br>​    （4）转至（2）直到没有误分类数据。</p>
<p>对偶形式中训练实例仅以内积的形式出现。为了方便，可以预先将训练集中实例间的内积计算出来并以矩阵的形式存储，这个矩阵就是所谓的$Gram$矩阵（Gram matrix）<br>$$<br>G = [x_i · x_j]_{N \times N}<br>$$<br>与原始形式一样，感知机学习算法的对偶形式迭代是收敛的，存在多个解。</p>

    </div>

    
    
    

      <footer class="post-footer">

        


        
    <div class="post-nav">
      <div class="post-nav-item">
    <a href="/2021/06/04/Python_Notes/%E7%AC%AC%E5%9B%9B%E7%AB%A0-%E6%93%8D%E4%BD%9C%E5%88%97%E8%A1%A8/" rel="prev" title="第四章 操作列表">
      <i class="fa fa-chevron-left"></i> 第四章 操作列表
    </a></div>
      <div class="post-nav-item">
    <a href="/2021/06/04/Java_Notes/Java%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/" rel="next" title="Java数据结构">
      Java数据结构 <i class="fa fa-chevron-right"></i>
    </a></div>
    </div>
      </footer>
    
  </article>
  
  
  



          </div>
          
    <div class="comments" id="valine-comments"></div>

<script>
  window.addEventListener('tabs:register', () => {
    let { activeClass } = CONFIG.comments;
    if (CONFIG.comments.storage) {
      activeClass = localStorage.getItem('comments_active') || activeClass;
    }
    if (activeClass) {
      let activeTab = document.querySelector(`a[href="#comment-${activeClass}"]`);
      if (activeTab) {
        activeTab.click();
      }
    }
  });
  if (CONFIG.comments.storage) {
    window.addEventListener('tabs:click', event => {
      if (!event.target.matches('.tabs-comment .tab-content .tab-pane')) return;
      let commentClass = event.target.classList[1];
      localStorage.setItem('comments_active', commentClass);
    });
  }
</script>

        </div>
          
  
  <div class="toggle sidebar-toggle">
    <span class="toggle-line toggle-line-first"></span>
    <span class="toggle-line toggle-line-middle"></span>
    <span class="toggle-line toggle-line-last"></span>
  </div>

  <aside class="sidebar">
    <div class="sidebar-inner">

      <ul class="sidebar-nav motion-element">
        <li class="sidebar-nav-toc">
          文章目录
        </li>
        <li class="sidebar-nav-overview">
          站点概览
        </li>
      </ul>

      <!--noindex-->
      <div class="post-toc-wrap sidebar-panel">
          <div class="post-toc motion-element"><ol class="nav"><li class="nav-item nav-level-1"><a class="nav-link" href="#2-1-%E6%84%9F%E7%9F%A5%E6%9C%BA%E6%A8%A1%E5%9E%8B"><span class="nav-number">1.</span> <span class="nav-text">2.1 感知机模型</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#2-2-%E6%84%9F%E7%9F%A5%E6%9C%BA%E5%AD%A6%E4%B9%A0%E7%AD%96%E7%95%A5"><span class="nav-number">2.</span> <span class="nav-text">2.2 感知机学习策略</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#2-2-1-%E6%95%B0%E6%8D%AE%E9%9B%86%E7%9A%84%E7%BA%BF%E6%80%A7%E5%8F%AF%E5%88%86%E6%80%A7"><span class="nav-number">2.1.</span> <span class="nav-text">2.2.1 数据集的线性可分性</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#2-2-2-%E6%84%9F%E7%9F%A5%E6%9C%BA%E5%AD%A6%E4%B9%A0%E7%AD%96%E7%95%A5"><span class="nav-number">2.2.</span> <span class="nav-text">2.2.2 感知机学习策略</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#2-3-%E6%84%9F%E7%9F%A5%E6%9C%BA%E5%AD%A6%E4%B9%A0%E7%AE%97%E6%B3%95"><span class="nav-number">3.</span> <span class="nav-text">2.3 感知机学习算法</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#2-3-2-%E7%AE%97%E6%B3%95%E7%9A%84%E6%94%B6%E6%95%9B%E6%80%A7"><span class="nav-number">3.1.</span> <span class="nav-text">2.3.2 算法的收敛性</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#2-3-3-%E6%84%9F%E7%9F%A5%E6%9C%BA%E5%AD%A6%E4%B9%A0%E7%AE%97%E6%B3%95%E7%9A%84%E5%AF%B9%E5%81%B6%E5%BD%A2%E5%BC%8F"><span class="nav-number">3.2.</span> <span class="nav-text">2.3.3 感知机学习算法的对偶形式</span></a></li></ol></li></ol></div>
      </div>
      <!--/noindex-->

      <div class="site-overview-wrap sidebar-panel">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
    <img class="site-author-image" itemprop="image" alt="Normal People"
      src="/images/posthead.jpg">
  <p class="site-author-name" itemprop="name">Normal People</p>
  <div class="site-description" itemprop="description">Get busy living or get busy dying</div>
</div>
<div class="site-state-wrap motion-element">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
          <a href="/archives">
        
          <span class="site-state-item-count">26</span>
          <span class="site-state-item-name">日志</span>
        </a>
      </div>
      <div class="site-state-item site-state-categories">
            <a href="/categories">
          
        <span class="site-state-item-count">6</span>
        <span class="site-state-item-name">分类</span></a>
      </div>
  </nav>
</div>
  <div class="links-of-author motion-element">
      <span class="links-of-author-item">
        <a href="https://github.com/TheNormalPeople" title="GitHub → https:&#x2F;&#x2F;github.com&#x2F;TheNormalPeople" rel="noopener" target="_blank"><i class="fab fa-github fa-fw"></i>GitHub</a>
      </span>
      <span class="links-of-author-item">
        <a href="mailto:1272481411@qq.com" title="E-Mail → mailto:1272481411@qq.com" rel="noopener" target="_blank"><i class="fa fa-envelope fa-fw"></i>E-Mail</a>
      </span>
      <span class="links-of-author-item">
        <a href="https://weibo.com/u/5938927274" title="Weibo → https:&#x2F;&#x2F;weibo.com&#x2F;u&#x2F;5938927274" rel="noopener" target="_blank"><i class="fab fa-weibo fa-fw"></i>Weibo</a>
      </span>
      <span class="links-of-author-item">
        <a href="https://instagram.com/cy19970506" title="Instagram → https:&#x2F;&#x2F;instagram.com&#x2F;cy19970506" rel="noopener" target="_blank"><i class="fab fa-instagram fa-fw"></i>Instagram</a>
      </span>
  </div>



      </div>

    </div>
  </aside>
  <div id="sidebar-dimmer"></div>


      </div>
    </main>

    <footer class="footer">
      <div class="footer-inner">
        

        

<div class="copyright">
  
  &copy; 
  <span itemprop="copyrightYear">2021</span>
  <span class="with-love">
    <i class="heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">Normal People</span>
</div>

        








      </div>
    </footer>
  </div>

  
  <script src="/lib/anime.min.js"></script>
  <script src="/lib/velocity/velocity.min.js"></script>
  <script src="/lib/velocity/velocity.ui.min.js"></script>

<script src="/js/utils.js"></script>

<script src="/js/motion.js"></script>


<script src="/js/schemes/pisces.js"></script>


<script src="/js/next-boot.js"></script>




  















  

  
      

<script>
  if (typeof MathJax === 'undefined') {
    window.MathJax = {
      loader: {
        source: {
          '[tex]/amsCd': '[tex]/amscd',
          '[tex]/AMScd': '[tex]/amscd'
        }
      },
      tex: {
        inlineMath: {'[+]': [['$', '$']]},
        tags: 'ams'
      },
      options: {
        renderActions: {
          findScript: [10, doc => {
            document.querySelectorAll('script[type^="math/tex"]').forEach(node => {
              const display = !!node.type.match(/; *mode=display/);
              const math = new doc.options.MathItem(node.textContent, doc.inputJax[0], display);
              const text = document.createTextNode('');
              node.parentNode.replaceChild(text, node);
              math.start = {node: text, delim: '', n: 0};
              math.end = {node: text, delim: '', n: 0};
              doc.math.push(math);
            });
          }, '', false],
          insertedScript: [200, () => {
            document.querySelectorAll('mjx-container').forEach(node => {
              let target = node.parentNode;
              if (target.nodeName.toLowerCase() === 'li') {
                target.parentNode.classList.add('has-jax');
              }
            });
          }, '', false]
        }
      }
    };
    (function () {
      var script = document.createElement('script');
      script.src = '//cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js';
      script.defer = true;
      document.head.appendChild(script);
    })();
  } else {
    MathJax.startup.document.state(0);
    MathJax.texReset();
    MathJax.typeset();
  }
</script>

    

  


<script>
NexT.utils.loadComments(document.querySelector('#valine-comments'), () => {
  NexT.utils.getScript('//unpkg.com/valine/dist/Valine.min.js', () => {
    var GUEST = ['nick', 'mail', 'link'];
    var guest = 'nick,mail,link';
    guest = guest.split(',').filter(item => {
      return GUEST.includes(item);
    });
    new Valine({
      el         : '#valine-comments',
      verify     : false,
      notify     : false,
      appId      : 'y8XFURQNCoQsprRTou9DiEJu-gzGzoHsz',
      appKey     : 'QfVpjKDtJQdJrnJNnWUbVvjH',
      placeholder: "留下邮箱,有空时间回复您！",
      avatar     : 'mm',
      meta       : guest,
      pageSize   : '10' || 10,
      visitor    : false,
      lang       : '' || 'zh-cn',
      path       : location.pathname,
      recordIP   : false,
      serverURLs : ''
    });
  }, window.Valine);
});
</script>

</body>
</html>
