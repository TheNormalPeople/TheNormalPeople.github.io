<!DOCTYPE html>
<html lang="zh-CN">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
<meta name="theme-color" content="#222">
<meta name="generator" content="Hexo 5.4.0">
  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png">
  <link rel="mask-icon" href="/images/logo.svg" color="#222">

<link rel="stylesheet" href="/css/main.css">


<link rel="stylesheet" href="/lib/font-awesome/css/all.min.css">

<script id="hexo-configurations">
    var NexT = window.NexT || {};
    var CONFIG = {"hostname":"example.com","root":"/","scheme":"Pisces","version":"7.8.0","exturl":false,"sidebar":{"position":"left","display":"post","padding":18,"offset":12,"onmobile":true,"scrollpercent":true,"b2t":true},"copycode":{"enable":true,"show_result":true,"style":null},"back2top":{"enable":true,"sidebar":false,"scrollpercent":false},"bookmark":{"enable":false,"color":"#222","save":"auto"},"fancybox":false,"mediumzoom":false,"lazyload":false,"pangu":false,"comments":{"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},"algolia":{"hits":{"per_page":10},"labels":{"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}},"localsearch":{"enable":false,"trigger":"auto","top_n_per_article":1,"unescape":false,"preload":false},"motion":{"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}}};
  </script>

  <meta name="description" content="1. HDFS的文件块大小 物理存储块（block）大小为128M，由寻址时间和传输时间决定（寻址时间为传输时间的1%为最佳）。 块大小设置太小会增加寻址时间，设置太大会增加传输时间。  2. HDFS的读写流程 写数据流程 客户端通过Distributed FileSystem模块向NameNode请求上传文件，NameNode检查目标文件是否已存在，父目录是否存在。   NameNode返回是">
<meta property="og:type" content="article">
<meta property="og:title" content="Hadoop">
<meta property="og:url" content="http://example.com/2023/04/04/BigData/Hadoop/Hadoop/index.html">
<meta property="og:site_name" content="Blog">
<meta property="og:description" content="1. HDFS的文件块大小 物理存储块（block）大小为128M，由寻址时间和传输时间决定（寻址时间为传输时间的1%为最佳）。 块大小设置太小会增加寻址时间，设置太大会增加传输时间。  2. HDFS的读写流程 写数据流程 客户端通过Distributed FileSystem模块向NameNode请求上传文件，NameNode检查目标文件是否已存在，父目录是否存在。   NameNode返回是">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="http://example.com/2023/04/04/BigData/Hadoop/Hadoop/ipic/数据切片与MapTask并行度决定机制-1680224243814.png">
<meta property="og:image" content="http://example.com/2023/04/04/BigData/Hadoop/Hadoop/ipic/MapReduce详细工作流程.png">
<meta property="og:image" content="http://example.com/2023/04/04/BigData/Hadoop/Hadoop/ipic/MapReduce详细工作流程2.png">
<meta property="og:image" content="http://example.com/2023/04/04/BigData/Hadoop/Hadoop/ipic/Shuffle机制.png">
<meta property="og:image" content="http://example.com/2023/04/04/BigData/Hadoop/Hadoop/ipic/Partition分区总结.png">
<meta property="og:image" content="http://example.com/2023/04/04/BigData/Hadoop/Hadoop/ipic/MapReduce排序概述.png">
<meta property="og:image" content="http://example.com/2023/04/04/BigData/Hadoop/Hadoop/ipic/combiner合并.png">
<meta property="og:image" content="http://example.com/2023/04/04/BigData/Hadoop/Hadoop/ipic/Yarn基础架构.png">
<meta property="og:image" content="http://example.com/2023/04/04/BigData/Hadoop/Hadoop/ipic/Yarn工作机制.png">
<meta property="og:image" content="http://example.com/2023/04/04/BigData/Hadoop/Hadoop/ipic/FIFO调度器.png">
<meta property="og:image" content="http://example.com/2023/04/04/BigData/Hadoop/Hadoop/ipic/容量调度器特点-1680336513973.png">
<meta property="og:image" content="http://example.com/2023/04/04/BigData/Hadoop/Hadoop/ipic/容量调度器资源分配算法.png">
<meta property="og:image" content="http://example.com/2023/04/04/BigData/Hadoop/Hadoop/ipic/公平调度器特点.png">
<meta property="og:image" content="http://example.com/2023/04/04/BigData/Hadoop/Hadoop/ipic/公平调度器概念-缺额.png">
<meta property="og:image" content="http://example.com/2023/04/04/BigData/Hadoop/Hadoop/ipic/公平调度器资源分配方式.png">
<meta property="og:image" content="http://example.com/2023/04/04/BigData/Hadoop/Hadoop/ipic/公平调度器队列资源分配方式2.png">
<meta property="article:published_time" content="2023-04-04T14:03:05.931Z">
<meta property="article:modified_time" content="2023-04-04T14:09:10.424Z">
<meta property="article:author" content="Normal People">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="http://example.com/2023/04/04/BigData/Hadoop/Hadoop/ipic/数据切片与MapTask并行度决定机制-1680224243814.png">

<link rel="canonical" href="http://example.com/2023/04/04/BigData/Hadoop/Hadoop/">


<script id="page-configurations">
  // https://hexo.io/docs/variables.html
  CONFIG.page = {
    sidebar: "",
    isHome : false,
    isPost : true,
    lang   : 'zh-CN'
  };
</script>

  <title>Hadoop | Blog</title>
  






  <noscript>
  <style>
  .use-motion .brand,
  .use-motion .menu-item,
  .sidebar-inner,
  .use-motion .post-block,
  .use-motion .pagination,
  .use-motion .comments,
  .use-motion .post-header,
  .use-motion .post-body,
  .use-motion .collection-header { opacity: initial; }

  .use-motion .site-title,
  .use-motion .site-subtitle {
    opacity: initial;
    top: initial;
  }

  .use-motion .logo-line-before i { left: initial; }
  .use-motion .logo-line-after i { right: initial; }
  </style>
</noscript>

</head>

<body itemscope itemtype="http://schema.org/WebPage">
  <div class="container use-motion">
    <div class="headband"></div>

    <header class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="切换导航栏">
      <span class="toggle-line toggle-line-first"></span>
      <span class="toggle-line toggle-line-middle"></span>
      <span class="toggle-line toggle-line-last"></span>
    </div>
  </div>

  <div class="site-meta">

    <a href="/" class="brand" rel="start">
      <span class="logo-line-before"><i></i></span>
      <h1 class="site-title">Blog</h1>
      <span class="logo-line-after"><i></i></span>
    </a>
      <p class="site-subtitle" itemprop="description">by Normal People</p>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger">
    </div>
  </div>
</div>




<nav class="site-nav">
  <ul id="menu" class="main-menu menu">
        <li class="menu-item menu-item-home">

    <a href="/" rel="section"><i class="fa fa-home fa-fw"></i>首页</a>

  </li>
        <li class="menu-item menu-item-about">

    <a href="/about" rel="section"><i class="fa fa-user fa-fw"></i>关于</a>

  </li>
        <li class="menu-item menu-item-tags">

    <a href="/tags" rel="section"><i class="fa fa-tags fa-fw"></i>标签<span class="badge">0</span></a>

  </li>
        <li class="menu-item menu-item-categories">

    <a href="/categories" rel="section"><i class="fa fa-th fa-fw"></i>分类<span class="badge">16</span></a>

  </li>
        <li class="menu-item menu-item-archives">

    <a href="/archives" rel="section"><i class="fa fa-archive fa-fw"></i>归档<span class="badge">41</span></a>

  </li>
  </ul>
</nav>




</div>
    </header>

    
  <div class="back-to-top">
    <i class="fa fa-arrow-up"></i>
    <span>0%</span>
  </div>


    <main class="main">
      <div class="main-inner">
        <div class="content-wrap">
          

          <div class="content post posts-expand">
            

    
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="http://example.com/2023/04/04/BigData/Hadoop/Hadoop/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/posthead.jpg">
      <meta itemprop="name" content="Normal People">
      <meta itemprop="description" content="Get busy living or get busy dying">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Blog">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          Hadoop
        </h1>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>
              

              <time title="创建时间：2023-04-04 22:03:05 / 修改时间：22:09:10" itemprop="dateCreated datePublished" datetime="2023-04-04T22:03:05+08:00">2023-04-04</time>
            </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/BigData/" itemprop="url" rel="index"><span itemprop="name">BigData</span></a>
                </span>
                  ，
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/BigData/Hadoop/" itemprop="url" rel="index"><span itemprop="name">Hadoop</span></a>
                </span>
            </span>

          
  
  <span class="post-meta-item">
    
      <span class="post-meta-item-icon">
        <i class="far fa-comment"></i>
      </span>
      <span class="post-meta-item-text">Valine：</span>
    
    <a title="valine" href="/2023/04/04/BigData/Hadoop/Hadoop/#valine-comments" itemprop="discussionUrl">
      <span class="post-comments-count valine-comment-count" data-xid="/2023/04/04/BigData/Hadoop/Hadoop/" itemprop="commentCount"></span>
    </a>
  </span>
  
  

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
        <h1 id="1-HDFS的文件块大小"><a href="#1-HDFS的文件块大小" class="headerlink" title="1. HDFS的文件块大小"></a>1. HDFS的文件块大小</h1><ol>
<li>物理存储块（block）大小为128M，由寻址时间和传输时间决定（寻址时间为传输时间的1%为最佳）。</li>
<li>块大小设置太小会增加寻址时间，设置太大会增加传输时间。</li>
</ol>
<h1 id="2-HDFS的读写流程"><a href="#2-HDFS的读写流程" class="headerlink" title="2. HDFS的读写流程"></a>2. HDFS的读写流程</h1><ul>
<li>写数据流程<ul>
<li>客户端通过Distributed FileSystem模块向NameNode请求上传文件，NameNode检查目标文件是否已存在，父目录是否存在。  </li>
<li>NameNode返回是否可以上传。  </li>
<li>客户端请求第一个 Block上传到哪几个DataNode服务器上。  </li>
<li>NameNode返回3个DataNode节点，分别为dn1、dn2、dn3。  </li>
<li>客户端通过FSDataOutputStream模块请求dn1上传数据，dn1收到请求会继续调用dn2，然后dn2调用dn3，将这个通信管道建立完成。  </li>
<li>dn1、dn2、dn3逐级应答客户端。</li>
<li>客户端开始往dn1上传第一个Block（先从磁盘读取数据放到一个本地内存缓存），以Packet为单位，dn1收到一个Packet就会传给dn2，dn2传给dn3；dn1每传一个packet会放入一个应答队列等待应答。</li>
<li>当一个Block传输完成之后，客户端再次请求NameNode上传第二个Block的服务器。（重复执行3-7步）。</li>
</ul>
</li>
<li>读数据流程<ul>
<li>客户端通过DistributedFileSystem向NameNode请求下载文件，NameNode通过查询元数据，找到文件块所在的DataNode地址。</li>
<li>挑选一台DataNode（就近原则，然后随机）服务器，请求读取数据。</li>
<li>DataNode开始传输数据给客户端（从磁盘里面读取数据输入流，以Packet为单位来做校验）。</li>
<li>客户端以Packet为单位接收，先在本地缓存，然后写入目标文件。  </li>
</ul>
</li>
</ul>
<h1 id="3-NameNode和SecondaryNameNode"><a href="#3-NameNode和SecondaryNameNode" class="headerlink" title="3.NameNode和SecondaryNameNode"></a>3.NameNode和SecondaryNameNode</h1><h3 id="第一阶段：NameNode启动"><a href="#第一阶段：NameNode启动" class="headerlink" title="第一阶段：NameNode启动"></a>第一阶段：NameNode启动</h3><p>（1）第一次启动NameNode格式化后，创建Fsimage和Edits文件。如果不是第一次启动，直接加载编辑日志和镜像文件到内存。</p>
<p>（2）客户端对元数据进行增删改的请求。</p>
<p>（3）NameNode记录操作日志，更新滚动日志。</p>
<p>（4）NameNode在内存中对元数据进行增删改。</p>
<h3 id="第二阶段：Secondary-NameNode工作"><a href="#第二阶段：Secondary-NameNode工作" class="headerlink" title="第二阶段：Secondary NameNode工作"></a>第二阶段：Secondary NameNode工作</h3><p>（1）Secondary NameNode询问NameNode是否需要CheckPoint。直接带回NameNode是否检查结果。</p>
<p>（2）Secondary NameNode请求执行CheckPoint。</p>
<p>（3）NameNode滚动正在写的Edits日志。</p>
<p>（4）将滚动前的编辑日志和镜像文件拷贝到Secondary NameNode。</p>
<p>（5）Secondary NameNode加载编辑日志和镜像文件到内存，并合并。</p>
<p>（6）生成新的镜像文件fsimage.chkpoint。</p>
<p>（7）拷贝fsimage.chkpoint到NameNode。</p>
<p>（8）NameNode将fsimage.chkpoint重新命名成fsimage。</p>
<p><strong>fsimage为元数据镜像文件，edits为元数据变更操作日志，均存储在磁盘上，NameNode启动时加载到内存。</strong></p>
<h1 id="4-DataNode"><a href="#4-DataNode" class="headerlink" title="4.DataNode"></a>4.DataNode</h1><h3 id="DataNode工作机制"><a href="#DataNode工作机制" class="headerlink" title="DataNode工作机制"></a>DataNode工作机制</h3><p>（1）一个数据块在DataNode上以文件形式存储在磁盘上，包括两个文件，一个是数据本身，一个是元数据包括数据块的长度，块数据的校验和，以及时间戳。</p>
<p>（2）DataNode启动后向NameNode注册，通过后，周期性（6小时）的向NameNode上报所有的块信息。</p>
<p>（3）心跳是每3秒一次，心跳返回结果带有NameNode给该DataNode的命令如复制块数据到另一台机器，或删除某个数据块。如果超过10分钟没有收到某个DataNode的心跳，则认为该节点不可用。</p>
<p>（4）集群运行中可以安全加入和退出一些机器。</p>
<h3 id="DataNode节点数据完整性"><a href="#DataNode节点数据完整性" class="headerlink" title="DataNode节点数据完整性"></a>DataNode节点数据完整性</h3><p>（1）当DataNode读取Block的时候，它会计算CheckSum。</p>
<p>（2）如果计算后的CheckSum，与Block创建时值不一样，说明Block已经损坏。</p>
<p>（3）Client读取其他DataNode上的Block。</p>
<p>（4）常见的校验算法crc（32），md5（128），sha1（160）</p>
<p>（5）DataNode在其文件创建后周期验证CheckSum。</p>
<h1 id="5-MapReduce"><a href="#5-MapReduce" class="headerlink" title="5. MapReduce"></a>5. MapReduce</h1><h3 id="MapReduce进程"><a href="#MapReduce进程" class="headerlink" title="MapReduce进程"></a>MapReduce进程</h3><p>一个完整的MapReduce程序在分布式运行时有三类实例进程：</p>
<p>（1）<strong>MrAppMaster</strong>：负责整个程序的过程调度及状态协调。</p>
<p>（2）<strong>MapTask</strong>：负责Map阶段的整个数据处理流程。</p>
<p>（3）<strong>ReduceTask</strong>：负责Reduce阶段的整个数据处理流程。</p>
<h3 id="Hadoop序列化"><a href="#Hadoop序列化" class="headerlink" title="Hadoop序列化"></a>Hadoop序列化</h3><ul>
<li><p><strong>序列化</strong>就是把内存中的对象，转换成字节序列（或其他数据传输协议）以便于存储到磁盘（持久化）和网络传输。 </p>
</li>
<li><p><strong>反序列化</strong>就是将收到字节序列（或其他数据传输协议）或者是磁盘的持久化数据，转换成内存中的对象。</p>
</li>
</ul>
<p>Java的序列化是一个重量级序列化框架（Serializable），一个对象被序列化后，会附带很多额外的信息（各种校验信息，Header，继承体系等），不便于在网络中高效传输。所以，Hadoop自己开发了一套序列化机制（Writable）。</p>
<h3 id="MapReduce框架原理"><a href="#MapReduce框架原理" class="headerlink" title="MapReduce框架原理"></a>MapReduce框架原理</h3><ul>
<li><strong>MapTask并行度决定机制</strong> <ul>
<li><strong>数据块：</strong>Block是HDFS物理上把数据分成一块一块。数据块是HDFS存储数据单位。</li>
<li><strong>数据切片：</strong>数据切片只是在逻辑上对输入进行分片，并不会在磁盘上将其切分成片进行存储。数据切片是MapReduce程序计算输入数据的单位，一个切片会对应启动一个MapTask。  </li>
</ul>
</li>
</ul>
<p><img src="ipic/数据切片与MapTask并行度决定机制-1680224243814.png" alt="数据切片与MapTask并行度决定机制"></p>
<p>==注：每次切片时，都要判断切完剩下的部分是否大于块的1.1倍，不大于1.1倍就划分一块切片。==</p>
<p>提交切片规划文件到YARN上，YARN上的MrAppMaster就可以根据切片规划文件计算开启MapTask的个数。</p>
<h3 id="MapReduce工作流程"><a href="#MapReduce工作流程" class="headerlink" title="MapReduce工作流程"></a>MapReduce工作流程</h3><p><img src="ipic/MapReduce详细工作流程.png" alt="MapReduce详细工作流程"></p>
<p><img src="ipic/MapReduce详细工作流程2.png" alt="MapReduce详细工作流程2"></p>
<ul>
<li><p>Shuffle过程详解 </p>
<p>（1）MapTask收集我们的map()方法输出的kv对，放到内存缓冲区中；</p>
<p>（2）从内存缓冲区不断溢出本地磁盘文件，可能会溢出多个文件；</p>
<p>（3）多个溢出文件会被合并成大的溢出文件；</p>
<p>（4）在溢出过程及合并的过程中，都要调用Partitioner进行分区和针对key进行排序；</p>
<p>（5）ReduceTask根据自己的分区号，去各个MapTask机器上取相应的结果分区数据；</p>
<p>（6）ReduceTask会抓取到同一个分区的来自不同MapTask的结果文件，ReduceTask会将这些文件再进行合并（归并排序）</p>
<p>（7）合并成大文件后，Shuffle的过程也就结束了，后面进入ReduceTask的逻辑运算过程（从文件中取出一个一个的键值对Group，调用用户自定义的reduce()方法）</p>
<p>==<strong>注意：</strong>==</p>
<p>==（1）Shuffle中的缓冲区大小会影响到MapReduce程序的执行效率，原则上说，缓冲区越大，磁盘io的次数越少，执行速度就越快。==</p>
<p>==（2）缓冲区的大小可以通过参数调整，参数：mapreduce.task.io.sort.mb默认100M。==</p>
</li>
</ul>
<h3 id="Shuffle机制"><a href="#Shuffle机制" class="headerlink" title="Shuffle机制"></a>Shuffle机制</h3><p><strong>==Map方法之后，Reduce方法之前==的数据处理过程称之为Shuffle。</strong></p>
<p><img src="ipic/Shuffle机制.png" alt="Shuffle机制"></p>
<h3 id="Partition分区"><a href="#Partition分区" class="headerlink" title="Partition分区"></a>Partition分区</h3><p>==默认分区是根据key的hash code对Reduce Tasks个数取模得到的。用户没法控制哪个key存储到哪个分区。==</p>
<p><img src="ipic/Partition分区总结.png" alt="Partition分区总结"></p>
<h3 id="WritableComparable排序"><a href="#WritableComparable排序" class="headerlink" title="WritableComparable排序"></a>WritableComparable排序</h3><p>MapTask和ReduceTask均会对数据按照key进行排序。该操作属于Hadoop的默认行为。==任何应用程序中的数据均会被排序，而不管逻辑上是否需要。==</p>
<p>默认排序是按照字典顺序排序，且实现该排序的方法是快速排序。</p>
<p><img src="ipic/MapReduce排序概述.png" alt="MapReduce排序概述"></p>
<h3 id="Combiner合并"><a href="#Combiner合并" class="headerlink" title="Combiner合并"></a>Combiner合并</h3><p><img src="ipic/combiner合并.png" alt="combiner合并"></p>
<p>==注：如果分区数不是1，但是ReduceTask为1，不执行分区过程。==</p>
<h3 id="Reduce-Join-（适合处理两个大表，需要多次进行磁盘IO）"><a href="#Reduce-Join-（适合处理两个大表，需要多次进行磁盘IO）" class="headerlink" title="Reduce Join  （适合处理两个大表，需要多次进行磁盘IO）"></a>Reduce Join  （适合处理两个大表，需要多次进行磁盘IO）</h3><p>Reduce join也称为Reduce端连接，适用于两个数据集的大小相当的情况。在Reduce join中，Map阶段将两个数据集中的记录分别标记为“left”和“right”，然后将它们分别输出到不同的Reducer中。 </p>
<p>以下是一些可能导致Reduce join数据倾斜的原因：</p>
<ol>
<li>连接键不合适：连接键的选择非常重要。如果选择的连接键分布不均匀，则会导致数据倾斜。例如，如果连接键是用户ID，而用户ID分布不均匀，则可能会导致数据倾斜。</li>
<li>数据分区不均匀：如果分区是基于连接键进行的，那么连接键分布不均匀也会导致数据分区不均匀，最终导致Reduce端数据倾斜。</li>
<li>数据倾斜的处理方式不当：处理数据倾斜的方式有很多种，但不同的方式适用于不同的情况。如果选择的方法不合适，则会导致更严重的数据倾斜问题。</li>
</ol>
<h3 id="Map-Join-（适合处理一个大表一个小表）"><a href="#Map-Join-（适合处理一个大表一个小表）" class="headerlink" title="Map Join  （适合处理一个大表一个小表）"></a>Map Join  （适合处理一个大表一个小表）</h3><p>Map join也称为Map端连接，适用于其中一个数据集比较小的情况。在Map join中，首先读取小的数据集并放入内存中，然后在Map阶段读取另一个大数据集的记录，并与内存中的小数据集进行连接。 </p>
<h3 id="数据清洗（ETL）"><a href="#数据清洗（ETL）" class="headerlink" title="数据清洗（ETL）"></a>数据清洗（ETL）</h3><p>在运行核心业务MapReduce程序之前，往往要先对数据进行清洗，清理掉不符合用户要求的数据。清理的过程往往只需要运行Mapper程序，不需要运行Reduce程序。</p>
<h1 id="6-Yarn"><a href="#6-Yarn" class="headerlink" title="6. Yarn"></a>6. Yarn</h1><h3 id="Yarn基础架构"><a href="#Yarn基础架构" class="headerlink" title="Yarn基础架构"></a>Yarn基础架构</h3><p>YARN主要由<strong>ResourceManager</strong>、<strong>NodeManager</strong>、<strong>ApplicationMaster</strong>和<strong>Container</strong>等组件构成。</p>
<p><img src="ipic/Yarn基础架构.png" alt="Yarn基础架构"></p>
<h3 id="Yarn工作机制"><a href="#Yarn工作机制" class="headerlink" title="Yarn工作机制"></a>Yarn工作机制</h3><p><img src="ipic/Yarn工作机制.png" alt="Yarn工作机制"></p>
<p>（1）MR程序提交到客户端所在的节点。</p>
<p>（2）YarnRunner向ResourceManager申请一个Application。</p>
<p>（3）RM将该应用程序的资源路径返回给YarnRunner。</p>
<p>（4）该程序将运行所需资源提交到HDFS上。</p>
<p>（5）程序资源提交完毕后，申请运行mrAppMaster。</p>
<p>（6）RM将用户的请求初始化成一个Task。</p>
<p>（7）其中一个NodeManager领取到Task任务。</p>
<p>（8）该NodeManager创建容器Container，并产生MRAppmaster。</p>
<p>（9）Container从HDFS上拷贝资源到本地。</p>
<p>（10）MRAppmaster向RM 申请运行MapTask资源。</p>
<p>（11）RM将运行MapTask任务分配给另外两个NodeManager，另两个NodeManager分别领取任务并创建容器。</p>
<p>（12）MR向两个接收到任务的NodeManager发送程序启动脚本，这两个NodeManager分别启动MapTask，MapTask对数据分区排序。</p>
<p>（13）MrAppMaster等待所有MapTask运行完毕后，向RM申请容器，运行ReduceTask。</p>
<p>（14）ReduceTask向MapTask获取相应分区的数据。</p>
<p>（15）程序运行完毕后，MR会向RM申请注销自己。</p>
<h3 id="Yarn调度器和调度算法"><a href="#Yarn调度器和调度算法" class="headerlink" title="Yarn调度器和调度算法"></a>Yarn调度器和调度算法</h3><p>Hadoop作业调度器主要有三种：<strong>FIFO</strong>、<strong>容量（Capacity Scheduler）</strong>和<strong>公平（Fair Scheduler）</strong>。  </p>
<p>==Hadoop3.1.3默认的资源调度器是Capacity Scheduler。==  </p>
<ul>
<li><strong>FIFO调度器（First In First Out）</strong>：单队列，根据提交作业的先后顺序，先来先服务。</li>
</ul>
<p><img src="ipic/FIFO调度器.png" alt="FIFO调度器"></p>
<ul>
<li><strong>容量调度器 (Capacity Scheduler)</strong>是Yahoo开发的多用户调度器。</li>
</ul>
<p><img src="ipic/容量调度器特点-1680336513973.png" alt="容量调度器特点"></p>
<p><img src="ipic/容量调度器资源分配算法.png" alt="容量调度器资源分配算法"></p>
<ul>
<li><strong>公平调度器（Fair Scheduler）</strong>是Facebook开发的多用户调度器。  </li>
</ul>
<p><img src="ipic/公平调度器特点.png" alt="公平调度器特点"></p>
<p><img src="ipic/公平调度器概念-缺额.png" alt="公平调度器概念-缺额"></p>
<p><img src="ipic/公平调度器资源分配方式.png" alt="公平调度器资源分配方式"></p>
<p><img src="ipic/公平调度器队列资源分配方式2.png" alt="公平调度器队列资源分配方式2"></p>

    </div>

    
    
    

      <footer class="post-footer">

        


        
    <div class="post-nav">
      <div class="post-nav-item">
    <a href="/2021/09/10/LeetCode_Solution/1894.%E6%89%BE%E5%88%B0%E9%9C%80%E8%A6%81%E8%A1%A5%E5%85%85%E7%B2%89%E7%AC%94%E7%9A%84%E5%AD%A6%E7%94%9F%E7%BC%96%E5%8F%B7/" rel="prev" title="1894.找到需要补充粉笔的学生编号">
      <i class="fa fa-chevron-left"></i> 1894.找到需要补充粉笔的学生编号
    </a></div>
      <div class="post-nav-item">
    <a href="/2023/04/04/BigData/HBase/HBase/" rel="next" title="HBase">
      HBase <i class="fa fa-chevron-right"></i>
    </a></div>
    </div>
      </footer>
    
  </article>
  
  
  



          </div>
          
    <div class="comments" id="valine-comments"></div>

<script>
  window.addEventListener('tabs:register', () => {
    let { activeClass } = CONFIG.comments;
    if (CONFIG.comments.storage) {
      activeClass = localStorage.getItem('comments_active') || activeClass;
    }
    if (activeClass) {
      let activeTab = document.querySelector(`a[href="#comment-${activeClass}"]`);
      if (activeTab) {
        activeTab.click();
      }
    }
  });
  if (CONFIG.comments.storage) {
    window.addEventListener('tabs:click', event => {
      if (!event.target.matches('.tabs-comment .tab-content .tab-pane')) return;
      let commentClass = event.target.classList[1];
      localStorage.setItem('comments_active', commentClass);
    });
  }
</script>

        </div>
          
  
  <div class="toggle sidebar-toggle">
    <span class="toggle-line toggle-line-first"></span>
    <span class="toggle-line toggle-line-middle"></span>
    <span class="toggle-line toggle-line-last"></span>
  </div>

  <aside class="sidebar">
    <div class="sidebar-inner">

      <ul class="sidebar-nav motion-element">
        <li class="sidebar-nav-toc">
          文章目录
        </li>
        <li class="sidebar-nav-overview">
          站点概览
        </li>
      </ul>

      <!--noindex-->
      <div class="post-toc-wrap sidebar-panel">
          <div class="post-toc motion-element"><ol class="nav"><li class="nav-item nav-level-1"><a class="nav-link" href="#1-HDFS%E7%9A%84%E6%96%87%E4%BB%B6%E5%9D%97%E5%A4%A7%E5%B0%8F"><span class="nav-number">1.</span> <span class="nav-text">1. HDFS的文件块大小</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#2-HDFS%E7%9A%84%E8%AF%BB%E5%86%99%E6%B5%81%E7%A8%8B"><span class="nav-number">2.</span> <span class="nav-text">2. HDFS的读写流程</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#3-NameNode%E5%92%8CSecondaryNameNode"><span class="nav-number">3.</span> <span class="nav-text">3.NameNode和SecondaryNameNode</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#%E7%AC%AC%E4%B8%80%E9%98%B6%E6%AE%B5%EF%BC%9ANameNode%E5%90%AF%E5%8A%A8"><span class="nav-number">3.0.1.</span> <span class="nav-text">第一阶段：NameNode启动</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E7%AC%AC%E4%BA%8C%E9%98%B6%E6%AE%B5%EF%BC%9ASecondary-NameNode%E5%B7%A5%E4%BD%9C"><span class="nav-number">3.0.2.</span> <span class="nav-text">第二阶段：Secondary NameNode工作</span></a></li></ol></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#4-DataNode"><span class="nav-number">4.</span> <span class="nav-text">4.DataNode</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#DataNode%E5%B7%A5%E4%BD%9C%E6%9C%BA%E5%88%B6"><span class="nav-number">4.0.1.</span> <span class="nav-text">DataNode工作机制</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#DataNode%E8%8A%82%E7%82%B9%E6%95%B0%E6%8D%AE%E5%AE%8C%E6%95%B4%E6%80%A7"><span class="nav-number">4.0.2.</span> <span class="nav-text">DataNode节点数据完整性</span></a></li></ol></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#5-MapReduce"><span class="nav-number">5.</span> <span class="nav-text">5. MapReduce</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#MapReduce%E8%BF%9B%E7%A8%8B"><span class="nav-number">5.0.1.</span> <span class="nav-text">MapReduce进程</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Hadoop%E5%BA%8F%E5%88%97%E5%8C%96"><span class="nav-number">5.0.2.</span> <span class="nav-text">Hadoop序列化</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#MapReduce%E6%A1%86%E6%9E%B6%E5%8E%9F%E7%90%86"><span class="nav-number">5.0.3.</span> <span class="nav-text">MapReduce框架原理</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#MapReduce%E5%B7%A5%E4%BD%9C%E6%B5%81%E7%A8%8B"><span class="nav-number">5.0.4.</span> <span class="nav-text">MapReduce工作流程</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Shuffle%E6%9C%BA%E5%88%B6"><span class="nav-number">5.0.5.</span> <span class="nav-text">Shuffle机制</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Partition%E5%88%86%E5%8C%BA"><span class="nav-number">5.0.6.</span> <span class="nav-text">Partition分区</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#WritableComparable%E6%8E%92%E5%BA%8F"><span class="nav-number">5.0.7.</span> <span class="nav-text">WritableComparable排序</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Combiner%E5%90%88%E5%B9%B6"><span class="nav-number">5.0.8.</span> <span class="nav-text">Combiner合并</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Reduce-Join-%EF%BC%88%E9%80%82%E5%90%88%E5%A4%84%E7%90%86%E4%B8%A4%E4%B8%AA%E5%A4%A7%E8%A1%A8%EF%BC%8C%E9%9C%80%E8%A6%81%E5%A4%9A%E6%AC%A1%E8%BF%9B%E8%A1%8C%E7%A3%81%E7%9B%98IO%EF%BC%89"><span class="nav-number">5.0.9.</span> <span class="nav-text">Reduce Join  （适合处理两个大表，需要多次进行磁盘IO）</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Map-Join-%EF%BC%88%E9%80%82%E5%90%88%E5%A4%84%E7%90%86%E4%B8%80%E4%B8%AA%E5%A4%A7%E8%A1%A8%E4%B8%80%E4%B8%AA%E5%B0%8F%E8%A1%A8%EF%BC%89"><span class="nav-number">5.0.10.</span> <span class="nav-text">Map Join  （适合处理一个大表一个小表）</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E6%95%B0%E6%8D%AE%E6%B8%85%E6%B4%97%EF%BC%88ETL%EF%BC%89"><span class="nav-number">5.0.11.</span> <span class="nav-text">数据清洗（ETL）</span></a></li></ol></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#6-Yarn"><span class="nav-number">6.</span> <span class="nav-text">6. Yarn</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#Yarn%E5%9F%BA%E7%A1%80%E6%9E%B6%E6%9E%84"><span class="nav-number">6.0.1.</span> <span class="nav-text">Yarn基础架构</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Yarn%E5%B7%A5%E4%BD%9C%E6%9C%BA%E5%88%B6"><span class="nav-number">6.0.2.</span> <span class="nav-text">Yarn工作机制</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Yarn%E8%B0%83%E5%BA%A6%E5%99%A8%E5%92%8C%E8%B0%83%E5%BA%A6%E7%AE%97%E6%B3%95"><span class="nav-number">6.0.3.</span> <span class="nav-text">Yarn调度器和调度算法</span></a></li></ol></li></ol></li></ol></div>
      </div>
      <!--/noindex-->

      <div class="site-overview-wrap sidebar-panel">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
    <img class="site-author-image" itemprop="image" alt="Normal People"
      src="/images/posthead.jpg">
  <p class="site-author-name" itemprop="name">Normal People</p>
  <div class="site-description" itemprop="description">Get busy living or get busy dying</div>
</div>
<div class="site-state-wrap motion-element">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
          <a href="/archives">
        
          <span class="site-state-item-count">41</span>
          <span class="site-state-item-name">日志</span>
        </a>
      </div>
      <div class="site-state-item site-state-categories">
            <a href="/categories">
          
        <span class="site-state-item-count">16</span>
        <span class="site-state-item-name">分类</span></a>
      </div>
  </nav>
</div>
  <div class="links-of-author motion-element">
      <span class="links-of-author-item">
        <a href="https://github.com/TheNormalPeople" title="GitHub → https:&#x2F;&#x2F;github.com&#x2F;TheNormalPeople" rel="noopener" target="_blank"><i class="fab fa-github fa-fw"></i>GitHub</a>
      </span>
      <span class="links-of-author-item">
        <a href="mailto:1272481411@qq.com" title="E-Mail → mailto:1272481411@qq.com" rel="noopener" target="_blank"><i class="fa fa-envelope fa-fw"></i>E-Mail</a>
      </span>
      <span class="links-of-author-item">
        <a href="https://weibo.com/u/5938927274" title="Weibo → https:&#x2F;&#x2F;weibo.com&#x2F;u&#x2F;5938927274" rel="noopener" target="_blank"><i class="fab fa-weibo fa-fw"></i>Weibo</a>
      </span>
      <span class="links-of-author-item">
        <a href="https://instagram.com/cy19970506" title="Instagram → https:&#x2F;&#x2F;instagram.com&#x2F;cy19970506" rel="noopener" target="_blank"><i class="fab fa-instagram fa-fw"></i>Instagram</a>
      </span>
  </div>



      </div>

    </div>
  </aside>
  <div id="sidebar-dimmer"></div>


      </div>
    </main>

    <footer class="footer">
      <div class="footer-inner">
        

        

<div class="copyright">
  
  &copy; 
  <span itemprop="copyrightYear">2023</span>
  <span class="with-love">
    <i class="heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">Normal People</span>
</div>

        








      </div>
    </footer>
  </div>

  
  <script src="/lib/anime.min.js"></script>
  <script src="/lib/velocity/velocity.min.js"></script>
  <script src="/lib/velocity/velocity.ui.min.js"></script>

<script src="/js/utils.js"></script>

<script src="/js/motion.js"></script>


<script src="/js/schemes/pisces.js"></script>


<script src="/js/next-boot.js"></script>




  















  

  

  


<script>
NexT.utils.loadComments(document.querySelector('#valine-comments'), () => {
  NexT.utils.getScript('//unpkg.com/valine/dist/Valine.min.js', () => {
    var GUEST = ['nick', 'mail', 'link'];
    var guest = 'nick,mail,link';
    guest = guest.split(',').filter(item => {
      return GUEST.includes(item);
    });
    new Valine({
      el         : '#valine-comments',
      verify     : false,
      notify     : false,
      appId      : 'y8XFURQNCoQsprRTou9DiEJu-gzGzoHsz',
      appKey     : 'QfVpjKDtJQdJrnJNnWUbVvjH',
      placeholder: "留下邮箱,有空时间回复您！",
      avatar     : 'mm',
      meta       : guest,
      pageSize   : '10' || 10,
      visitor    : false,
      lang       : '' || 'zh-cn',
      path       : location.pathname,
      recordIP   : false,
      serverURLs : ''
    });
  }, window.Valine);
});
</script>

</body>
</html>
