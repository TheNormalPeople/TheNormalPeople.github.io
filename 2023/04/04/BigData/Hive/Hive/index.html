<!DOCTYPE html>
<html lang="zh-CN">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
<meta name="theme-color" content="#222">
<meta name="generator" content="Hexo 5.4.0">
  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png">
  <link rel="mask-icon" href="/images/logo.svg" color="#222">

<link rel="stylesheet" href="/css/main.css">


<link rel="stylesheet" href="/lib/font-awesome/css/all.min.css">

<script id="hexo-configurations">
    var NexT = window.NexT || {};
    var CONFIG = {"hostname":"example.com","root":"/","scheme":"Pisces","version":"7.8.0","exturl":false,"sidebar":{"position":"left","display":"post","padding":18,"offset":12,"onmobile":true,"scrollpercent":true,"b2t":true},"copycode":{"enable":true,"show_result":true,"style":null},"back2top":{"enable":true,"sidebar":false,"scrollpercent":false},"bookmark":{"enable":false,"color":"#222","save":"auto"},"fancybox":false,"mediumzoom":false,"lazyload":false,"pangu":false,"comments":{"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},"algolia":{"hits":{"per_page":10},"labels":{"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}},"localsearch":{"enable":false,"trigger":"auto","top_n_per_article":1,"unescape":false,"preload":false},"motion":{"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}}};
  </script>

  <meta name="description" content="一.Hive入门1.什么是HiveHive是由Facebook开源，基于Hadoop的一个&#x3D;&#x3D;数据仓库工具&#x3D;&#x3D;，可以将&#x3D;&#x3D;结构化的数据文件映射为一张表&#x3D;&#x3D;，并提供&#x3D;&#x3D;类SQL&#x3D;&#x3D;查询功能。 2.Hive本质Hive是一个Hadoop客户端，用于&#x3D;&#x3D;将HQL（Hive SQL）转化成MapReduce程序&#x3D;&#x3D;。 （1）Hive中每张表的&#x3D;&#x3D;数据存储在HDFS&#x3D;&#x3D;； （2）Hive分析数据底层的实现是">
<meta property="og:type" content="article">
<meta property="og:title" content="Hive">
<meta property="og:url" content="http://example.com/2023/04/04/BigData/Hive/Hive/index.html">
<meta property="og:site_name" content="Blog">
<meta property="og:description" content="一.Hive入门1.什么是HiveHive是由Facebook开源，基于Hadoop的一个&#x3D;&#x3D;数据仓库工具&#x3D;&#x3D;，可以将&#x3D;&#x3D;结构化的数据文件映射为一张表&#x3D;&#x3D;，并提供&#x3D;&#x3D;类SQL&#x3D;&#x3D;查询功能。 2.Hive本质Hive是一个Hadoop客户端，用于&#x3D;&#x3D;将HQL（Hive SQL）转化成MapReduce程序&#x3D;&#x3D;。 （1）Hive中每张表的&#x3D;&#x3D;数据存储在HDFS&#x3D;&#x3D;； （2）Hive分析数据底层的实现是">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="http://example.com/2023/04/04/BigData/Hive/Hive/ipic/Hive架构原理.png">
<meta property="og:image" content="http://example.com/2023/04/04/BigData/Hive/Hive/ipic/炸裂函数示意图.png">
<meta property="og:image" content="http://example.com/2023/04/04/BigData/Hive/Hive/ipic/窗口函数示意图.png">
<meta property="og:image" content="http://example.com/2023/04/04/BigData/Hive/Hive/ipic/ORC文件基本格式.png">
<meta property="og:image" content="http://example.com/2023/04/04/BigData/Hive/Hive/ipic/parquet文件基本格式.png">
<meta property="article:published_time" content="2023-04-04T14:03:42.477Z">
<meta property="article:modified_time" content="2023-04-04T14:09:50.241Z">
<meta property="article:author" content="Normal People">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="http://example.com/2023/04/04/BigData/Hive/Hive/ipic/Hive架构原理.png">

<link rel="canonical" href="http://example.com/2023/04/04/BigData/Hive/Hive/">


<script id="page-configurations">
  // https://hexo.io/docs/variables.html
  CONFIG.page = {
    sidebar: "",
    isHome : false,
    isPost : true,
    lang   : 'zh-CN'
  };
</script>

  <title>Hive | Blog</title>
  






  <noscript>
  <style>
  .use-motion .brand,
  .use-motion .menu-item,
  .sidebar-inner,
  .use-motion .post-block,
  .use-motion .pagination,
  .use-motion .comments,
  .use-motion .post-header,
  .use-motion .post-body,
  .use-motion .collection-header { opacity: initial; }

  .use-motion .site-title,
  .use-motion .site-subtitle {
    opacity: initial;
    top: initial;
  }

  .use-motion .logo-line-before i { left: initial; }
  .use-motion .logo-line-after i { right: initial; }
  </style>
</noscript>

</head>

<body itemscope itemtype="http://schema.org/WebPage">
  <div class="container use-motion">
    <div class="headband"></div>

    <header class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="切换导航栏">
      <span class="toggle-line toggle-line-first"></span>
      <span class="toggle-line toggle-line-middle"></span>
      <span class="toggle-line toggle-line-last"></span>
    </div>
  </div>

  <div class="site-meta">

    <a href="/" class="brand" rel="start">
      <span class="logo-line-before"><i></i></span>
      <h1 class="site-title">Blog</h1>
      <span class="logo-line-after"><i></i></span>
    </a>
      <p class="site-subtitle" itemprop="description">by Normal People</p>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger">
    </div>
  </div>
</div>




<nav class="site-nav">
  <ul id="menu" class="main-menu menu">
        <li class="menu-item menu-item-home">

    <a href="/" rel="section"><i class="fa fa-home fa-fw"></i>首页</a>

  </li>
        <li class="menu-item menu-item-about">

    <a href="/about" rel="section"><i class="fa fa-user fa-fw"></i>关于</a>

  </li>
        <li class="menu-item menu-item-tags">

    <a href="/tags" rel="section"><i class="fa fa-tags fa-fw"></i>标签<span class="badge">0</span></a>

  </li>
        <li class="menu-item menu-item-categories">

    <a href="/categories" rel="section"><i class="fa fa-th fa-fw"></i>分类<span class="badge">17</span></a>

  </li>
        <li class="menu-item menu-item-archives">

    <a href="/archives" rel="section"><i class="fa fa-archive fa-fw"></i>归档<span class="badge">42</span></a>

  </li>
  </ul>
</nav>




</div>
    </header>

    
  <div class="back-to-top">
    <i class="fa fa-arrow-up"></i>
    <span>0%</span>
  </div>


    <main class="main">
      <div class="main-inner">
        <div class="content-wrap">
          

          <div class="content post posts-expand">
            

    
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="http://example.com/2023/04/04/BigData/Hive/Hive/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/posthead.jpg">
      <meta itemprop="name" content="Normal People">
      <meta itemprop="description" content="Get busy living or get busy dying">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Blog">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          Hive
        </h1>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>
              

              <time title="创建时间：2023-04-04 22:03:42 / 修改时间：22:09:50" itemprop="dateCreated datePublished" datetime="2023-04-04T22:03:42+08:00">2023-04-04</time>
            </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/BigData/" itemprop="url" rel="index"><span itemprop="name">BigData</span></a>
                </span>
                  ，
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/BigData/Hive/" itemprop="url" rel="index"><span itemprop="name">Hive</span></a>
                </span>
            </span>

          
  
  <span class="post-meta-item">
    
      <span class="post-meta-item-icon">
        <i class="far fa-comment"></i>
      </span>
      <span class="post-meta-item-text">Valine：</span>
    
    <a title="valine" href="/2023/04/04/BigData/Hive/Hive/#valine-comments" itemprop="discussionUrl">
      <span class="post-comments-count valine-comment-count" data-xid="/2023/04/04/BigData/Hive/Hive/" itemprop="commentCount"></span>
    </a>
  </span>
  
  

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
        <h1 id="一-Hive入门"><a href="#一-Hive入门" class="headerlink" title="一.Hive入门"></a>一.Hive入门</h1><h2 id="1-什么是Hive"><a href="#1-什么是Hive" class="headerlink" title="1.什么是Hive"></a>1.什么是Hive</h2><p>Hive是由Facebook开源，基于Hadoop的一个<strong>==数据仓库工具==</strong>，可以将==结构化的数据文件映射为一张表==，并提供==类SQL==查询功能。</p>
<h2 id="2-Hive本质"><a href="#2-Hive本质" class="headerlink" title="2.Hive本质"></a>2.<strong>Hive本质</strong></h2><p>Hive是一个Hadoop客户端，用于==将HQL（Hive SQL）转化成MapReduce程序==。</p>
<p>（1）Hive中每张表的==数据存储在HDFS==；</p>
<p>（2）Hive分析数据底层的实现是MapReduce（也可配置为Spark或者Tez）；</p>
<p>（3）执行==程序运行在Yarn==上 。</p>
<h2 id="3-Hive架构原理"><a href="#3-Hive架构原理" class="headerlink" title="3.Hive架构原理"></a>3.Hive架构原理</h2><p><img src="ipic/Hive架构原理.png" alt="Hive架构原理"></p>
<ul>
<li><strong>用户接口：Client</strong></li>
</ul>
<p>CLI（command-line interface）、JDBC/ODBC。</p>
<p>==说明：JDBC和ODBC的区别。==</p>
<ol>
<li>JDBC的移植性比ODBC好；（通常情况下，安装完ODBC驱动程序之后，还需要经过确定的配置才能够应用。而不相同的配置在不相同数据库服务器之间不能够通用。所以，安装一次就需要再配置一次。JDBC只需要选取适当的JDBC数据库驱动程序，就不需要额外的配置。在安装过程中，JDBC数据库驱动程序会自己完成有关的配置。）</li>
<li>两者使用的语言不同，JDBC在Java编程时使用，ODBC一般在C/C++编程时使用。  </li>
</ol>
<ul>
<li><strong>元数据：Metastore</strong>  </li>
</ul>
<p>元数据包括：数据库（默认是default）、表名、表的拥有者、列/分区字段、表的类型（是否是外部表）、表的数据所在目录等。默认存储在自带的derby数据库中，由于derby数据库只支持单客户端访问，生产环境中为了多人开发，推荐使用MySQL存储Metastore。</p>
<ul>
<li><strong>驱动器：Driver</strong>  </li>
</ul>
<ol>
<li>==解析器（SQLParser）==：将SQL字符串转换成抽象语法树（AST）</li>
<li>==语义分析（Semantic Analyzer）==：将AST进一步划分为QeuryBlock</li>
<li>==逻辑计划生成器（Logical Plan Gen）==：将语法树生成逻辑计划</li>
<li>==逻辑优化器（Logical Optimizer）==：对逻辑计划进行优化</li>
<li>==物理计划生成器（Physical Plan Gen）==：根据优化后的逻辑计划生成物理计划</li>
<li>==物理优化器（Physical Optimizer）==：对物理计划进行优化</li>
<li>==执行器（Execution）==：执行该计划，得到查询结果并返回给客户端</li>
</ol>
<ul>
<li><strong>Hadoop</strong>  </li>
</ul>
<p>使用HDFS进行存储，可以选择MapReduce/Tez/Spark进行计算。</p>
<h1 id="二-DDL（Data-Definition-Language）数据定义"><a href="#二-DDL（Data-Definition-Language）数据定义" class="headerlink" title="二.DDL（Data Definition Language）数据定义"></a>二.DDL（Data Definition Language）数据定义</h1><h2 id="1-数据库（database）"><a href="#1-数据库（database）" class="headerlink" title="1.数据库（database）"></a>1.数据库（database）</h2><h3 id="1）创建数据库"><a href="#1）创建数据库" class="headerlink" title="1）创建数据库"></a>1）创建数据库</h3><p>创建数据库可以指定HDFS路径的位置，不指定路径，默认路径==<strong>${hive.metastore.warehouse.dir}/database_name.db</strong>==  </p>
<h3 id="2）查询数据库"><a href="#2）查询数据库" class="headerlink" title="2）查询数据库"></a>2）查询数据库</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">SHOW DATABASES [LIKE &#39;identifier_with_wildcards&#39;];</span><br></pre></td></tr></table></figure>
<p>==注：like通配表达式说明：*表示任意个任意字符，|表示或的关系。==</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">DESCRIBE DATABASE [EXTENDED] db_name;</span><br></pre></td></tr></table></figure>
<p>==注：查看数据库信息== </p>
<h3 id="3）修改数据库"><a href="#3）修改数据库" class="headerlink" title="3）修改数据库"></a>3）修改数据库</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">--修改dbproperties</span><br><span class="line">ALTER DATABASE database_name SET DBPROPERTIES (property_name&#x3D;property_value, ...);</span><br><span class="line"></span><br><span class="line">--修改location</span><br><span class="line">ALTER DATABASE database_name SET LOCATION hdfs_path;</span><br><span class="line"></span><br><span class="line">--修改owner user</span><br><span class="line">ALTER DATABASE database_name SET OWNER USER user_name;</span><br></pre></td></tr></table></figure>
<h3 id="4）删除数据库"><a href="#4）删除数据库" class="headerlink" title="4）删除数据库"></a>4）删除数据库</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">DROP DATABASE [IF EXISTS] database_name [RESTRICT|CASCADE];</span><br></pre></td></tr></table></figure>
<h2 id="2-表（table"><a href="#2-表（table" class="headerlink" title="2.表（table)"></a>2.表（table)</h2><h3 id="1）创建表"><a href="#1）创建表" class="headerlink" title="1）创建表"></a>1）创建表</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">CREATE [TEMPORARY] [EXTERNAL] TABLE [IF NOT EXISTS] [db_name.]table_name   </span><br><span class="line">[(col_name data_type [COMMENT col_comment], ...)]</span><br><span class="line">[COMMENT table_comment]</span><br><span class="line">[PARTITIONED BY (col_name data_type [COMMENT col_comment], ...)]</span><br><span class="line">[CLUSTERED BY (col_name, col_name, ...) </span><br><span class="line">[SORTED BY (col_name [ASC|DESC], ...)] INTO num_buckets BUCKETS]</span><br><span class="line">[ROW FORMAT row_format] </span><br><span class="line">[STORED AS file_format]</span><br><span class="line">[LOCATION hdfs_path]</span><br><span class="line">[TBLPROPERTIES (property_name&#x3D;property_value, ...)]</span><br></pre></td></tr></table></figure>
<ol>
<li><p><strong>TEMPORARY</strong>  临时表，该表只在当前会话可见，会话结束，表会被删除。</p>
</li>
<li><p><strong>EXTERNAL</strong>  外部表，与之相对应的是==内部表（管理表）。管理表意味着Hive会完全接管该表，包括元数据和HDFS中的数据==。而==外部表则意味着Hive只接管元数据，而不完全接管HDFS中的数据==。</p>
</li>
<li><p><strong>data_type</strong>  还包含==复杂数据类型array<string>，map<string, int>，struct<id:int, name:string>==  </p>
<p><strong>注：类型转换 </strong>Hive的基本数据类型可以做类型转换，转换的方式包括隐式转换以及显示转换。</p>
<p><strong>显示转换</strong>：==cast(expr as <type>)==  </p>
</li>
<li><p><strong>PARTITIONED BY</strong> 创建分区表。</p>
</li>
<li><p><strong>CLUSTERED BY … SORTED BY…INTO … BUCKETS</strong>  创建分桶表。</p>
</li>
<li><p><strong>ROW FORMAT</strong> 指定SERDE，SERDE是Serializer and Deserializer的简写。Hive使用SERDE序列化和反序列化每行数据。  </p>
</li>
<li><p><strong>STORED AS</strong> 指定文件格式，常用的文件格式有，==textfile（默认值）==，==sequence file==，==orc file==、==parquet file==等等。</p>
</li>
<li><p><strong>LOCATION</strong> 指定表所对应的HDFS路径，若不指定路径，其默认值为==${hive.metastore.warehouse.dir}/db_name.db/table_name==</p>
</li>
<li><p><strong>TBLPROPERTIES</strong> 用于配置表的一些KV键值对参数。</p>
</li>
</ol>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">Create Table As Select（CTAS）建表</span><br><span class="line">Create Table Like 语法</span><br></pre></td></tr></table></figure>
<h3 id="2）查看表"><a href="#2）查看表" class="headerlink" title="2）查看表"></a>2）查看表</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">SHOW TABLES [IN database_name] LIKE [&#39;identifier_with_wildcards&#39;];</span><br><span class="line">DESCRIBE [EXTENDED | FORMATTED] [db_name.]table_name</span><br></pre></td></tr></table></figure>
<h3 id="3）修改表"><a href="#3）修改表" class="headerlink" title="3）修改表"></a>3）修改表</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">ALTER TABLE table_name RENAME TO new_table_name</span><br><span class="line"></span><br><span class="line">#增加列 该语句允许用户增加新的列，新增列的位置位于末尾。</span><br><span class="line">ALTER TABLE table_name ADD COLUMNS (col_name data_type [COMMENT col_comment], ...) </span><br><span class="line"></span><br><span class="line"># 更新列 该语句允许用户修改指定列的列名、数据类型、注释信息以及在表中的位置。</span><br><span class="line">ALTER TABLE table_name CHANGE [COLUMN] col_old_name col_new_name column_type [COMMENT col_comment] [FIRST|AFTER column_name] </span><br><span class="line"></span><br><span class="line">#替换列 该语句允许用户用新的列集替换表中原有的全部列。</span><br><span class="line">ALTER TABLE table_name REPLACE COLUMNS (col_name data_type [COMMENT col_comment], ...) </span><br></pre></td></tr></table></figure>
<h3 id="4）删除表"><a href="#4）删除表" class="headerlink" title="4）删除表"></a>4）删除表</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">DROP TABLE [IF EXISTS] table_name; </span><br></pre></td></tr></table></figure>
<h3 id="5）清空表"><a href="#5）清空表" class="headerlink" title="5）清空表"></a>5）清空表</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">TRUNCATE [TABLE] table_name</span><br></pre></td></tr></table></figure>
<h1 id="三-DML（Data-Manipulation-Language）数据操作"><a href="#三-DML（Data-Manipulation-Language）数据操作" class="headerlink" title="三.DML（Data Manipulation Language）数据操作"></a>三.DML（Data Manipulation Language）数据操作</h1><h2 id="1-Load"><a href="#1-Load" class="headerlink" title="1.Load"></a>1.Load</h2><p>Load语句可将文件导入到Hive表中。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">LOAD DATA [LOCAL] INPATH &#39;filepath&#39; [OVERWRITE] INTO TABLE tablename [PARTITION (partcol1&#x3D;val1, partcol2&#x3D;val2 ...)];</span><br></pre></td></tr></table></figure>
<h2 id="2-Insert"><a href="#2-Insert" class="headerlink" title="2.Insert"></a>2.Insert</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">INSERT (INTO | OVERWRITE) TABLE tablename [PARTITION (partcol1&#x3D;val1, partcol2&#x3D;val2 ...)] select_statement;</span><br><span class="line"></span><br><span class="line"># 将给定Values插入表中</span><br><span class="line">INSERT (INTO | OVERWRITE) TABLE tablename [PARTITION (partcol1[&#x3D;val1], partcol2[&#x3D;val2] ...)] VALUES values_row [, values_row ...]</span><br><span class="line"></span><br><span class="line"># 将查询结果写入目标路径</span><br><span class="line">INSERT OVERWRITE [LOCAL] DIRECTORY directory [ROW FORMAT row_format] [STORED AS file_format] select_statement;</span><br></pre></td></tr></table></figure>
<h2 id="3-Export-amp-Import"><a href="#3-Export-amp-Import" class="headerlink" title="3.Export&amp;Import"></a>3.Export&amp;Import</h2><p>Export导出语句可将==表的数据和元数据信息一并到处的HDFS路径==，Import可将Export导出的内容导入Hive，==表的数据和元数据信息都会恢复==。Export和Import可用于两个Hive实例之间的数据迁移。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">--导出</span><br><span class="line">EXPORT TABLE tablename TO &#39;export_target_path&#39;</span><br><span class="line"></span><br><span class="line">--导入</span><br><span class="line">IMPORT [EXTERNAL] TABLE new_or_original_tablename FROM &#39;source_path&#39; [LOCATION &#39;import_target_path&#39;]</span><br></pre></td></tr></table></figure>
<h1 id="四-查询"><a href="#四-查询" class="headerlink" title="四.查询"></a>四.查询</h1><ol>
<li><strong>having</strong>与<strong>where</strong>不同点</li>
</ol>
<p>（1）where后面不能写分组聚合函数，而having后面可以使用分组聚合函数。</p>
<p>（2）having只用于group by分组统计语句。</p>
<ol>
<li><p>Hive支持通常的sql join语句，但是==只支持等值连接，不支持非等值连接==。</p>
</li>
<li><p><strong>union</strong>和<strong>union all</strong>在上下拼接sql结果时有两个要求：</p>
</li>
</ol>
<p>（1）两个sql的结果，列的个数必须相同</p>
<p>（2）两个sql的结果，上下所对应列的类型必须一致</p>
<h2 id="1-Sort-By（每个Reduce内部排序）"><a href="#1-Sort-By（每个Reduce内部排序）" class="headerlink" title="1.Sort By（每个Reduce内部排序）"></a>1.Sort By（每个Reduce内部排序）</h2><p>Sort By：对于==大规模的数据集==order by的效率非常低。在很多情况下，并==不需要全局排序==，此时可以使用<strong>Sort by</strong>。</p>
<p>Sort by为每个reduce产生一个排序文件。==每个Reduce内部进行排序，对全局结果集来说不是排序==。</p>
<h2 id="2-Distribute-By（分区）"><a href="#2-Distribute-By（分区）" class="headerlink" title="2.Distribute By（分区）"></a>2.Distribute By（分区）</h2><p>Distribute By：在有些情况下，我们需要控制某个特定行应该到哪个Reducer，通常是为了进行后续的聚集操作。<strong>distribute by</strong>子句可以做这件事。<strong>distribute by</strong>类似MapReduce中partition（自定义分区），进行分区，结合sort by使用。  </p>
<p><strong>注意：</strong></p>
<ul>
<li><p>distribute by的分区规则是==根据分区字段的hash码与reduce的个数进行相除==后，余数相同的分到一个区。</p>
</li>
<li><p>Hive要求<strong>distribute by</strong>语句要写在sort by语句之前。</p>
</li>
</ul>
<h2 id="3-Cluster-By（分区排序）"><a href="#3-Cluster-By（分区排序）" class="headerlink" title="3.Cluster By（分区排序）"></a>3.Cluster By（分区排序）</h2><p>==当distribute by和sort by字段相同时，可以使用cluster by方式。==</p>
<p>cluster by除了具有distribute by的功能外还兼具sort by的功能。但是==排序只能是升序排序，不能指定排序规则为asc或者desc==。</p>
<h1 id="五-函数"><a href="#五-函数" class="headerlink" title="五.函数"></a>五.函数</h1><p>Hive提供了大量的内置函数，按照其特点可大致分为如下几类：单行函数、聚合函数、炸裂函数、窗口函数。</p>
<h2 id="1-单行函数"><a href="#1-单行函数" class="headerlink" title="1.单行函数"></a>1.单行函数</h2><p><strong>单行函数的特点是一进一出，即输入一行，输出一行。</strong></p>
<p><strong>单行函数按照功能可分为如下几类:</strong>日期函数、字符串函数、集合函数、数学函数、流程控制函数等。</p>
<h3 id="1）算术运算函数"><a href="#1）算术运算函数" class="headerlink" title="1）算术运算函数"></a>1）算术运算函数</h3><p>+、-、*、/、&amp;、|、~、%、^</p>
<h3 id="2）数值函数"><a href="#2）数值函数" class="headerlink" title="2）数值函数"></a>2）数值函数</h3><ul>
<li><p>==round：四舍五入==  </p>
</li>
<li><p>==ceil：向上取整==  </p>
</li>
<li><p>==floor：向下取整==  </p>
</li>
</ul>
<h3 id="3）字符串函数"><a href="#3）字符串函数" class="headerlink" title="3）字符串函数"></a>3）字符串函数</h3><ul>
<li>==substring：截取字符串==  </li>
<li><p>substring(string A, int start)</p>
<ul>
<li>substring(string A, int start, int len)      </li>
</ul>
</li>
<li><p>==replace ：替换==  </p>
<ul>
<li>replace(string A, string B, string C) 将字符串A中的子字符串B替换为C。  </li>
</ul>
</li>
<li><p>==regexp_replace：正则替换==  </p>
<ul>
<li>regexp_replace(string A, string B, string C) 将字符串A中的符合java正则表达式B的部分替换为C。注意，在有些情况下要使用转义字符。  </li>
</ul>
</li>
<li><p>==regexp：正则匹配==  </p>
<ul>
<li>字符串 regexp 正则表达式 若字符串符合正则表达式，则返回true，否则返回false。  </li>
</ul>
</li>
<li><p>==repeat：重复字符串==  </p>
<ul>
<li>repeat(string A, int n) 将字符串A重复n遍。</li>
</ul>
</li>
<li><p>==split ：字符串切割== </p>
<ul>
<li>split(string str, string pat) 按照正则表达式pat匹配到的内容分割str，分割后的字符串，以数组的形式返回。  </li>
</ul>
</li>
<li><p>==nvl ：替换null值==  </p>
<ul>
<li>nvl(A,B) 若A的值不为null，则返回A，否则返回B。</li>
</ul>
</li>
<li><p>==concat ：拼接字符串==</p>
<ul>
<li>concat(string A, string B, string C, ……) 将A,B,C……等字符拼接为一个字符串。   </li>
</ul>
</li>
<li><p>==concat_ws：以指定分隔符拼接字符串或者字符串数组==  </p>
<ul>
<li>concat_ws(string A, string…| array(string)) 使用分隔符A拼接多个字符串，或者一个数组的所有元素。    </li>
</ul>
</li>
<li><p>==get_json_object：解析json字符串==  </p>
<ul>
<li>get_json_object(string json_string, string path) 解析json的字符串json_string，返回path指定的内容。如果输入的json字符串无效，那么返回NULL。 <h3 id="4）日期函数"><a href="#4）日期函数" class="headerlink" title="4）日期函数"></a>4）日期函数</h3></li>
</ul>
</li>
<li><p>==unix_timestamp：返回当前或指定时间的时间戳==  </p>
<ul>
<li><p>unix_timestamp()   </p>
</li>
<li><p>```mysql<br>select unix_timestamp(‘2022/08/08 08-08-08’,’yyyy/MM/dd HH-mm-ss’);</p>
<h1 id="1659946088"><a href="#1659946088" class="headerlink" title="1659946088"></a>1659946088</h1><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">    说明：前面是日期后面是指，日期传进来的具体格式 </span><br><span class="line"></span><br><span class="line">* &#x3D;&#x3D;from_unixtime：转化UNIX时间戳（从 1970-01-01 00:00:00 UTC 到指定时间的秒数）到当前时区的时间格式&#x3D;&#x3D;  </span><br><span class="line"></span><br><span class="line">  * from_unixtime(bigint unixtime[, string format])  </span><br><span class="line"></span><br><span class="line">  * &#96;&#96;&#96;mysql</span><br><span class="line">    select from_unixtime(1659946088);</span><br><span class="line">    #2022-08-08 08:08:08</span><br></pre></td></tr></table></figure>
</li>
</ul>
</li>
<li><p>==current_date：当前日期==  </p>
<ul>
<li>```mysql<br>select current_date;<h1 id="2022-07-11"><a href="#2022-07-11" class="headerlink" title="2022-07-11"></a>2022-07-11</h1><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">* &#x3D;&#x3D;current_timestamp：当前的日期加时间，并且精确的毫秒&#x3D;&#x3D;  </span><br><span class="line"></span><br><span class="line">  * &#96;&#96;&#96;mysql</span><br><span class="line">    select current_timestamp;</span><br><span class="line">    # 2022-07-11 15:32:22.402</span><br></pre></td></tr></table></figure>
</li>
</ul>
</li>
<li><p>==year/month/day/hour：获取日期中的年/月/日/时==  </p>
<ul>
<li>```mysql<br>year(string date)<br>month(string date)<br>day(string date)<br>hour(string date)<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">* &#x3D;&#x3D;datediff：两个日期相差的天数（结束日期减去开始日期的天数）&#x3D;&#x3D;  </span><br><span class="line"></span><br><span class="line">  * datediff(string enddate, string startdate) </span><br><span class="line"></span><br><span class="line">  * &#96;&#96;&#96;mysql</span><br><span class="line">    select datediff(&#39;2021-08-08&#39;,&#39;2022-10-09&#39;);</span><br><span class="line">    # -427</span><br></pre></td></tr></table></figure>
</li>
</ul>
</li>
<li><p>==date_add：日期加天数/date_sub：日期减天数==  </p>
<ul>
<li><p>date_add(string startdate, int days)  </p>
</li>
<li><p>date_sub (string startdate, int days)  </p>
</li>
<li><p>```mysql<br> select date_add(‘2022-08-08’,2);</p>
<h1 id="2022-08-10"><a href="#2022-08-10" class="headerlink" title="2022-08-10"></a>2022-08-10</h1><p> select date_sub(‘2022-08-08’,2);</p>
<h1 id="2022-08-06"><a href="#2022-08-06" class="headerlink" title="2022-08-06"></a>2022-08-06</h1><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">* &#x3D;&#x3D;date_format:将标准日期解析成指定格式字符串&#x3D;&#x3D;  </span><br><span class="line"></span><br><span class="line">  * &#96;&#96;&#96;mysql</span><br><span class="line">    select date_format(&#39;2022-08-08&#39;,&#39;yyyy年-MM月-dd日&#39;) # yyyy-MM-dd </span><br><span class="line">    # 2022年-08月-08日</span><br></pre></td></tr></table></figure>
</li>
</ul>
</li>
</ul>
<h3 id="5）流程控制函数"><a href="#5）流程控制函数" class="headerlink" title="5）流程控制函数"></a>5）流程控制函数</h3><ul>
<li><p>==case when：条件判断函数==  </p>
<ul>
<li>```mysql<br>case when a then b <pre><code>[when c then d]
[else e] 
</code></pre>end<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">* &#96;&#96;&#96;mysql</span><br><span class="line">  case a </span><br><span class="line">      when b then c </span><br><span class="line">      [when d then e]</span><br><span class="line">      [else f] </span><br><span class="line">  end</span><br></pre></td></tr></table></figure>
</li>
</ul>
</li>
<li><p>==if: 条件判断，类似于Java中三元运算符==  </p>
<ul>
<li>```mysql<br>if（boolean testCondition, T valueTrue, T valueFalseOrNull）<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">### 6）集合函数</span><br><span class="line"></span><br><span class="line">* &#x3D;&#x3D;size：集合中元素的个数&#x3D;&#x3D;  </span><br><span class="line"></span><br><span class="line">  * &#96;&#96;&#96;mysql</span><br><span class="line">    select size(friends) from test; </span><br><span class="line">    # 每一行数据中的friends集合里的个数</span><br></pre></td></tr></table></figure>
</li>
</ul>
</li>
<li><p>==map：创建map集合==  </p>
<ul>
<li><p>根据输入的key和value对构建map类型  </p>
</li>
<li><p>```mysql<br>map (key1, value1, key2, value2, …) </p>
<h1 id="select-map-‘xiaohai’-1-’dahai’-2"><a href="#select-map-‘xiaohai’-1-’dahai’-2" class="headerlink" title="select map(‘xiaohai’,1,’dahai’,2);"></a>select map(‘xiaohai’,1,’dahai’,2);</h1><h1 id="“xiaohai”-1-”dahai”-2"><a href="#“xiaohai”-1-”dahai”-2" class="headerlink" title="{“xiaohai”:1,”dahai”:2}"></a>{“xiaohai”:1,”dahai”:2}</h1><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">* &#x3D;&#x3D;map_keys： 返回map中的key&#x3D;&#x3D;  </span><br><span class="line"></span><br><span class="line">  * &#96;&#96;&#96;mysql</span><br><span class="line">    select map_keys(map(&#39;xiaohai&#39;,1,&#39;dahai&#39;,2));</span><br><span class="line">    # [&quot;xiaohai&quot;,&quot;dahai&quot;] 输出为集合类型</span><br></pre></td></tr></table></figure>
</li>
</ul>
</li>
<li><p>==map_values: 返回map中的value==  </p>
<ul>
<li>```mysql<br>select map_values(map(‘xiaohai’,1,’dahai’,2));<h1 id="1-2-输出为集合类型"><a href="#1-2-输出为集合类型" class="headerlink" title="[1,2] 输出为集合类型"></a>[1,2] 输出为集合类型</h1><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">* &#x3D;&#x3D;array 声明array集合&#x3D;&#x3D;  </span><br><span class="line"></span><br><span class="line">  * array(val1, val2, …) 根据输入的参数构建数组array类。</span><br><span class="line"></span><br><span class="line">  * &#96;&#96;&#96;mysql</span><br><span class="line">    select array(&#39;1&#39;,&#39;2&#39;,&#39;3&#39;,&#39;4&#39;);</span><br><span class="line">    # [&quot;1&quot;,&quot;2&quot;,&quot;3&quot;,&quot;4&quot;]</span><br></pre></td></tr></table></figure>
</li>
</ul>
</li>
<li><p>==array_contains: 判断array中是否包含某个元素==  </p>
<ul>
<li>```mysql<br>select array_contains(array(‘a’,’b’,’c’,’d’),’a’);<h1 id="true"><a href="#true" class="headerlink" title="true"></a>true</h1><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">* &#x3D;&#x3D;sort_array：将array中的元素排序&#x3D;&#x3D;  </span><br><span class="line"></span><br><span class="line">  * &#96;&#96;&#96;mysql</span><br><span class="line">    select sort_array(array(&#39;a&#39;,&#39;d&#39;,&#39;c&#39;));</span><br><span class="line">    # [&quot;a&quot;,&quot;c&quot;,&quot;d&quot;]</span><br></pre></td></tr></table></figure>
</li>
</ul>
</li>
<li><p>==struct声明struct中的各属性==  </p>
<ul>
<li><p>struct(val1, val2, val3, …) 根据输入的参数构建结构体struct类。</p>
</li>
<li><p>```mysql<br>select struct(‘name’,’age’,’weight’);</p>
<h1 id="“col1”-”name”-”col2”-”age”-”col3”-”weight”"><a href="#“col1”-”name”-”col2”-”age”-”col3”-”weight”" class="headerlink" title="{“col1”:”name”,”col2”:”age”,”col3”:”weight”}"></a>{“col1”:”name”,”col2”:”age”,”col3”:”weight”}</h1><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">* &#x3D;&#x3D;named_struct声明struct的属性和值&#x3D;&#x3D;  </span><br><span class="line"></span><br><span class="line">  * &#96;&#96;&#96;mysql</span><br><span class="line">    select named_struct(&#39;name&#39;,&#39;xiaosong&#39;,&#39;age&#39;,18,&#39;weight&#39;,80);</span><br><span class="line">    # &#123;&quot;name&quot;:&quot;xiaosong&quot;,&quot;age&quot;:18,&quot;weight&quot;:80&#125;</span><br></pre></td></tr></table></figure>
</li>
</ul>
</li>
</ul>
<h2 id="2-高级聚合函数"><a href="#2-高级聚合函数" class="headerlink" title="2.高级聚合函数"></a>2.高级聚合函数</h2><p><strong>多进一出 （多行传入，一个行输出）。</strong></p>
<h3 id="1）普通聚合-count-sum…"><a href="#1）普通聚合-count-sum…" class="headerlink" title="1）普通聚合 count/sum…."></a><strong>1）普通聚合 count/sum….</strong></h3><h3 id="2）collect-list收集并形成list集合，结果不去重"><a href="#2）collect-list收集并形成list集合，结果不去重" class="headerlink" title="2）collect_list收集并形成list集合，结果不去重"></a>2）collect_list收集并形成list集合，结果不去重</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">select sex, collect_list(job)</span><br><span class="line">from employee</span><br><span class="line">group by sex</span><br><span class="line"></span><br><span class="line"># 女	[&quot;行政&quot;,&quot;研发&quot;,&quot;行政&quot;,&quot;前台&quot;]</span><br><span class="line"># 男	[&quot;销售&quot;,&quot;研发&quot;,&quot;销售&quot;,&quot;前台&quot;]</span><br></pre></td></tr></table></figure>
<h3 id="3）collect-set-收集并形成set集合，结果去重"><a href="#3）collect-set-收集并形成set集合，结果去重" class="headerlink" title="3）collect_set 收集并形成set集合，结果去重"></a>3）collect_set 收集并形成set集合，结果去重</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">select sex, collect_set(job)</span><br><span class="line">from employee</span><br><span class="line">group by sex</span><br><span class="line"></span><br><span class="line"># 女	[&quot;行政&quot;,&quot;研发&quot;,&quot;前台&quot;]</span><br><span class="line"># 男	[&quot;销售&quot;,&quot;研发&quot;,&quot;前台&quot;]</span><br></pre></td></tr></table></figure>
<h2 id="3-炸裂函数"><a href="#3-炸裂函数" class="headerlink" title="3.炸裂函数"></a>3.炸裂函数</h2><p><strong>UDTF(Table-Generating Functions),接收一行数据，输出一行或多行数据。</strong></p>
<p><img src="ipic/炸裂函数示意图.png" alt="炸裂函数示意图"></p>
<div class="table-container">
<table>
<thead>
<tr>
<th><strong>movie</strong></th>
<th><strong>category</strong></th>
</tr>
</thead>
<tbody>
<tr>
<td>《疑犯追踪》</td>
<td>悬疑，动作，科幻，剧情</td>
</tr>
<tr>
<td>《Lie to  me》</td>
<td>悬疑，警匪，动作，心理，剧情</td>
</tr>
<tr>
<td>《战狼2》</td>
<td>战争，动作，灾难</td>
</tr>
</tbody>
</table>
</div>
<p><strong>建表</strong></p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">create table movie_info(</span><br><span class="line">    movie string,     --电影名称</span><br><span class="line">    category string   --电影分类</span><br><span class="line">) </span><br><span class="line">row format delimited fields terminated by &quot;\t&quot;;</span><br></pre></td></tr></table></figure>
<p><strong>数据装载</strong></p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">insert overwrite table movie_info</span><br><span class="line">values (&quot;《疑犯追踪》&quot;, &quot;悬疑,动作,科幻,剧情&quot;),</span><br><span class="line">       (&quot;《Lie to me》&quot;, &quot;悬疑,警匪,动作,心理,剧情&quot;),</span><br><span class="line">       (&quot;《战狼2》&quot;, &quot;战争,动作,灾难&quot;);</span><br></pre></td></tr></table></figure>
<p><strong>需求：根据上述电影信息表，统计各分类的电影数量，期望结果如下：</strong></p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">select cate, count(*)</span><br><span class="line">from (</span><br><span class="line">    select movie, cate</span><br><span class="line">    from (</span><br><span class="line">        select movie, split(category,&#39;,&#39;) cates</span><br><span class="line">        from movie_info</span><br><span class="line">    )t1 lateral view explode(cates) tmp as cate</span><br><span class="line">)t2</span><br><span class="line">group by cate;</span><br></pre></td></tr></table></figure>
<h2 id="4-窗口函数（开窗函数）"><a href="#4-窗口函数（开窗函数）" class="headerlink" title="4.窗口函数（开窗函数）"></a>4.窗口函数（开窗函数）</h2><p>窗口函数，能为每行数据划分一个窗口，然后对窗口范围内的数据进行计算，最后将计算结果返回给该行数据。</p>
<p><img src="ipic/窗口函数示意图.png" alt="窗口函数示意图"></p>
<h3 id="1）常用窗口函数"><a href="#1）常用窗口函数" class="headerlink" title="1）常用窗口函数"></a>1）常用窗口函数</h3><ul>
<li><p>==聚合函数==  </p>
<ul>
<li>max：最大值。</li>
<li>min：最小值。</li>
<li>sum：求和。</li>
<li>avg：平均值。</li>
<li>count：计数。</li>
</ul>
</li>
<li><p>==跨行取值函数：获取当前行的上/下边某行、某个字段的值。==</p>
<ul>
<li>```mysql<br>lead(column, offset, Defaults)<br>lag(column, offset, Defaults) <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">  * **注：lag和lead函数不支持自定义窗口。**</span><br><span class="line"></span><br><span class="line">* &#x3D;&#x3D;first_value和last_value：获取窗口内某一列的第一个值&#x2F;最后一个值&#x3D;&#x3D; </span><br><span class="line"></span><br><span class="line">  * &#96;&#96;&#96;mysql</span><br><span class="line">    first_value(column, skipNULL)</span><br><span class="line">    last_value(column, skipNULL)</span><br><span class="line">    # skipNULL为是否跳过null值</span><br></pre></td></tr></table></figure>
</li>
</ul>
</li>
<li><p>==排名函数：rank、dense_rank、row_number计算排名==  </p>
<ul>
<li><p>```mysql<br>rank() over(partition by xxx order by yyy)<br>dense_rank() over(partition by xxx order by yyy)<br>row_number() over(partition by xxx order by yyy)</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">  * **注：rank 、dense_rank、row_number不支持自定义窗口。**  </span><br><span class="line"></span><br><span class="line">## 5.自定义函数</span><br><span class="line"></span><br><span class="line">* **Hive自带了一些函数，比如：max&#x2F;min等，但是数量有限，自己可以通过自定义UDF来方便的扩展。**  </span><br><span class="line"></span><br><span class="line">* **当Hive提供的内置函数无法满足你的业务处理需要时，此时就可以考虑使用用户自定义函数（UDF：user-defined function）。** </span><br><span class="line"></span><br><span class="line">* **根据用户自定义函数类别分为以下三种：**  </span><br><span class="line"></span><br><span class="line">  * &#x3D;&#x3D;UDF（User-Defined-Function）&#x3D;&#x3D;一进一出。</span><br><span class="line">  * &#x3D;&#x3D;UDAF（User-Defined Aggregation Function）&#x3D;&#x3D;用户自定义聚合函数，多进一出。类似于：count&#x2F;max&#x2F;min。</span><br><span class="line">  * &#x3D;&#x3D;UDTF（User-Defined Table-Generating Functions）&#x3D;&#x3D;用户自定义表生成函数，一进多出。如lateral view explode() </span><br><span class="line"></span><br><span class="line">* **编程步骤**  </span><br><span class="line"></span><br><span class="line">  * 继承Hive提供的类</span><br><span class="line"></span><br><span class="line">    org.apache.hadoop.hive.ql.udf.generic.GenericUDF</span><br><span class="line"></span><br><span class="line">    org.apache.hadoop.hive.ql.udf.generic.GenericUDTF;</span><br><span class="line"></span><br><span class="line">  * 实现类中的抽象方法  </span><br><span class="line"></span><br><span class="line">  * 在hive的命令行窗口创建函数  </span><br><span class="line"></span><br><span class="line">    * 添加jar  </span><br><span class="line"></span><br><span class="line">    * &#96;&#96;&#96;mysql</span><br><span class="line">      add jar linux_jar_path </span><br><span class="line">      # 将打包好的jar包上传到linux后，使用add将jar包添加到hive的classpath</span><br></pre></td></tr></table></figure>
<ul>
<li><p>创建function。</p>
</li>
<li><p>```mysql<br>create [temporary] function [dbname.]function_name AS class_name;</p>
<h1 id="创建临时函数与开发好的java-class关联"><a href="#创建临时函数与开发好的java-class关联" class="headerlink" title="创建临时函数与开发好的java class关联"></a>创建临时函数与开发好的java class关联</h1><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">**注意：临时函数只跟会话有关系，跟库没有关系。只要创建临时函数的会话不断，在当前会话下，任意一个库都可以使用，其他会话全都不能使用。**  </span><br><span class="line"></span><br><span class="line">**注意：因为add jar本身也是临时生效，所以在创建永久函数的时候，需要制定路径（并且因为元数据的原因，这个路径还得是HDFS上的路径）。**</span><br><span class="line"></span><br><span class="line">&#96;&#96;&#96;mysql</span><br><span class="line">create function my_len2 </span><br><span class="line">as &quot;com.atguigu.hive.udf.MyUDF&quot; </span><br><span class="line">using jar &quot;hdfs:&#x2F;&#x2F;hadoop102:8020&#x2F;udf&#x2F;myudf.jar&quot;;</span><br></pre></td></tr></table></figure>
</li>
</ul>
</li>
</ul>
<p><strong>注意：永久函数跟会话没有关系，创建函数的会话断了以后，其他会话也可以使用。</strong></p>
<p>永久函数创建的时候，在函数名之前需要自己加上库名，如果不指定库名的话，会默认把当前库的库名给加上。</p>
<p>永久函数使用的时候，需要在指定的库里面操作，或者在其他库里面使用的话加上，<strong>库名.函数名。</strong></p>
</li>
</ul>
<h1 id="六-分区表和分桶表"><a href="#六-分区表和分桶表" class="headerlink" title="六.分区表和分桶表"></a>六.分区表和分桶表</h1><h2 id="1-分区表"><a href="#1-分区表" class="headerlink" title="1.分区表"></a>1.分区表</h2><p>Hive中的分区就是把==一张大表==的数据==按照业务需要==分散的==存储到多个目录==，==每个目录就称为该表的一个分区==。在查询时==通过where子句中的表达式选择查询所需要的分区，这样的查询效率会提高很多==。</p>
<h3 id="1）分区表基本语法"><a href="#1）分区表基本语法" class="headerlink" title="1）分区表基本语法"></a>1）分区表基本语法</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">create table dept_partition</span><br><span class="line">(</span><br><span class="line">    deptno int,    --部门编号</span><br><span class="line">    dname  string, --部门名称</span><br><span class="line">    loc    string  --部门位置</span><br><span class="line">)</span><br><span class="line">partitioned by (day string)  # ——&gt;填写分区字段</span><br><span class="line">row format delimited fields terminated by &#39;\t&#39;;</span><br></pre></td></tr></table></figure>
<h3 id="2）分区表读写数据"><a href="#2）分区表读写数据" class="headerlink" title="2）分区表读写数据"></a>2）分区表读写数据</h3><ul>
<li><p><strong>写数据</strong>  </p>
<ul>
<li><p><strong>装载数据</strong></p>
</li>
<li><p>```mysql</p>
<h1 id="将数据加载到’20220401’分区"><a href="#将数据加载到’20220401’分区" class="headerlink" title="将数据加载到’20220401’分区"></a>将数据加载到’20220401’分区</h1><p>load data local inpath ‘/opt/module/hive/datas/dept_20220401.log’<br>into table dept_partition<br>partition(day=’20220401’);</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">* **insert-数据插入**</span><br><span class="line"></span><br><span class="line">* &#96;&#96;&#96;mysql</span><br><span class="line">  # 将day&#x3D;&#39;20220401&#39;分区的数据插入到day&#x3D;&#39;20220402&#39;分区</span><br><span class="line">  insert overwrite table dept_partition partition (day &#x3D; &#39;20220402&#39;)</span><br><span class="line">  select deptno, dname, loc</span><br><span class="line">  from dept_partition</span><br><span class="line">  where day &#x3D; &#39;2020-04-01&#39;;</span><br></pre></td></tr></table></figure>
</li>
</ul>
</li>
<li><p><strong>读数据</strong>  </p>
<ul>
<li><p>```mysql</p>
<h1 id="查询分区表数据时，可以将分区字段看作表的伪列，可像使用其他字段一样使用分区字段。"><a href="#查询分区表数据时，可以将分区字段看作表的伪列，可像使用其他字段一样使用分区字段。" class="headerlink" title="查询分区表数据时，可以将分区字段看作表的伪列，可像使用其他字段一样使用分区字段。"></a>查询分区表数据时，可以将分区字段看作表的伪列，可像使用其他字段一样使用分区字段。</h1><p>select deptno, dname, loc ,day<br>from dept_partition<br>where day = ‘2020-04-01’;</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">* **分区表基本操作**</span><br><span class="line"></span><br><span class="line">  * **查看所有分区信息**  </span><br><span class="line"></span><br><span class="line">  * &#96;&#96;&#96;mysql</span><br><span class="line">    show partitions dept_partition;</span><br></pre></td></tr></table></figure>
</li>
<li><p><strong>增加分区</strong>  </p>
</li>
<li><p>```mysql<br>alter table dept_partition<br>add partition(day=’20220403’);</p>
<p>alter table dept_partition<br>add partition(day=’20220404’) partition(day=’20220405’);</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">* **删除分区**  </span><br><span class="line"></span><br><span class="line">* &#96;&#96;&#96;mysql</span><br><span class="line">  alter table dept_partition </span><br><span class="line">  drop partition (day&#x3D;&#39;20220403&#39;);</span><br><span class="line">  </span><br><span class="line">  alter table dept_partition </span><br><span class="line">  drop partition (day&#x3D;&#39;20220404&#39;), partition(day&#x3D;&#39;20220405&#39;);</span><br></pre></td></tr></table></figure>
</li>
<li><p><strong>修复分区</strong>  </p>
<p>==Hive将分区表的所有分区信息都保存在了元数据中，只有元数据与HDFS上的分区路径一致时，分区表才能正常读写数据。==若用户手动创建/删除分区路径，Hive都是感知不到的，这样就会导致Hive的元数据和HDFS的分区路径不一致。再比如，若分区表为外部表，用户执行drop partition命令后，分区元数据会被删除，而HDFS的分区路径不会被删除，同样会导致Hive的元数据和HDFS的分区路径不一致。</p>
<p>若出现元数据和HDFS路径不一致的情况，可通过如下几种手段进行修复。</p>
<ul>
<li><p><strong>add partition</strong>  </p>
<p>若手动创建HDFS的分区路径，Hive无法识别，可通过add partition命令增加分区元数据信息，从而使元数据和分区路径保持一致。</p>
</li>
<li><p><strong>drop partition</strong>  </p>
<p>若手动删除HDFS的分区路径，Hive无法识别，可通过drop partition命令删除分区元数据信息，从而使元数据和分区路径保持一致。</p>
</li>
<li><p><strong>msck</strong>  </p>
<p>若分区元数据和HDFS的分区路径不一致，还可使用msck命令进行修复，以下是该命令的用法说明。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">msck repair table table_name [add&#x2F;drop&#x2F;sync partitions];</span><br></pre></td></tr></table></figure>
<p>说明：</p>
<ul>
<li><p>msck repair table table_name ==add partitions==：该命令会增加HDFS路径存在但元数据缺失的分区信息。</p>
</li>
<li><p>msck repair table table_name ==drop partitions==：该命令会删除HDFS路径已经删除但元数据仍然存在的分区信息。</p>
</li>
<li><p>msck repair table table_name ==sync partitions==：该命令会同步HDFS路径和元数据分区信息，相当于同时执行上述的两个命令。</p>
</li>
<li><p>msck repair table table_name：等价于msck repair table table_name <strong>add</strong> partitions命令。</p>
</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
</ul>
<h3 id="3）二级分区表"><a href="#3）二级分区表" class="headerlink" title="3）二级分区表"></a>3）二级分区表</h3><p>思考：如果一天内的日志数据量也很大，如何再将数据拆分?</p>
<p>答案是二级分区表，例如可以在按天分区的基础上，再对每天的数据按小时进行分区。</p>
<ul>
<li><strong>建表语句</strong></li>
</ul>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">create table dept_partition2(</span><br><span class="line">    deptno int,    -- 部门编号</span><br><span class="line">    dname string, -- 部门名称</span><br><span class="line">    loc string     -- 部门位置</span><br><span class="line">)</span><br><span class="line">partitioned by (day string, hour string)</span><br><span class="line">row format delimited fields terminated by &#39;\t&#39;;</span><br></pre></td></tr></table></figure>
<ul>
<li><strong>数据装载语句</strong>  </li>
</ul>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">load data local inpath &#39;&#x2F;opt&#x2F;module&#x2F;hive&#x2F;datas&#x2F;dept_20220401.log&#39; </span><br><span class="line">into table dept_partition2 </span><br><span class="line">partition(day&#x3D;&#39;20220401&#39;, hour&#x3D;&#39;12&#39;);</span><br></pre></td></tr></table></figure>
<ul>
<li><strong>查询分区数据</strong>  </li>
</ul>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">select * </span><br><span class="line">from dept_partition2 </span><br><span class="line">where day&#x3D;&#39;20220401&#39; and hour&#x3D;&#39;12&#39;;</span><br></pre></td></tr></table></figure>
<h3 id="4）动态分区"><a href="#4）动态分区" class="headerlink" title="4）动态分区"></a>4）动态分区</h3><p>动态分区是指向分区表insert数据时，==被写往的分区不由用户指定，而是由每行数据的最后一个字段的值来动态的决定==。使用动态分区，可只用一个insert语句将数据写入多个分区。  </p>
<ul>
<li><strong>动态分区功能总开关（默认true，开启）</strong>set hive.exec.dynamic.partition=true。</li>
<li><strong>严格模式和非严格模式</strong>  动态分区的模式，默认strict（严格模式），要求必须指定至少一个分区为静态分区，nonstrict（非严格模式）允许所有的分区字段都使用动态分区。</li>
<li><strong>一条insert语句可同时创建的最大的分区个数，默认为1000</strong> set hive.exec.max.dynamic.partitions=1000。  </li>
<li><strong>单个Mapper或者Reducer可同时创建的最大的分区个数，默认为100</strong> set hive.exec.max.dynamic.partitions.pernode=100。</li>
<li><strong>一条insert语句可以创建的最大的文件个数，默认100000</strong> hive.exec.max.created.files=100000。</li>
<li><strong>当查询结果为空时且进行动态分区时，是否抛出异常，默认false </strong>hive.error.on.empty.partition=false。  </li>
</ul>
<p>案例需求：将dept表中的数据按照地区（loc字段），插入到目标表dept_partition_dynamic的相应分区中。</p>
<p><strong>1.创建目标分区表</strong>  </p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">create table dept_partition_dynamic(</span><br><span class="line">    id int, </span><br><span class="line">    name string</span><br><span class="line">) </span><br><span class="line">partitioned by (loc int) </span><br><span class="line">row format delimited fields terminated by &#39;\t&#39;;</span><br></pre></td></tr></table></figure>
<p><strong>2.设置动态分区</strong>  </p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">set hive.exec.dynamic.partition.mode &#x3D; nonstrict;</span><br><span class="line"></span><br><span class="line">insert into table dept_partition_dynamic </span><br><span class="line">partition(loc) </span><br><span class="line">select deptno, dname, loc </span><br><span class="line">from dept;</span><br></pre></td></tr></table></figure>
<h2 id="2-分桶表"><a href="#2-分桶表" class="headerlink" title="2.分桶表"></a>2.分桶表</h2><h3 id="1）普通分桶表"><a href="#1）普通分桶表" class="headerlink" title="1）普通分桶表"></a>1）普通分桶表</h3><ul>
<li><p><strong>建表语句</strong></p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">create table stu_buck(</span><br><span class="line">    id int, </span><br><span class="line">    name string</span><br><span class="line">)</span><br><span class="line">clustered by(id) </span><br><span class="line">into 4 buckets</span><br><span class="line">row format delimited fields terminated by &#39;\t&#39;;</span><br></pre></td></tr></table></figure>
</li>
<li><p><strong>数据装载</strong></p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">load data local inpath &#39;&#x2F;opt&#x2F;module&#x2F;hive&#x2F;datas&#x2F;student.txt&#39; </span><br><span class="line">into table stu_buck;</span><br></pre></td></tr></table></figure>
</li>
</ul>
<h3 id="3）分桶排序表"><a href="#3）分桶排序表" class="headerlink" title="3）分桶排序表"></a>3）分桶排序表</h3><ul>
<li><p>建表语句</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">create table stu_buck_sort(</span><br><span class="line">    id int, </span><br><span class="line">    name string</span><br><span class="line">)</span><br><span class="line">clustered by(id) sorted by(id)</span><br><span class="line">into 4 buckets</span><br><span class="line">row format delimited fields terminated by &#39;\t&#39;;</span><br></pre></td></tr></table></figure>
</li>
<li><p>数据装载</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">load data local inpath &#39;&#x2F;opt&#x2F;module&#x2F;hive&#x2F;datas&#x2F;student.txt&#39; </span><br><span class="line">into table stu_buck_sort;</span><br></pre></td></tr></table></figure>
<p>==注：create table的clustered by其实仅仅是分布，与Select语句中的cluster by其实并不一样。而是和Select语句中的distribute by相同。所以create table的clustered by sorted by其实等价于select的distribute by sort by。==</p>
</li>
</ul>
<h1 id="七-文件格式和压缩"><a href="#七-文件格式和压缩" class="headerlink" title="七.文件格式和压缩"></a>七.文件格式和压缩</h1><h2 id="1-Hadoop压缩概述"><a href="#1-Hadoop压缩概述" class="headerlink" title="1.Hadoop压缩概述"></a>1.Hadoop压缩概述</h2><div class="table-container">
<table>
<thead>
<tr>
<th><strong>压缩格式</strong></th>
<th><strong>算法</strong></th>
<th><strong>文件扩展名</strong></th>
<th><strong>是否可切分</strong></th>
</tr>
</thead>
<tbody>
<tr>
<td>DEFLATE</td>
<td>DEFLATE</td>
<td>.deflate</td>
<td>否</td>
</tr>
<tr>
<td>Gzip</td>
<td>DEFLATE</td>
<td>.gz</td>
<td>否</td>
</tr>
<tr>
<td>bzip2</td>
<td>bzip2</td>
<td>.bz2</td>
<td><strong>是</strong></td>
</tr>
<tr>
<td>LZO</td>
<td>LZO</td>
<td>.lzo</td>
<td><strong>是</strong></td>
</tr>
<tr>
<td>Snappy</td>
<td>Snappy</td>
<td>.snappy</td>
<td>否</td>
</tr>
</tbody>
</table>
</div>
<h2 id="2-Hive文件格式"><a href="#2-Hive文件格式" class="headerlink" title="2.Hive文件格式"></a>2.Hive文件格式</h2><p>为Hive表中的数据选择一个合适的文件格式，对提高查询性能的提高是十分有益的。Hive表数据的存储格式，可以选择text file、orc、parquet、sequence file等。</p>
<h3 id="1）Text-File"><a href="#1）Text-File" class="headerlink" title="1）Text File"></a>1）Text File</h3><p>文本文件是Hive默认使用的文件格式，文本文件中的一行内容，就对应Hive表中的一行记录。  </p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">create table textfile_table</span><br><span class="line">(column_specs)</span><br><span class="line">stored as textfile; #设置表的存储文件格式</span><br></pre></td></tr></table></figure>
<h3 id="2）ORC"><a href="#2）ORC" class="headerlink" title="2）ORC"></a>2）ORC</h3><p>==ORC（Optimized Row Columnar）==file format是Hive 0.11版里引入的一种<strong>列式存储</strong>的文件格式。ORC文件能够提高Hive读写数据和处理数据的性能。</p>
<ul>
<li><p><strong>行存储的特点</strong>  </p>
<p>查询满足条件的一整行数据的时候，列存储则需要去每个聚集的字段找到对应的每个列的值，行存储只需要找到其中一个值，其余的值都在相邻地方，所以此时行存储查询的速度更快。</p>
</li>
<li><p><strong>列存储的特点</strong>  </p>
<p>因为每个字段的数据聚集存储，在查询只需要少数几个字段的时候，能大大减少读取的数据量；每个字段的数据类型一定是相同的，列式存储可以针对性的设计更好的设计压缩算法。</p>
</li>
</ul>
<p><img src="ipic/ORC文件基本格式.png" alt="ORC文件基本格式"></p>
<p>每个Orc文件由Header、Body和Tail三部分组成。</p>
<ul>
<li><p>其中Header内容为ORC，用于表示文件类型。</p>
</li>
<li><p>Body由1个或多个stripe组成，==每个stripe一般为HDFS的块大小==，每一个stripe包含多条记录，这些记录按照列进行独立存储，每个stripe里有三部分组成，分别是Index Data，Row Data，Stripe Footer。</p>
<ul>
<li><p><strong>Index Data</strong>：一个轻量级的index，==默认是为各列每隔1W行做一个索引==。每个索引会记录第n万行的位置，和最近一万行的最大值和最小值等信息。</p>
</li>
<li><p><strong>Row Data</strong>：存的是具体的数据，按列进行存储，并==对每个列进行编码==，分成多个Stream来存储。</p>
</li>
<li><p><strong>Stripe Footer</strong>：存放的是各个Stream的位置以及各column的编码信息。</p>
</li>
</ul>
</li>
<li><p>Tail由File Footer和PostScript组成。File Footer中保存了各Stripe的其实位置、索引长度、数据长度等信息，各Column的统计信息等；PostScript记录了整个文件的压缩类型以及File Footer的长度信息等。</p>
</li>
</ul>
<p>在读取ORC文件时，会先从最后一个字节读取PostScript长度，进而读取到PostScript，从里面解析到File Footer长度，进而读取FileFooter，从中解析到各个Stripe信息，再读各个Stripe，即从后往前读。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">create table orc_table</span><br><span class="line">(column_specs)</span><br><span class="line">stored as orc # 指定表的存储格式</span><br><span class="line">tblproperties (property_name&#x3D;property_value, ...); #选择其他参数如压缩格式等</span><br></pre></td></tr></table></figure>
<h3 id="3）Parquet"><a href="#3）Parquet" class="headerlink" title="3）Parquet"></a>3）Parquet</h3><p>Parquet文件是Hadoop生态中的一个通用的文件格式，它也是一个<strong>列式存储</strong>的文件格式。</p>
<p><img src="ipic/parquet文件基本格式.png" alt="parquet文件基本格式"></p>
<ul>
<li><p>文件的首尾都是该文件的Magic Code，用于校验它是否是一个Parquet文件。</p>
</li>
<li><p>首尾中间由若干个Row Group和一个Footer（File Meta Data）组成。每个Row Group包含多个Column Chunk，每个Column Chunk包含多个Page。以下是Row Group、Column Chunk和Page三个概念的说明：</p>
<ul>
<li><p><strong>行组（Row Group）：</strong>一个行组对应逻辑表中的若干行。 </p>
</li>
<li><p><strong>列块（Column Chunk）：</strong>一个行组中的一列保存在一个列块中。 </p>
</li>
<li><p><strong>页（Page）：</strong>一个列块的数据会划分为若干个页。 </p>
</li>
</ul>
</li>
<li><p>Footer（File Meta Data）中存储了每个行组（Row Group）中的每个列快（Column Chunk）的元数据信息，元数据信息包含了该列的数据类型、该列的编码方式、该类的Data Page位置等信息。</p>
</li>
</ul>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">Create table parquet_table</span><br><span class="line">(column_specs)</span><br><span class="line">stored as parquet #指定表的存储格式</span><br><span class="line">tblproperties (property_name&#x3D;property_value, ...); #可选属性值，如压缩格式等</span><br></pre></td></tr></table></figure>
<h2 id="3-压缩"><a href="#3-压缩" class="headerlink" title="3.压缩"></a>3.压缩</h2><p>在Hive表中和计算过程中，保持数据的压缩，对磁盘空间的有效利用和提高查询性能都是十分有益的。  </p>
<h3 id="1）Hive表数据进行压缩"><a href="#1）Hive表数据进行压缩" class="headerlink" title="1）Hive表数据进行压缩"></a>1）Hive表数据进行压缩</h3><ul>
<li><p><strong>TextFile</strong>  </p>
<p>若一张表的文件类型为TextFile，若需要对该表中的数据进行压缩，多数情况下，无需在建表语句做出声明。直接将压缩后的文件导入到该表即可，Hive在查询表中数据时，可自动识别其压缩格式，进行解压。</p>
<p>需要注意的是，在执行往表中导入数据的SQL语句时，用户需设置以下参数，来保证写入表中的数据是被压缩的。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"># SQL语句的最终输出结果是否压缩</span><br><span class="line">set hive.exec.compress.output&#x3D;true;</span><br><span class="line"></span><br><span class="line"># 输出结果的压缩格式（以下示例为snappy）</span><br><span class="line">set mapreduce.output.fileoutputformat.compress.codec&#x3D;org.apache.hadoop.io.compress.SnappyCodec;</span><br></pre></td></tr></table></figure>
</li>
<li><p><strong>ORC</strong></p>
<p>若一张表的文件类型为ORC，若需要对该表数据进行压缩，需在建表语句中声明压缩格式。</p>
</li>
<li><p><strong>Parquet</strong>  </p>
<p>若一张表的文件类型为Parquet，若需要对该表数据进行压缩，需在建表语句中声明压缩格式。</p>
</li>
</ul>
<h3 id="2）计算过程中使用压缩"><a href="#2）计算过程中使用压缩" class="headerlink" title="2）计算过程中使用压缩"></a>2）计算过程中使用压缩</h3><ul>
<li><p><strong>单个MR的中间结果进行压缩</strong></p>
<p>单个MR的中间结果是指Mapper输出的数据，对其进行压缩可降低shuffle阶段的网络IO，可通过以下参数进行配置：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"># 开启MapReduce中间数据压缩功能</span><br><span class="line">set mapreduce.map.output.compress&#x3D;true;</span><br><span class="line"># 设置MapReduce中间数据数据的压缩方式（以下示例为snappy）</span><br><span class="line">set mapreduce.map.output.compress.codec&#x3D;org.apache.hadoop.io.compress.SnappyCodec;</span><br></pre></td></tr></table></figure>
</li>
</ul>
<ul>
<li><p><strong>单条SQL语句的中间结果进行压缩</strong> </p>
<p>单条SQL语句的中间结果是指，两个MR（一条SQL语句可能需要通过MR进行计算）之间的临时数据，可通过以下参数进行配置： </p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"># 是否对两个MR之间的临时数据进行压缩</span><br><span class="line">set hive.exec.compress.intermediate&#x3D;true;</span><br><span class="line"># 压缩格式（以下示例为snappy）</span><br><span class="line">set hive.intermediate.compression.codec&#x3D; org.apache.hadoop.io.compress.SnappyCodec;</span><br></pre></td></tr></table></figure>
</li>
</ul>

    </div>

    
    
    

      <footer class="post-footer">

        


        
    <div class="post-nav">
      <div class="post-nav-item">
    <a href="/2023/04/04/BigData/HBase/HBase/" rel="prev" title="HBase">
      <i class="fa fa-chevron-left"></i> HBase
    </a></div>
      <div class="post-nav-item">
    <a href="/2023/04/05/BigData/Kafka/kafka/" rel="next" title="Kafka">
      Kafka <i class="fa fa-chevron-right"></i>
    </a></div>
    </div>
      </footer>
    
  </article>
  
  
  



          </div>
          
    <div class="comments" id="valine-comments"></div>

<script>
  window.addEventListener('tabs:register', () => {
    let { activeClass } = CONFIG.comments;
    if (CONFIG.comments.storage) {
      activeClass = localStorage.getItem('comments_active') || activeClass;
    }
    if (activeClass) {
      let activeTab = document.querySelector(`a[href="#comment-${activeClass}"]`);
      if (activeTab) {
        activeTab.click();
      }
    }
  });
  if (CONFIG.comments.storage) {
    window.addEventListener('tabs:click', event => {
      if (!event.target.matches('.tabs-comment .tab-content .tab-pane')) return;
      let commentClass = event.target.classList[1];
      localStorage.setItem('comments_active', commentClass);
    });
  }
</script>

        </div>
          
  
  <div class="toggle sidebar-toggle">
    <span class="toggle-line toggle-line-first"></span>
    <span class="toggle-line toggle-line-middle"></span>
    <span class="toggle-line toggle-line-last"></span>
  </div>

  <aside class="sidebar">
    <div class="sidebar-inner">

      <ul class="sidebar-nav motion-element">
        <li class="sidebar-nav-toc">
          文章目录
        </li>
        <li class="sidebar-nav-overview">
          站点概览
        </li>
      </ul>

      <!--noindex-->
      <div class="post-toc-wrap sidebar-panel">
          <div class="post-toc motion-element"><ol class="nav"><li class="nav-item nav-level-1"><a class="nav-link" href="#%E4%B8%80-Hive%E5%85%A5%E9%97%A8"><span class="nav-number">1.</span> <span class="nav-text">一.Hive入门</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#1-%E4%BB%80%E4%B9%88%E6%98%AFHive"><span class="nav-number">1.1.</span> <span class="nav-text">1.什么是Hive</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#2-Hive%E6%9C%AC%E8%B4%A8"><span class="nav-number">1.2.</span> <span class="nav-text">2.Hive本质</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#3-Hive%E6%9E%B6%E6%9E%84%E5%8E%9F%E7%90%86"><span class="nav-number">1.3.</span> <span class="nav-text">3.Hive架构原理</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#%E4%BA%8C-DDL%EF%BC%88Data-Definition-Language%EF%BC%89%E6%95%B0%E6%8D%AE%E5%AE%9A%E4%B9%89"><span class="nav-number">2.</span> <span class="nav-text">二.DDL（Data Definition Language）数据定义</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#1-%E6%95%B0%E6%8D%AE%E5%BA%93%EF%BC%88database%EF%BC%89"><span class="nav-number">2.1.</span> <span class="nav-text">1.数据库（database）</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#1%EF%BC%89%E5%88%9B%E5%BB%BA%E6%95%B0%E6%8D%AE%E5%BA%93"><span class="nav-number">2.1.1.</span> <span class="nav-text">1）创建数据库</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#2%EF%BC%89%E6%9F%A5%E8%AF%A2%E6%95%B0%E6%8D%AE%E5%BA%93"><span class="nav-number">2.1.2.</span> <span class="nav-text">2）查询数据库</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#3%EF%BC%89%E4%BF%AE%E6%94%B9%E6%95%B0%E6%8D%AE%E5%BA%93"><span class="nav-number">2.1.3.</span> <span class="nav-text">3）修改数据库</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#4%EF%BC%89%E5%88%A0%E9%99%A4%E6%95%B0%E6%8D%AE%E5%BA%93"><span class="nav-number">2.1.4.</span> <span class="nav-text">4）删除数据库</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#2-%E8%A1%A8%EF%BC%88table"><span class="nav-number">2.2.</span> <span class="nav-text">2.表（table)</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#1%EF%BC%89%E5%88%9B%E5%BB%BA%E8%A1%A8"><span class="nav-number">2.2.1.</span> <span class="nav-text">1）创建表</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#2%EF%BC%89%E6%9F%A5%E7%9C%8B%E8%A1%A8"><span class="nav-number">2.2.2.</span> <span class="nav-text">2）查看表</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#3%EF%BC%89%E4%BF%AE%E6%94%B9%E8%A1%A8"><span class="nav-number">2.2.3.</span> <span class="nav-text">3）修改表</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#4%EF%BC%89%E5%88%A0%E9%99%A4%E8%A1%A8"><span class="nav-number">2.2.4.</span> <span class="nav-text">4）删除表</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#5%EF%BC%89%E6%B8%85%E7%A9%BA%E8%A1%A8"><span class="nav-number">2.2.5.</span> <span class="nav-text">5）清空表</span></a></li></ol></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#%E4%B8%89-DML%EF%BC%88Data-Manipulation-Language%EF%BC%89%E6%95%B0%E6%8D%AE%E6%93%8D%E4%BD%9C"><span class="nav-number">3.</span> <span class="nav-text">三.DML（Data Manipulation Language）数据操作</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#1-Load"><span class="nav-number">3.1.</span> <span class="nav-text">1.Load</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#2-Insert"><span class="nav-number">3.2.</span> <span class="nav-text">2.Insert</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#3-Export-amp-Import"><span class="nav-number">3.3.</span> <span class="nav-text">3.Export&amp;Import</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#%E5%9B%9B-%E6%9F%A5%E8%AF%A2"><span class="nav-number">4.</span> <span class="nav-text">四.查询</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#1-Sort-By%EF%BC%88%E6%AF%8F%E4%B8%AAReduce%E5%86%85%E9%83%A8%E6%8E%92%E5%BA%8F%EF%BC%89"><span class="nav-number">4.1.</span> <span class="nav-text">1.Sort By（每个Reduce内部排序）</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#2-Distribute-By%EF%BC%88%E5%88%86%E5%8C%BA%EF%BC%89"><span class="nav-number">4.2.</span> <span class="nav-text">2.Distribute By（分区）</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#3-Cluster-By%EF%BC%88%E5%88%86%E5%8C%BA%E6%8E%92%E5%BA%8F%EF%BC%89"><span class="nav-number">4.3.</span> <span class="nav-text">3.Cluster By（分区排序）</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#%E4%BA%94-%E5%87%BD%E6%95%B0"><span class="nav-number">5.</span> <span class="nav-text">五.函数</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#1-%E5%8D%95%E8%A1%8C%E5%87%BD%E6%95%B0"><span class="nav-number">5.1.</span> <span class="nav-text">1.单行函数</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#1%EF%BC%89%E7%AE%97%E6%9C%AF%E8%BF%90%E7%AE%97%E5%87%BD%E6%95%B0"><span class="nav-number">5.1.1.</span> <span class="nav-text">1）算术运算函数</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#2%EF%BC%89%E6%95%B0%E5%80%BC%E5%87%BD%E6%95%B0"><span class="nav-number">5.1.2.</span> <span class="nav-text">2）数值函数</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#3%EF%BC%89%E5%AD%97%E7%AC%A6%E4%B8%B2%E5%87%BD%E6%95%B0"><span class="nav-number">5.1.3.</span> <span class="nav-text">3）字符串函数</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#4%EF%BC%89%E6%97%A5%E6%9C%9F%E5%87%BD%E6%95%B0"><span class="nav-number">5.1.4.</span> <span class="nav-text">4）日期函数</span></a></li></ol></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#1659946088"><span class="nav-number">6.</span> <span class="nav-text">1659946088</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#2022-07-11"><span class="nav-number">7.</span> <span class="nav-text">2022-07-11</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#2022-08-10"><span class="nav-number">8.</span> <span class="nav-text">2022-08-10</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#2022-08-06"><span class="nav-number">9.</span> <span class="nav-text">2022-08-06</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#5%EF%BC%89%E6%B5%81%E7%A8%8B%E6%8E%A7%E5%88%B6%E5%87%BD%E6%95%B0"><span class="nav-number">9.0.1.</span> <span class="nav-text">5）流程控制函数</span></a></li></ol></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#select-map-%E2%80%98xiaohai%E2%80%99-1-%E2%80%99dahai%E2%80%99-2"><span class="nav-number">10.</span> <span class="nav-text">select map(‘xiaohai’,1,’dahai’,2);</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#%E2%80%9Cxiaohai%E2%80%9D-1-%E2%80%9Ddahai%E2%80%9D-2"><span class="nav-number">11.</span> <span class="nav-text">{“xiaohai”:1,”dahai”:2}</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#1-2-%E8%BE%93%E5%87%BA%E4%B8%BA%E9%9B%86%E5%90%88%E7%B1%BB%E5%9E%8B"><span class="nav-number">12.</span> <span class="nav-text">[1,2] 输出为集合类型</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#true"><span class="nav-number">13.</span> <span class="nav-text">true</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#%E2%80%9Ccol1%E2%80%9D-%E2%80%9Dname%E2%80%9D-%E2%80%9Dcol2%E2%80%9D-%E2%80%9Dage%E2%80%9D-%E2%80%9Dcol3%E2%80%9D-%E2%80%9Dweight%E2%80%9D"><span class="nav-number">14.</span> <span class="nav-text">{“col1”:”name”,”col2”:”age”,”col3”:”weight”}</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#2-%E9%AB%98%E7%BA%A7%E8%81%9A%E5%90%88%E5%87%BD%E6%95%B0"><span class="nav-number">14.1.</span> <span class="nav-text">2.高级聚合函数</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#1%EF%BC%89%E6%99%AE%E9%80%9A%E8%81%9A%E5%90%88-count-sum%E2%80%A6"><span class="nav-number">14.1.1.</span> <span class="nav-text">1）普通聚合 count&#x2F;sum….</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#2%EF%BC%89collect-list%E6%94%B6%E9%9B%86%E5%B9%B6%E5%BD%A2%E6%88%90list%E9%9B%86%E5%90%88%EF%BC%8C%E7%BB%93%E6%9E%9C%E4%B8%8D%E5%8E%BB%E9%87%8D"><span class="nav-number">14.1.2.</span> <span class="nav-text">2）collect_list收集并形成list集合，结果不去重</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#3%EF%BC%89collect-set-%E6%94%B6%E9%9B%86%E5%B9%B6%E5%BD%A2%E6%88%90set%E9%9B%86%E5%90%88%EF%BC%8C%E7%BB%93%E6%9E%9C%E5%8E%BB%E9%87%8D"><span class="nav-number">14.1.3.</span> <span class="nav-text">3）collect_set 收集并形成set集合，结果去重</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#3-%E7%82%B8%E8%A3%82%E5%87%BD%E6%95%B0"><span class="nav-number">14.2.</span> <span class="nav-text">3.炸裂函数</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#4-%E7%AA%97%E5%8F%A3%E5%87%BD%E6%95%B0%EF%BC%88%E5%BC%80%E7%AA%97%E5%87%BD%E6%95%B0%EF%BC%89"><span class="nav-number">14.3.</span> <span class="nav-text">4.窗口函数（开窗函数）</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#1%EF%BC%89%E5%B8%B8%E7%94%A8%E7%AA%97%E5%8F%A3%E5%87%BD%E6%95%B0"><span class="nav-number">14.3.1.</span> <span class="nav-text">1）常用窗口函数</span></a></li></ol></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#%E5%88%9B%E5%BB%BA%E4%B8%B4%E6%97%B6%E5%87%BD%E6%95%B0%E4%B8%8E%E5%BC%80%E5%8F%91%E5%A5%BD%E7%9A%84java-class%E5%85%B3%E8%81%94"><span class="nav-number">15.</span> <span class="nav-text">创建临时函数与开发好的java class关联</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#%E5%85%AD-%E5%88%86%E5%8C%BA%E8%A1%A8%E5%92%8C%E5%88%86%E6%A1%B6%E8%A1%A8"><span class="nav-number">16.</span> <span class="nav-text">六.分区表和分桶表</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#1-%E5%88%86%E5%8C%BA%E8%A1%A8"><span class="nav-number">16.1.</span> <span class="nav-text">1.分区表</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#1%EF%BC%89%E5%88%86%E5%8C%BA%E8%A1%A8%E5%9F%BA%E6%9C%AC%E8%AF%AD%E6%B3%95"><span class="nav-number">16.1.1.</span> <span class="nav-text">1）分区表基本语法</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#2%EF%BC%89%E5%88%86%E5%8C%BA%E8%A1%A8%E8%AF%BB%E5%86%99%E6%95%B0%E6%8D%AE"><span class="nav-number">16.1.2.</span> <span class="nav-text">2）分区表读写数据</span></a></li></ol></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#%E5%B0%86%E6%95%B0%E6%8D%AE%E5%8A%A0%E8%BD%BD%E5%88%B0%E2%80%9920220401%E2%80%99%E5%88%86%E5%8C%BA"><span class="nav-number">17.</span> <span class="nav-text">将数据加载到’20220401’分区</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#%E6%9F%A5%E8%AF%A2%E5%88%86%E5%8C%BA%E8%A1%A8%E6%95%B0%E6%8D%AE%E6%97%B6%EF%BC%8C%E5%8F%AF%E4%BB%A5%E5%B0%86%E5%88%86%E5%8C%BA%E5%AD%97%E6%AE%B5%E7%9C%8B%E4%BD%9C%E8%A1%A8%E7%9A%84%E4%BC%AA%E5%88%97%EF%BC%8C%E5%8F%AF%E5%83%8F%E4%BD%BF%E7%94%A8%E5%85%B6%E4%BB%96%E5%AD%97%E6%AE%B5%E4%B8%80%E6%A0%B7%E4%BD%BF%E7%94%A8%E5%88%86%E5%8C%BA%E5%AD%97%E6%AE%B5%E3%80%82"><span class="nav-number">18.</span> <span class="nav-text">查询分区表数据时，可以将分区字段看作表的伪列，可像使用其他字段一样使用分区字段。</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#3%EF%BC%89%E4%BA%8C%E7%BA%A7%E5%88%86%E5%8C%BA%E8%A1%A8"><span class="nav-number">18.0.1.</span> <span class="nav-text">3）二级分区表</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#4%EF%BC%89%E5%8A%A8%E6%80%81%E5%88%86%E5%8C%BA"><span class="nav-number">18.0.2.</span> <span class="nav-text">4）动态分区</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#2-%E5%88%86%E6%A1%B6%E8%A1%A8"><span class="nav-number">18.1.</span> <span class="nav-text">2.分桶表</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#1%EF%BC%89%E6%99%AE%E9%80%9A%E5%88%86%E6%A1%B6%E8%A1%A8"><span class="nav-number">18.1.1.</span> <span class="nav-text">1）普通分桶表</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#3%EF%BC%89%E5%88%86%E6%A1%B6%E6%8E%92%E5%BA%8F%E8%A1%A8"><span class="nav-number">18.1.2.</span> <span class="nav-text">3）分桶排序表</span></a></li></ol></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#%E4%B8%83-%E6%96%87%E4%BB%B6%E6%A0%BC%E5%BC%8F%E5%92%8C%E5%8E%8B%E7%BC%A9"><span class="nav-number">19.</span> <span class="nav-text">七.文件格式和压缩</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#1-Hadoop%E5%8E%8B%E7%BC%A9%E6%A6%82%E8%BF%B0"><span class="nav-number">19.1.</span> <span class="nav-text">1.Hadoop压缩概述</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#2-Hive%E6%96%87%E4%BB%B6%E6%A0%BC%E5%BC%8F"><span class="nav-number">19.2.</span> <span class="nav-text">2.Hive文件格式</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#1%EF%BC%89Text-File"><span class="nav-number">19.2.1.</span> <span class="nav-text">1）Text File</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#2%EF%BC%89ORC"><span class="nav-number">19.2.2.</span> <span class="nav-text">2）ORC</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#3%EF%BC%89Parquet"><span class="nav-number">19.2.3.</span> <span class="nav-text">3）Parquet</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#3-%E5%8E%8B%E7%BC%A9"><span class="nav-number">19.3.</span> <span class="nav-text">3.压缩</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#1%EF%BC%89Hive%E8%A1%A8%E6%95%B0%E6%8D%AE%E8%BF%9B%E8%A1%8C%E5%8E%8B%E7%BC%A9"><span class="nav-number">19.3.1.</span> <span class="nav-text">1）Hive表数据进行压缩</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#2%EF%BC%89%E8%AE%A1%E7%AE%97%E8%BF%87%E7%A8%8B%E4%B8%AD%E4%BD%BF%E7%94%A8%E5%8E%8B%E7%BC%A9"><span class="nav-number">19.3.2.</span> <span class="nav-text">2）计算过程中使用压缩</span></a></li></ol></li></ol></li></ol></div>
      </div>
      <!--/noindex-->

      <div class="site-overview-wrap sidebar-panel">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
    <img class="site-author-image" itemprop="image" alt="Normal People"
      src="/images/posthead.jpg">
  <p class="site-author-name" itemprop="name">Normal People</p>
  <div class="site-description" itemprop="description">Get busy living or get busy dying</div>
</div>
<div class="site-state-wrap motion-element">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
          <a href="/archives">
        
          <span class="site-state-item-count">42</span>
          <span class="site-state-item-name">日志</span>
        </a>
      </div>
      <div class="site-state-item site-state-categories">
            <a href="/categories">
          
        <span class="site-state-item-count">17</span>
        <span class="site-state-item-name">分类</span></a>
      </div>
  </nav>
</div>
  <div class="links-of-author motion-element">
      <span class="links-of-author-item">
        <a href="https://github.com/TheNormalPeople" title="GitHub → https:&#x2F;&#x2F;github.com&#x2F;TheNormalPeople" rel="noopener" target="_blank"><i class="fab fa-github fa-fw"></i>GitHub</a>
      </span>
      <span class="links-of-author-item">
        <a href="mailto:1272481411@qq.com" title="E-Mail → mailto:1272481411@qq.com" rel="noopener" target="_blank"><i class="fa fa-envelope fa-fw"></i>E-Mail</a>
      </span>
      <span class="links-of-author-item">
        <a href="https://weibo.com/u/5938927274" title="Weibo → https:&#x2F;&#x2F;weibo.com&#x2F;u&#x2F;5938927274" rel="noopener" target="_blank"><i class="fab fa-weibo fa-fw"></i>Weibo</a>
      </span>
      <span class="links-of-author-item">
        <a href="https://instagram.com/cy19970506" title="Instagram → https:&#x2F;&#x2F;instagram.com&#x2F;cy19970506" rel="noopener" target="_blank"><i class="fab fa-instagram fa-fw"></i>Instagram</a>
      </span>
  </div>



      </div>

    </div>
  </aside>
  <div id="sidebar-dimmer"></div>


      </div>
    </main>

    <footer class="footer">
      <div class="footer-inner">
        

        

<div class="copyright">
  
  &copy; 
  <span itemprop="copyrightYear">2023</span>
  <span class="with-love">
    <i class="heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">Normal People</span>
</div>

        








      </div>
    </footer>
  </div>

  
  <script src="/lib/anime.min.js"></script>
  <script src="/lib/velocity/velocity.min.js"></script>
  <script src="/lib/velocity/velocity.ui.min.js"></script>

<script src="/js/utils.js"></script>

<script src="/js/motion.js"></script>


<script src="/js/schemes/pisces.js"></script>


<script src="/js/next-boot.js"></script>




  















  

  

  


<script>
NexT.utils.loadComments(document.querySelector('#valine-comments'), () => {
  NexT.utils.getScript('//unpkg.com/valine/dist/Valine.min.js', () => {
    var GUEST = ['nick', 'mail', 'link'];
    var guest = 'nick,mail,link';
    guest = guest.split(',').filter(item => {
      return GUEST.includes(item);
    });
    new Valine({
      el         : '#valine-comments',
      verify     : false,
      notify     : false,
      appId      : 'y8XFURQNCoQsprRTou9DiEJu-gzGzoHsz',
      appKey     : 'QfVpjKDtJQdJrnJNnWUbVvjH',
      placeholder: "留下邮箱,有空时间回复您！",
      avatar     : 'mm',
      meta       : guest,
      pageSize   : '10' || 10,
      visitor    : false,
      lang       : '' || 'zh-cn',
      path       : location.pathname,
      recordIP   : false,
      serverURLs : ''
    });
  }, window.Valine);
});
</script>

</body>
</html>
